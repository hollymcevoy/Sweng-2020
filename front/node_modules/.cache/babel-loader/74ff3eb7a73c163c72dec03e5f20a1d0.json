{"ast":null,"code":"\"use strict\";\n\nfunction _typeof(obj) {\n  \"@babel/helpers - typeof\";\n\n  if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") {\n    _typeof = function _typeof(obj) {\n      return typeof obj;\n    };\n  } else {\n    _typeof = function _typeof(obj) {\n      return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj;\n    };\n  }\n\n  return _typeof(obj);\n}\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = exports.connectMicrophoneButton = void 0;\nexports.useMicrophoneButtonClick = useMicrophoneButtonClick;\nexports.useMicrophoneButtonDisabled = useMicrophoneButtonDisabled;\n\nvar _botframeworkWebchatCore = require(\"botframework-webchat-core\");\n\nvar _botframeworkWebchatApi = require(\"botframework-webchat-api\");\n\nvar _classnames = _interopRequireDefault(require(\"classnames\"));\n\nvar _memoizeOne = _interopRequireDefault(require(\"memoize-one\"));\n\nvar _propTypes = _interopRequireDefault(require(\"prop-types\"));\n\nvar _react = _interopRequireWildcard(require(\"react\"));\n\nvar _connectToWebChat = _interopRequireDefault(require(\"../connectToWebChat\"));\n\nvar _IconButton = _interopRequireDefault(require(\"./IconButton\"));\n\nvar _MicrophoneIcon = _interopRequireDefault(require(\"./Assets/MicrophoneIcon\"));\n\nvar _useDictateAbortable3 = _interopRequireDefault(require(\"../hooks/useDictateAbortable\"));\n\nvar _useStyleSet3 = _interopRequireDefault(require(\"../hooks/useStyleSet\"));\n\nvar _useStyleToEmotionObject = _interopRequireDefault(require(\"../hooks/internal/useStyleToEmotionObject\"));\n\nvar _useWebSpeechPonyfill3 = _interopRequireDefault(require(\"../hooks/useWebSpeechPonyfill\"));\n\nfunction _getRequireWildcardCache(nodeInterop) {\n  if (typeof WeakMap !== \"function\") return null;\n  var cacheBabelInterop = new WeakMap();\n  var cacheNodeInterop = new WeakMap();\n  return (_getRequireWildcardCache = function _getRequireWildcardCache(nodeInterop) {\n    return nodeInterop ? cacheNodeInterop : cacheBabelInterop;\n  })(nodeInterop);\n}\n\nfunction _interopRequireWildcard(obj, nodeInterop) {\n  if (!nodeInterop && obj && obj.__esModule) {\n    return obj;\n  }\n\n  if (obj === null || _typeof(obj) !== \"object\" && typeof obj !== \"function\") {\n    return {\n      default: obj\n    };\n  }\n\n  var cache = _getRequireWildcardCache(nodeInterop);\n\n  if (cache && cache.has(obj)) {\n    return cache.get(obj);\n  }\n\n  var newObj = {};\n  var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor;\n\n  for (var key in obj) {\n    if (key !== \"default\" && Object.prototype.hasOwnProperty.call(obj, key)) {\n      var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null;\n\n      if (desc && (desc.get || desc.set)) {\n        Object.defineProperty(newObj, key, desc);\n      } else {\n        newObj[key] = obj[key];\n      }\n    }\n  }\n\n  newObj.default = obj;\n\n  if (cache) {\n    cache.set(obj, newObj);\n  }\n\n  return newObj;\n}\n\nfunction _interopRequireDefault(obj) {\n  return obj && obj.__esModule ? obj : {\n    default: obj\n  };\n}\n\nfunction _slicedToArray(arr, i) {\n  return _arrayWithHoles(arr) || _iterableToArrayLimit(arr, i) || _unsupportedIterableToArray(arr, i) || _nonIterableRest();\n}\n\nfunction _nonIterableRest() {\n  throw new TypeError(\"Invalid attempt to destructure non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n}\n\nfunction _unsupportedIterableToArray(o, minLen) {\n  if (!o) return;\n  if (typeof o === \"string\") return _arrayLikeToArray(o, minLen);\n  var n = Object.prototype.toString.call(o).slice(8, -1);\n  if (n === \"Object\" && o.constructor) n = o.constructor.name;\n  if (n === \"Map\" || n === \"Set\") return Array.from(o);\n  if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen);\n}\n\nfunction _arrayLikeToArray(arr, len) {\n  if (len == null || len > arr.length) len = arr.length;\n\n  for (var i = 0, arr2 = new Array(len); i < len; i++) {\n    arr2[i] = arr[i];\n  }\n\n  return arr2;\n}\n\nfunction _iterableToArrayLimit(arr, i) {\n  var _i = arr == null ? null : typeof Symbol !== \"undefined\" && arr[Symbol.iterator] || arr[\"@@iterator\"];\n\n  if (_i == null) return;\n  var _arr = [];\n  var _n = true;\n  var _d = false;\n\n  var _s, _e;\n\n  try {\n    for (_i = _i.call(arr); !(_n = (_s = _i.next()).done); _n = true) {\n      _arr.push(_s.value);\n\n      if (i && _arr.length === i) break;\n    }\n  } catch (err) {\n    _d = true;\n    _e = err;\n  } finally {\n    try {\n      if (!_n && _i[\"return\"] != null) _i[\"return\"]();\n    } finally {\n      if (_d) throw _e;\n    }\n  }\n\n  return _arr;\n}\n\nfunction _arrayWithHoles(arr) {\n  if (Array.isArray(arr)) return arr;\n}\n\nvar DictateState = _botframeworkWebchatCore.Constants.DictateState;\nvar useDictateInterims = _botframeworkWebchatApi.hooks.useDictateInterims,\n    useDictateState = _botframeworkWebchatApi.hooks.useDictateState,\n    useDisabled = _botframeworkWebchatApi.hooks.useDisabled,\n    useLocalizer = _botframeworkWebchatApi.hooks.useLocalizer,\n    useSendBoxValue = _botframeworkWebchatApi.hooks.useSendBoxValue,\n    useShouldSpeakIncomingActivity = _botframeworkWebchatApi.hooks.useShouldSpeakIncomingActivity,\n    useStartDictate = _botframeworkWebchatApi.hooks.useStartDictate,\n    useStopDictate = _botframeworkWebchatApi.hooks.useStopDictate;\nvar ROOT_STYLE = {\n  display: 'flex',\n  // .sr-only - This component is intended to be invisible to the visual Web Chat user, but read by the AT when using a screen reader\n  '& > .sr-only': {\n    color: 'transparent',\n    height: 1,\n    left: -10000,\n    overflow: 'hidden',\n    position: 'absolute',\n    top: 0,\n    whiteSpace: 'nowrap',\n    width: 1\n  }\n};\n\nvar connectMicrophoneButton = function connectMicrophoneButton() {\n  var primeSpeechSynthesis = (0, _memoizeOne.default)(function (speechSynthesis, SpeechSynthesisUtterance) {\n    if (speechSynthesis && SpeechSynthesisUtterance) {\n      var utterance = new SpeechSynthesisUtterance('');\n\n      var _speechSynthesis$getV = speechSynthesis.getVoices();\n\n      var _speechSynthesis$getV2 = _slicedToArray(_speechSynthesis$getV, 1);\n\n      utterance.voice = _speechSynthesis$getV2[0];\n      speechSynthesis.speak(utterance);\n    }\n  });\n\n  for (var _len = arguments.length, selectors = new Array(_len), _key = 0; _key < _len; _key++) {\n    selectors[_key] = arguments[_key];\n  }\n\n  return _connectToWebChat.default.apply(void 0, [function (_ref) {\n    var disabled = _ref.disabled,\n        dictateInterims = _ref.dictateInterims,\n        dictateState = _ref.dictateState,\n        language = _ref.language,\n        setSendBox = _ref.setSendBox,\n        startDictate = _ref.startDictate,\n        stopDictate = _ref.stopDictate,\n        stopSpeakingActivity = _ref.stopSpeakingActivity,\n        webSpeechPonyfill = _ref.webSpeechPonyfill;\n\n    var _ref2 = webSpeechPonyfill || {},\n        speechSynthesis = _ref2.speechSynthesis,\n        SpeechSynthesisUtterance = _ref2.SpeechSynthesisUtterance;\n\n    return {\n      click: function click() {\n        if (dictateState === DictateState.WILL_START) {\n          stopSpeakingActivity();\n        } else if (dictateState === DictateState.DICTATING) {\n          stopDictate();\n          setSendBox(dictateInterims.join(' '));\n        } else {\n          stopSpeakingActivity();\n          startDictate();\n        }\n\n        primeSpeechSynthesis(speechSynthesis, SpeechSynthesisUtterance);\n      },\n      dictating: dictateState === DictateState.DICTATING,\n      disabled: disabled || dictateState === DictateState.STARTING && dictateState === DictateState.STOPPING,\n      language: language\n    };\n  }].concat(selectors));\n};\n\nexports.connectMicrophoneButton = connectMicrophoneButton;\n\nfunction useMicrophoneButtonClick() {\n  var _useSendBoxValue = useSendBoxValue(),\n      _useSendBoxValue2 = _slicedToArray(_useSendBoxValue, 2),\n      setSendBox = _useSendBoxValue2[1];\n\n  var _useShouldSpeakIncomi = useShouldSpeakIncomingActivity(),\n      _useShouldSpeakIncomi2 = _slicedToArray(_useShouldSpeakIncomi, 2),\n      setShouldSpeakIncomingActivity = _useShouldSpeakIncomi2[1];\n\n  var _useDictateInterims = useDictateInterims(),\n      _useDictateInterims2 = _slicedToArray(_useDictateInterims, 1),\n      dictateInterims = _useDictateInterims2[0];\n\n  var _useDictateState = useDictateState(),\n      _useDictateState2 = _slicedToArray(_useDictateState, 1),\n      dictateState = _useDictateState2[0];\n\n  var _useWebSpeechPonyfill = (0, _useWebSpeechPonyfill3.default)(),\n      _useWebSpeechPonyfill2 = _slicedToArray(_useWebSpeechPonyfill, 1),\n      webSpeechPonyfill = _useWebSpeechPonyfill2[0];\n\n  var startDictate = useStartDictate();\n  var stopDictate = useStopDictate();\n\n  var _ref3 = webSpeechPonyfill || {},\n      speechSynthesis = _ref3.speechSynthesis,\n      SpeechSynthesisUtterance = _ref3.SpeechSynthesisUtterance;\n\n  var _useState = (0, _react.useState)(function () {\n    return (0, _memoizeOne.default)(function (speechSynthesis, SpeechSynthesisUtterance) {\n      if (speechSynthesis && SpeechSynthesisUtterance) {\n        var utterance = new SpeechSynthesisUtterance('');\n\n        var _speechSynthesis$getV3 = speechSynthesis.getVoices();\n\n        var _speechSynthesis$getV4 = _slicedToArray(_speechSynthesis$getV3, 1);\n\n        utterance.voice = _speechSynthesis$getV4[0];\n        speechSynthesis.speak(utterance);\n      }\n    });\n  }),\n      _useState2 = _slicedToArray(_useState, 1),\n      primeSpeechSynthesis = _useState2[0]; // TODO: [P2] We should revisit this function later\n  //       The click() logic seems local to the component, but may not be generalized across all implementations.\n\n\n  return (0, _react.useCallback)(function () {\n    if (dictateState === DictateState.WILL_START) {\n      setShouldSpeakIncomingActivity(false);\n    } else if (dictateState === DictateState.DICTATING) {\n      stopDictate();\n      setSendBox(dictateInterims.join(' '));\n    } else {\n      setShouldSpeakIncomingActivity(false);\n      startDictate();\n    }\n\n    primeSpeechSynthesis(speechSynthesis, SpeechSynthesisUtterance);\n  }, [dictateInterims, dictateState, primeSpeechSynthesis, setSendBox, setShouldSpeakIncomingActivity, speechSynthesis, SpeechSynthesisUtterance, startDictate, stopDictate]);\n}\n\nfunction useMicrophoneButtonDisabled() {\n  var _useDictateAbortable = (0, _useDictateAbortable3.default)(),\n      _useDictateAbortable2 = _slicedToArray(_useDictateAbortable, 1),\n      abortable = _useDictateAbortable2[0];\n\n  var _useDictateState3 = useDictateState(),\n      _useDictateState4 = _slicedToArray(_useDictateState3, 1),\n      dictateState = _useDictateState4[0];\n\n  var _useDisabled = useDisabled(),\n      _useDisabled2 = _slicedToArray(_useDisabled, 1),\n      disabled = _useDisabled2[0];\n\n  return [disabled || dictateState === DictateState.STARTING || dictateState === DictateState.STOPPING || dictateState === DictateState.DICTATING && !abortable];\n}\n\nvar MicrophoneButton = function MicrophoneButton(_ref4) {\n  var className = _ref4.className;\n\n  var _useStyleSet = (0, _useStyleSet3.default)(),\n      _useStyleSet2 = _slicedToArray(_useStyleSet, 1),\n      microphoneButtonStyleSet = _useStyleSet2[0].microphoneButton;\n\n  var _useDictateState5 = useDictateState(),\n      _useDictateState6 = _slicedToArray(_useDictateState5, 1),\n      dictateState = _useDictateState6[0];\n\n  var _useMicrophoneButtonD = useMicrophoneButtonDisabled(),\n      _useMicrophoneButtonD2 = _slicedToArray(_useMicrophoneButtonD, 1),\n      disabled = _useMicrophoneButtonD2[0];\n\n  var click = useMicrophoneButtonClick();\n  var localize = useLocalizer();\n  var rootClassName = (0, _useStyleToEmotionObject.default)()(ROOT_STYLE) + '';\n  var dictating = dictateState === DictateState.DICTATING;\n  return /*#__PURE__*/_react.default.createElement(\"div\", {\n    \"aria-controls\": \"webchatSendBoxMicrophoneButton\",\n    className: (0, _classnames.default)('webchat__microphone-button', {\n      'webchat__microphone-button--dictating': dictating\n    }, microphoneButtonStyleSet + '', rootClassName, (className || '') + '')\n  }, /*#__PURE__*/_react.default.createElement(_IconButton.default, {\n    alt: localize('TEXT_INPUT_SPEAK_BUTTON_ALT'),\n    className: \"webchat__microphone-button__button\",\n    disabled: disabled,\n    onClick: click\n  }, /*#__PURE__*/_react.default.createElement(_MicrophoneIcon.default, {\n    className: \"webchat__microphone-button__icon\"\n  })), /*#__PURE__*/_react.default.createElement(\"div\", {\n    \"aria-live\": \"polite\",\n    className: \"sr-only\",\n    id: \"webchatSendBoxMicrophoneButton\",\n    role: \"status\"\n  }, localize(dictating ? 'SPEECH_INPUT_MICROPHONE_BUTTON_OPEN_ALT' : 'SPEECH_INPUT_MICROPHONE_BUTTON_CLOSE_ALT')));\n};\n\nMicrophoneButton.defaultProps = {\n  className: ''\n};\nMicrophoneButton.propTypes = {\n  className: _propTypes.default.string\n};\nvar _default = MicrophoneButton;\nexports.default = _default;","map":{"version":3,"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;AAGA;;AACA;;AACA;;AACA;;AACA;;AACA;;AAEA;;AACA;;AACA;;AACA;;AACA;;AACA;;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAEA,IAAQA,YAAR,GAAyBC,mCAAjBD,YAAR;AAEA,IACEE,kBADF,GASIC,8BARFD,kBADF;AAAA,IAEEE,eAFF,GASID,8BAPFC,eAFF;AAAA,IAGEC,WAHF,GASIF,8BANFE,WAHF;AAAA,IAIEC,YAJF,GASIH,8BALFG,YAJF;AAAA,IAKEC,eALF,GASIJ,8BAJFI,eALF;AAAA,IAMEC,8BANF,GASIL,8BAHFK,8BANF;AAAA,IAOEC,eAPF,GASIN,8BAFFM,eAPF;AAAA,IAQEC,cARF,GASIP,8BADFO,cARF;AAWA,IAAMC,UAAU,GAAG;AACjBC,SAAO,EAAE,MADQ;AAGjB;AAEA,kBAAgB;AACdC,SAAK,EAAE,aADO;AAEdC,UAAM,EAAE,CAFM;AAGdC,QAAI,EAAE,CAAC,KAHO;AAIdC,YAAQ,EAAE,QAJI;AAKdC,YAAQ,EAAE,UALI;AAMdC,OAAG,EAAE,CANS;AAOdC,cAAU,EAAE,QAPE;AAQdC,SAAK,EAAE;AARO;AALC,CAAnB;;AAiBA,IAAMC,uBAAuB,GAAG,SAA1BA,uBAA0B,GAAkB;AAChD,MAAMC,oBAAoB,GAAG,yBAAQ,UAACC,eAAD,EAAkBC,wBAAlB,EAA+C;AAClF,QAAID,eAAe,IAAIC,wBAAvB,EAAiD;AAC/C,UAAMC,SAAS,GAAG,IAAID,wBAAJ,CAA6B,EAA7B,CAAlB;;AAD+C,kCAG3BD,eAAe,CAACG,SAAhBH,EAH2B;;AAAA;;AAG9CE,eAAS,CAACE,KAAVF,GAH8CG,yBAG9CH;AACDF,qBAAe,CAACM,KAAhBN,CAAsBE,SAAtBF;AACD;AAN0B,IAA7B;;AADgD,oCAAdO,SAAc;AAAdA,aAAc,MAAdA,GAAcC,eAAdD;AAAc;;AAUhD,SAAOE,yCACL,gBAUM;AAAA,QATJC,QASI,QATJA,QASI;AAAA,QARJC,eAQI,QARJA,eAQI;AAAA,QAPJC,YAOI,QAPJA,YAOI;AAAA,QANJC,QAMI,QANJA,QAMI;AAAA,QALJC,UAKI,QALJA,UAKI;AAAA,QAJJC,YAII,QAJJA,YAII;AAAA,QAHJC,WAGI,QAHJA,WAGI;AAAA,QAFJC,oBAEI,QAFJA,oBAEI;AAAA,QADJC,iBACI,QADJA,iBACI;;AACJ,gBAAsDA,iBAAiB,IAAI,EAA3E;AAAA,QAAQlB,eAAR,SAAQA,eAAR;AAAA,QAAyBC,wBAAzB,SAAyBA,wBAAzB;;AAEA,WAAO;AACLkB,WAAK,EAAE,iBAAM;AACX,YAAIP,YAAY,KAAKnC,YAAY,CAAC2C,UAAlC,EAA8C;AAC5CH,8BAAoB;AADtB,eAEO,IAAIL,YAAY,KAAKnC,YAAY,CAAC4C,SAAlC,EAA6C;AAClDL,qBAAW;AACXF,oBAAU,CAACH,eAAe,CAACW,IAAhBX,CAAqB,GAArBA,CAAD,CAAVG;AAFK,eAGA;AACLG,8BAAoB;AACpBF,sBAAY;AACb;;AAEDhB,4BAAoB,CAACC,eAAD,EAAkBC,wBAAlB,CAApBF;AAZG;AAcLwB,eAAS,EAAEX,YAAY,KAAKnC,YAAY,CAAC4C,SAdpC;AAeLX,cAAQ,EAAEA,QAAQ,IAAKE,YAAY,KAAKnC,YAAY,CAAC+C,QAA9BZ,IAA0CA,YAAY,KAAKnC,YAAY,CAACgD,QAf1F;AAgBLZ,cAAQ,EAARA;AAhBK,KAAP;AAdG,YAiCFN,SAjCEE,EAAP;AAVF;;;;AA+CA,SAASiB,wBAAT,GAAgD;AAC9C,yBAAuB1C,eAAe,EAAtC;AAAA;AAAA,MAAS8B,UAAT;;AACA,8BAA2C7B,8BAA8B,EAAzE;AAAA;AAAA,MAAS0C,8BAAT;;AACA,4BAA0BhD,kBAAkB,EAA5C;AAAA;AAAA,MAAOgC,eAAP;;AACA,yBAAuB9B,eAAe,EAAtC;AAAA;AAAA,MAAO+B,YAAP;;AACA,8BAA4B,qCAA5B;AAAA;AAAA,MAAOM,iBAAP;;AACA,MAAMH,YAAY,GAAG7B,eAAe,EAApC;AACA,MAAM8B,WAAW,GAAG7B,cAAc,EAAlC;;AAEA,cAAsD+B,iBAAiB,IAAI,EAA3E;AAAA,MAAQlB,eAAR,SAAQA,eAAR;AAAA,MAAyBC,wBAAzB,SAAyBA,wBAAzB;;AAEA,kBAA+B,qBAAS;AAAA,WACtC,yBAAQ,UAACD,eAAD,EAAkBC,wBAAlB,EAA+C;AACrD,UAAID,eAAe,IAAIC,wBAAvB,EAAiD;AAC/C,YAAMC,SAAS,GAAG,IAAID,wBAAJ,CAA6B,EAA7B,CAAlB;;AAD+C,qCAG3BD,eAAe,CAACG,SAAhBH,EAH2B;;AAAA;;AAG9CE,iBAAS,CAACE,KAAVF,GAH8C0B,yBAG9C1B;AACDF,uBAAe,CAACM,KAAhBN,CAAsBE,SAAtBF;AACD;AANH,MADsC;AAAT,IAA/B;AAAA;AAAA,MAAOD,oBAAP,iBAX8C,CAsB9C;AACA;;;AACA,SAAO,wBAAY,YAAM;AACvB,QAAIa,YAAY,KAAKnC,YAAY,CAAC2C,UAAlC,EAA8C;AAC5CO,oCAA8B,CAAC,KAAD,CAA9BA;AADF,WAEO,IAAIf,YAAY,KAAKnC,YAAY,CAAC4C,SAAlC,EAA6C;AAClDL,iBAAW;AACXF,gBAAU,CAACH,eAAe,CAACW,IAAhBX,CAAqB,GAArBA,CAAD,CAAVG;AAFK,WAGA;AACLa,oCAA8B,CAAC,KAAD,CAA9BA;AACAZ,kBAAY;AACb;;AAEDhB,wBAAoB,CAACC,eAAD,EAAkBC,wBAAlB,CAApBF;AAXK,KAYJ,CACDY,eADC,EAEDC,YAFC,EAGDb,oBAHC,EAIDe,UAJC,EAKDa,8BALC,EAMD3B,eANC,EAODC,wBAPC,EAQDc,YARC,EASDC,WATC,CAZI,CAAP;AAuBD;;AAED,SAASa,2BAAT,GAAkD;AAChD,6BAAoB,oCAApB;AAAA;AAAA,MAAOC,SAAP;;AACA,0BAAuBjD,eAAe,EAAtC;AAAA;AAAA,MAAO+B,YAAP;;AACA,qBAAmB9B,WAAW,EAA9B;AAAA;AAAA,MAAO4B,QAAP;;AAEA,SAAO,CACLA,QAAQ,IACNE,YAAY,KAAKnC,YAAY,CAAC+C,QADhCd,IAEEE,YAAY,KAAKnC,YAAY,CAACgD,QAFhCf,IAGGE,YAAY,KAAKnC,YAAY,CAAC4C,SAA9BT,IAA2C,CAACkB,SAJ1C,CAAP;AAMD;;AAMD,IAAMC,gBAA2C,GAAG,SAA9CA,gBAA8C,QAAmB;AAAA,MAAhBC,SAAgB,SAAhBA,SAAgB;;AACrE,qBAAyD,4BAAzD;AAAA;AAAA,MAA2BC,wBAA3B,oBAASC,gBAAT;;AACA,0BAAuBrD,eAAe,EAAtC;AAAA;AAAA,MAAO+B,YAAP;;AACA,8BAAmBiB,2BAA2B,EAA9C;AAAA;AAAA,MAAOnB,QAAP;;AACA,MAAMS,KAAK,GAAGO,wBAAwB,EAAtC;AACA,MAAMS,QAAQ,GAAGpD,YAAY,EAA7B;AACA,MAAMqD,aAAa,GAAG,wCAA0BhD,UAA1B,IAAwC,EAA9D;AAEA,MAAMmC,SAAS,GAAGX,YAAY,KAAKnC,YAAY,CAAC4C,SAAhD;AAEA,sBACEgB;AACE,qBAAc,gCADhB;AAEEL,aAAS,EAAE,yBACT,4BADS,EAET;AAAE,+CAAyCT;AAA3C,KAFS,EAGTU,wBAAwB,GAAG,EAHlB,EAITG,aAJS,EAKT,CAACJ,SAAS,IAAI,EAAd,IAAoB,EALX;AAFb,kBAUEK,6BAACC,mBAAD;AACEC,OAAG,EAAEJ,QAAQ,CAAC,6BAAD,CADf;AAEEH,aAAS,EAAC,oCAFZ;AAGEtB,YAAQ,EAAEA,QAHZ;AAIE8B,WAAO,EAAErB;AAJX,kBAMEkB,6BAACI,uBAAD;AAAgBT,aAAS,EAAC;AAA1B,IANF,CAVF,eAkBEK;AAAK,iBAAU,QAAf;AAAwBL,aAAS,EAAC,SAAlC;AAA4CU,MAAE,EAAC,gCAA/C;AAAgFC,QAAI,EAAC;AAArF,KACGR,QAAQ,CAACZ,SAAS,GAAG,yCAAH,GAA+C,0CAAzD,CADX,CAlBF,CADF;AAVF;;AAoCAQ,gBAAgB,CAACa,YAAjBb,GAAgC;AAC9BC,WAAS,EAAE;AADmB,CAAhCD;AAIAA,gBAAgB,CAACc,SAAjBd,GAA6B;AAC3BC,WAAS,EAAEc,mBAAUC;AADM,CAA7BhB;eAIeA","names":["DictateState","Constants","useDictateInterims","hooks","useDictateState","useDisabled","useLocalizer","useSendBoxValue","useShouldSpeakIncomingActivity","useStartDictate","useStopDictate","ROOT_STYLE","display","color","height","left","overflow","position","top","whiteSpace","width","connectMicrophoneButton","primeSpeechSynthesis","speechSynthesis","SpeechSynthesisUtterance","utterance","getVoices","voice","_speechSynthesis$getV2","speak","selectors","arguments","connectToWebChat","disabled","dictateInterims","dictateState","language","setSendBox","startDictate","stopDictate","stopSpeakingActivity","webSpeechPonyfill","click","WILL_START","DICTATING","join","dictating","STARTING","STOPPING","useMicrophoneButtonClick","setShouldSpeakIncomingActivity","_speechSynthesis$getV4","useMicrophoneButtonDisabled","abortable","MicrophoneButton","className","microphoneButtonStyleSet","microphoneButton","localize","rootClassName","_react","_IconButton","alt","onClick","_MicrophoneIcon","id","role","defaultProps","propTypes","PropTypes","string"],"sources":["/Users/dylanmurray/Sweng-2022/front/node_modules/botframework-webchat-component/lib/src/SendBox/MicrophoneButton.tsx"],"sourcesContent":["// This is required for aria-controls.\n/* eslint react/forbid-dom-props: \"off\" */\n\nimport { Constants } from 'botframework-webchat-core';\nimport { hooks } from 'botframework-webchat-api';\nimport classNames from 'classnames';\nimport memoize from 'memoize-one';\nimport PropTypes from 'prop-types';\nimport React, { FC, useCallback, useState } from 'react';\n\nimport connectToWebChat from '../connectToWebChat';\nimport IconButton from './IconButton';\nimport MicrophoneIcon from './Assets/MicrophoneIcon';\nimport useDictateAbortable from '../hooks/useDictateAbortable';\nimport useStyleSet from '../hooks/useStyleSet';\nimport useStyleToEmotionObject from '../hooks/internal/useStyleToEmotionObject';\nimport useWebSpeechPonyfill from '../hooks/useWebSpeechPonyfill';\n\nconst { DictateState } = Constants;\n\nconst {\n  useDictateInterims,\n  useDictateState,\n  useDisabled,\n  useLocalizer,\n  useSendBoxValue,\n  useShouldSpeakIncomingActivity,\n  useStartDictate,\n  useStopDictate\n} = hooks;\n\nconst ROOT_STYLE = {\n  display: 'flex',\n\n  // .sr-only - This component is intended to be invisible to the visual Web Chat user, but read by the AT when using a screen reader\n\n  '& > .sr-only': {\n    color: 'transparent',\n    height: 1,\n    left: -10000,\n    overflow: 'hidden',\n    position: 'absolute',\n    top: 0,\n    whiteSpace: 'nowrap',\n    width: 1\n  }\n};\n\nconst connectMicrophoneButton = (...selectors) => {\n  const primeSpeechSynthesis = memoize((speechSynthesis, SpeechSynthesisUtterance) => {\n    if (speechSynthesis && SpeechSynthesisUtterance) {\n      const utterance = new SpeechSynthesisUtterance('');\n\n      [utterance.voice] = speechSynthesis.getVoices();\n      speechSynthesis.speak(utterance);\n    }\n  });\n\n  return connectToWebChat(\n    ({\n      disabled,\n      dictateInterims,\n      dictateState,\n      language,\n      setSendBox,\n      startDictate,\n      stopDictate,\n      stopSpeakingActivity,\n      webSpeechPonyfill\n    }) => {\n      const { speechSynthesis, SpeechSynthesisUtterance } = webSpeechPonyfill || {};\n\n      return {\n        click: () => {\n          if (dictateState === DictateState.WILL_START) {\n            stopSpeakingActivity();\n          } else if (dictateState === DictateState.DICTATING) {\n            stopDictate();\n            setSendBox(dictateInterims.join(' '));\n          } else {\n            stopSpeakingActivity();\n            startDictate();\n          }\n\n          primeSpeechSynthesis(speechSynthesis, SpeechSynthesisUtterance);\n        },\n        dictating: dictateState === DictateState.DICTATING,\n        disabled: disabled || (dictateState === DictateState.STARTING && dictateState === DictateState.STOPPING),\n        language\n      };\n    },\n    ...selectors\n  );\n};\n\nfunction useMicrophoneButtonClick(): () => void {\n  const [, setSendBox] = useSendBoxValue();\n  const [, setShouldSpeakIncomingActivity] = useShouldSpeakIncomingActivity();\n  const [dictateInterims] = useDictateInterims();\n  const [dictateState] = useDictateState();\n  const [webSpeechPonyfill] = useWebSpeechPonyfill();\n  const startDictate = useStartDictate();\n  const stopDictate = useStopDictate();\n\n  const { speechSynthesis, SpeechSynthesisUtterance } = webSpeechPonyfill || {};\n\n  const [primeSpeechSynthesis] = useState(() =>\n    memoize((speechSynthesis, SpeechSynthesisUtterance) => {\n      if (speechSynthesis && SpeechSynthesisUtterance) {\n        const utterance = new SpeechSynthesisUtterance('');\n\n        [utterance.voice] = speechSynthesis.getVoices();\n        speechSynthesis.speak(utterance);\n      }\n    })\n  );\n\n  // TODO: [P2] We should revisit this function later\n  //       The click() logic seems local to the component, but may not be generalized across all implementations.\n  return useCallback(() => {\n    if (dictateState === DictateState.WILL_START) {\n      setShouldSpeakIncomingActivity(false);\n    } else if (dictateState === DictateState.DICTATING) {\n      stopDictate();\n      setSendBox(dictateInterims.join(' '));\n    } else {\n      setShouldSpeakIncomingActivity(false);\n      startDictate();\n    }\n\n    primeSpeechSynthesis(speechSynthesis, SpeechSynthesisUtterance);\n  }, [\n    dictateInterims,\n    dictateState,\n    primeSpeechSynthesis,\n    setSendBox,\n    setShouldSpeakIncomingActivity,\n    speechSynthesis,\n    SpeechSynthesisUtterance,\n    startDictate,\n    stopDictate\n  ]);\n}\n\nfunction useMicrophoneButtonDisabled(): [boolean] {\n  const [abortable] = useDictateAbortable();\n  const [dictateState] = useDictateState();\n  const [disabled] = useDisabled();\n\n  return [\n    disabled ||\n      dictateState === DictateState.STARTING ||\n      dictateState === DictateState.STOPPING ||\n      (dictateState === DictateState.DICTATING && !abortable)\n  ];\n}\n\ntype MicrophoneButtonProps = {\n  className?: string;\n};\n\nconst MicrophoneButton: FC<MicrophoneButtonProps> = ({ className }) => {\n  const [{ microphoneButton: microphoneButtonStyleSet }] = useStyleSet();\n  const [dictateState] = useDictateState();\n  const [disabled] = useMicrophoneButtonDisabled();\n  const click = useMicrophoneButtonClick();\n  const localize = useLocalizer();\n  const rootClassName = useStyleToEmotionObject()(ROOT_STYLE) + '';\n\n  const dictating = dictateState === DictateState.DICTATING;\n\n  return (\n    <div\n      aria-controls=\"webchatSendBoxMicrophoneButton\"\n      className={classNames(\n        'webchat__microphone-button',\n        { 'webchat__microphone-button--dictating': dictating },\n        microphoneButtonStyleSet + '',\n        rootClassName,\n        (className || '') + ''\n      )}\n    >\n      <IconButton\n        alt={localize('TEXT_INPUT_SPEAK_BUTTON_ALT')}\n        className=\"webchat__microphone-button__button\"\n        disabled={disabled}\n        onClick={click}\n      >\n        <MicrophoneIcon className=\"webchat__microphone-button__icon\" />\n      </IconButton>\n      <div aria-live=\"polite\" className=\"sr-only\" id=\"webchatSendBoxMicrophoneButton\" role=\"status\">\n        {localize(dictating ? 'SPEECH_INPUT_MICROPHONE_BUTTON_OPEN_ALT' : 'SPEECH_INPUT_MICROPHONE_BUTTON_CLOSE_ALT')}\n      </div>\n    </div>\n  );\n};\n\nMicrophoneButton.defaultProps = {\n  className: ''\n};\n\nMicrophoneButton.propTypes = {\n  className: PropTypes.string\n};\n\nexport default MicrophoneButton;\n\nexport { connectMicrophoneButton, useMicrophoneButtonClick, useMicrophoneButtonDisabled };\n"]},"metadata":{},"sourceType":"script"}