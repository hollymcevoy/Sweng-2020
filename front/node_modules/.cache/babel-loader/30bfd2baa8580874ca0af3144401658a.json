{"ast":null,"code":"\"use strict\";\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\");\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = createMicrophoneAudioConfigAndAudioContext;\n\nvar _regenerator = _interopRequireDefault(require(\"@babel/runtime/regenerator\"));\n\nvar _slicedToArray2 = _interopRequireDefault(require(\"@babel/runtime/helpers/slicedToArray\"));\n\nvar _asyncToGenerator2 = _interopRequireDefault(require(\"@babel/runtime/helpers/asyncToGenerator\"));\n\nvar _Exports = require(\"microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports\");\n\nvar _Exports2 = require(\"microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports\");\n\nvar _bytesPerSample = _interopRequireDefault(require(\"./bytesPerSample\"));\n\nvar _createAudioConfig = _interopRequireDefault(require(\"./createAudioConfig\"));\n\nvar _createAudioContext = _interopRequireDefault(require(\"./createAudioContext\"));\n\nvar _getUserMedia = _interopRequireDefault(require(\"./getUserMedia\")); // This is how often we are flushing audio buffer to the network. Modify this value will affect latency.\n\n\nvar DEFAULT_BUFFER_DURATION_IN_MS = 100; // TODO: [P2] #3975 We should consider building our own PcmRecorder:\n//       - Use Audio Worklet via blob URL\n//       - Not hardcoding the sample rate or other values\n// PcmRecorder always downscale to 16000 Hz. We cannot use the dynamic value from MediaConstraints or MediaTrackSettings.\n\nvar PCM_RECORDER_HARDCODED_SETTINGS = Object.freeze({\n  channelCount: 1,\n  sampleRate: 16000,\n  sampleSize: 16\n});\nvar PCM_RECORDER_HARDCODED_FORMAT = Object.freeze({\n  bitsPerSample: PCM_RECORDER_HARDCODED_SETTINGS.sampleSize,\n  channels: PCM_RECORDER_HARDCODED_SETTINGS.channelCount,\n  samplesPerSec: PCM_RECORDER_HARDCODED_SETTINGS.sampleRate\n});\n\nfunction createMicrophoneAudioConfig(options) {\n  var audioConstraints = options.audioConstraints,\n      audioContext = options.audioContext,\n      debug = options.debug,\n      enableTelemetry = options.enableTelemetry,\n      pcmRecorderWorkletUrl = options.pcmRecorderWorkletUrl;\n  var bufferDurationInMS = options.bufferDurationInMS || DEFAULT_BUFFER_DURATION_IN_MS;\n  var pcmRecorder = new _Exports2.PcmRecorder();\n  pcmRecorderWorkletUrl && pcmRecorder.setWorkletUrl(pcmRecorderWorkletUrl);\n  return (0, _createAudioConfig.default)({\n    attach: function attach(audioNodeId) {\n      return (0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee() {\n        var mediaStream, _mediaStream$getAudio, _mediaStream$getAudio2, firstAudioTrack, outputStream;\n\n        return _regenerator.default.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                _context.next = 2;\n                return (0, _getUserMedia.default)({\n                  audio: audioConstraints,\n                  video: false\n                });\n\n              case 2:\n                mediaStream = _context.sent;\n                _mediaStream$getAudio = mediaStream.getAudioTracks(), _mediaStream$getAudio2 = (0, _slicedToArray2.default)(_mediaStream$getAudio, 1), firstAudioTrack = _mediaStream$getAudio2[0];\n\n                if (firstAudioTrack) {\n                  _context.next = 6;\n                  break;\n                }\n\n                throw new Error('No audio device is found.');\n\n              case 6:\n                outputStream = new _Exports.ChunkedArrayBufferStream( // Speech SDK quirks: PcmRecorder hardcoded sample rate of 16000 Hz.\n                (0, _bytesPerSample.default)(PCM_RECORDER_HARDCODED_SETTINGS) * ( // eslint-disable-next-line no-magic-numbers\n                (bufferDurationInMS || DEFAULT_BUFFER_DURATION_IN_MS) / 1000), audioNodeId);\n                pcmRecorder.record(audioContext, mediaStream, outputStream);\n                return _context.abrupt(\"return\", {\n                  audioStreamNode: {\n                    // Speech SDK quirks: In SDK's original MicAudioSource implementation, it call turnOff() during detach().\n                    //                    That means, it call turnOff(), then detach(), then turnOff() again. Seems redundant.\n                    //                    When using with Direct Line Speech, turnOff() is never called.\n                    detach: function detach() {\n                      // Speech SDK quirks: In SDK, it call outputStream.close() in turnOff() before outputStream.readEnded() in detach().\n                      //                    I think it make sense to call readEnded() before close().\n                      outputStream.readEnded();\n                      outputStream.close(); // PcmRecorder.releaseMediaResources() will disconnect/stop the MediaStream.\n                      // We cannot use MediaStream again after turned off.\n                      // PcmRecorder.releaseMediaResources() will disconnect/stop the MediaStream.\n                      // We cannot use MediaStream again after turned off.\n\n                      pcmRecorder.releaseMediaResources(audioContext); // MediaStream will become inactive after all tracks are removed.\n                      // MediaStream will become inactive after all tracks are removed.\n\n                      mediaStream.getTracks().forEach(function (track) {\n                        return mediaStream.removeTrack(track);\n                      }); // ESLint: \"return\" is required by TypeScript\n                      // eslint-disable-next-line no-useless-return\n                      // ESLint: \"return\" is required by TypeScript\n                      // eslint-disable-next-line no-useless-return\n\n                      return;\n                    },\n                    id: function id() {\n                      return audioNodeId;\n                    },\n                    read: function read() {\n                      return outputStream.read();\n                    }\n                  },\n                  deviceInfo: {\n                    manufacturer: 'Bot Framework Web Chat',\n                    model: enableTelemetry ? firstAudioTrack.label : '',\n                    type: enableTelemetry ? 'Microphones' : 'Unknown'\n                  },\n                  // Speech SDK quirks: PcmRecorder hardcoded sample rate of 16000 Hz.\n                  //                    We cannot obtain this number other than looking at their source code.\n                  //                    I.e. no getter property.\n                  // PcmRecorder always downscale to 16000 Hz. We cannot use the dynamic value from MediaConstraints or MediaTrackSettings.\n                  format: PCM_RECORDER_HARDCODED_FORMAT\n                });\n\n              case 9:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee);\n      }))();\n    },\n    debug: debug\n  });\n}\n\nfunction createMicrophoneAudioConfigAndAudioContext(_ref) {\n  var audioContext = _ref.audioContext,\n      audioInputDeviceId = _ref.audioInputDeviceId,\n      enableTelemetry = _ref.enableTelemetry; // Web Chat has an implementation of AudioConfig for microphone that would enable better support on Safari:\n  // - Maintain same instance of `AudioContext` across recognitions;\n  // - Resume suspended `AudioContext` on user gestures.\n\n  audioContext || (audioContext = (0, _createAudioContext.default)());\n  return {\n    audioConfig: createMicrophoneAudioConfig({\n      audioConstraints: audioInputDeviceId ? {\n        deviceId: audioInputDeviceId\n      } : true,\n      audioContext: audioContext,\n      enableTelemetry: enableTelemetry ? true : undefined\n    }),\n    audioContext: audioContext\n  };\n}","map":{"version":3,"mappings":";;;;;;;;;;;;;;;AAAA;;AACA;;AAGA;;AACA;;AACA;;AACA,sE,CAEA;;;AACA,IAAMA,6BAA6B,GAAG,GAAtC,C,CAEA;AACA;AACA;AACA;;AACA,IAAMC,+BAAmD,GAAGC,MAAM,CAACC,MAAPD,CAAc;AACxEE,cAAY,EAAE,CAD0D;AAExEC,YAAU,EAAE,KAF4D;AAGxEC,YAAU,EAAE;AAH4D,CAAdJ,CAA5D;AAMA,IAAMK,6BAAqC,GAAGL,MAAM,CAACC,MAAPD,CAAc;AAC1DM,eAAa,EAAEP,+BAA+B,CAACK,UADW;AAE1DG,UAAQ,EAAER,+BAA+B,CAACG,YAFgB;AAG1DM,eAAa,EAAET,+BAA+B,CAACI;AAHW,CAAdH,CAA9C;;AA0BA,SAASS,2BAAT,CAAqCC,OAArC,EAAiF;AAC/E,MAAQC,gBAAR,GAA0FD,OAA1F,CAAQC,gBAAR;AAAA,MAA0BC,YAA1B,GAA0FF,OAA1F,CAA0BE,YAA1B;AAAA,MAAwCC,KAAxC,GAA0FH,OAA1F,CAAwCG,KAAxC;AAAA,MAA+CC,eAA/C,GAA0FJ,OAA1F,CAA+CI,eAA/C;AAAA,MAAgEC,qBAAhE,GAA0FL,OAA1F,CAAgEK,qBAAhE;AACA,MAAMC,kBAAkB,GAAGN,OAAO,CAACM,kBAARN,IAA8BZ,6BAAzD;AAEA,MAAMmB,WAAW,GAAG,IAAIC,qBAAJ,EAApB;AAEAH,uBAAqB,IAAIE,WAAW,CAACE,aAAZF,CAA0BF,qBAA1BE,CAAzBF;AAEA,SAAO,gCAAkB;AACjBK,UADiB,kBACVC,WADU,EAKpB;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAAC;AAAA,uBAGyB,2BAAa;AAAEC,uBAAK,EAAEZ,gBAAT;AAA2Ba,uBAAK,EAAE;AAAlC,iBAAb,CAHzB;;AAAA;AAGKC,2BAHL,gBAGKA;AAHLC,wCAKyBD,WAAW,CAACE,cAAZF,EALzB,mFAKMG,eALN;;AAAA,oBAOIA,eAPJ;AAAAN;AAAA;AAAA;;AAAA,sBAQO,IAAIO,KAAJ,CAAU,2BAAV,CARP;;AAAA;AAWKC,4BAXL,GAWoB,IAAIC,iCAAJ,EACnB;AACA,6CAAehC,+BAAf,MACE;AACC,iBAACiB,kBAAkB,IAAIlB,6BAAvB,IAAwD,IAF3D,CAFmB,EAKnBuB,WALmB,CAAfS;AAQNb,2BAAW,CAACe,MAAZf,CAAmBL,YAAnBK,EAAiCQ,WAAjCR,EAA8Ca,YAA9Cb;AAnBC,iDAqBM;AACLgB,iCAAe,EAAE;AACf;AACA;AACA;AACAC,0BAAM,EAAE,kBAAqB;AAC3B;AACA;AACAJ,kCAAY,CAACK,SAAbL;AACAA,kCAAY,CAACM,KAAbN,GAJ2B,CAM3B;AACA;AADA;AACA;;AACAb,iCAAW,CAACoB,qBAAZpB,CAAkCL,YAAlCK,EAR2B,CAU3B;AAAA;;AACAQ,iCAAW,CAACa,SAAZb,GAAwBc,OAAxBd,CAAgC,iBAAK;AAAA,+BAAIA,WAAW,CAACe,WAAZf,CAAwBgB,KAAxBhB,CAAJ;AAArC,yBAX2B,CAa3B;AACA;AADA;AACA;;AACA;AAnBa;AAqBfiB,sBAAE,EAAE;AAAA,6BAAMrB,WAAN;AArBW;AAsBfsB,wBAAI,EAAE;AAAA,6BAAMb,YAAY,CAACa,IAAbb,EAAN;AAAA;AAtBS,mBADZ;AAyBLc,4BAAU,EAAE;AACVC,gCAAY,EAAE,wBADJ;AAEVC,yBAAK,EAAEhC,eAAe,GAAGc,eAAe,CAACmB,KAAnB,GAA2B,EAFvC;AAGVC,wBAAI,EAAElC,eAAe,GAAG,aAAH,GAAmB;AAH9B,mBAzBP;AA8BL;AACA;AACA;AACA;AACAmC,wBAAM,EAAE5C;AAlCH,iBArBN;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AALoB;AA+DvBQ,SAAK,EAALA;AA/DuB,GAAlB,CAAP;AAiED;;AAEc,SAASqC,0CAAT,OAQZ;AAAA,MAPDtC,YAOC,QAPDA,YAOC;AAAA,MANDuC,kBAMC,QANDA,kBAMC;AAAA,MALDrC,eAKC,QALDA,eAKC,EACD;AACA;AACA;;AACAF,cAAY,KAAKA,YAAY,GAAG,kCAApB,CAAZA;AAEA,SAAO;AACLwC,eAAW,EAAE3C,2BAA2B,CAAC;AACvCE,sBAAgB,EAAEwC,kBAAkB,GAAG;AAAEE,gBAAQ,EAAEF;AAAZ,OAAH,GAAsC,IADnC;AAEvCvC,kBAAY,EAAZA,YAFuC;AAGvCE,qBAAe,EAAEA,eAAe,GAAG,IAAH,GAAUwC;AAHH,KAAD,CADnC;AAML1C,gBAAY,EAAZA;AANK,GAAP;AAQD","names":["DEFAULT_BUFFER_DURATION_IN_MS","PCM_RECORDER_HARDCODED_SETTINGS","Object","freeze","channelCount","sampleRate","sampleSize","PCM_RECORDER_HARDCODED_FORMAT","bitsPerSample","channels","samplesPerSec","createMicrophoneAudioConfig","options","audioConstraints","audioContext","debug","enableTelemetry","pcmRecorderWorkletUrl","bufferDurationInMS","pcmRecorder","PcmRecorder","setWorkletUrl","attach","audioNodeId","_context","audio","video","mediaStream","_mediaStream$getAudio","getAudioTracks","firstAudioTrack","Error","outputStream","ChunkedArrayBufferStream","record","audioStreamNode","detach","readEnded","close","releaseMediaResources","getTracks","forEach","removeTrack","track","id","read","deviceInfo","manufacturer","model","label","type","format","createMicrophoneAudioConfigAndAudioContext","audioInputDeviceId","audioConfig","deviceId","undefined"],"sources":["/Users/dylanmurray/Sweng-2022/front/node_modules/botframework-webchat/lib/src/speech/createMicrophoneAudioConfigAndAudioContext.ts"],"sourcesContent":["import { ChunkedArrayBufferStream } from 'microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports';\nimport { PcmRecorder } from 'microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.browser/Exports';\n\nimport { AudioStreamNode, DeviceInfo, Format } from './CustomAudioInputStream';\nimport bytesPerSample from './bytesPerSample';\nimport createAudioConfig from './createAudioConfig';\nimport createAudioContext from './createAudioContext';\nimport getUserMedia from './getUserMedia';\n\n// This is how often we are flushing audio buffer to the network. Modify this value will affect latency.\nconst DEFAULT_BUFFER_DURATION_IN_MS = 100;\n\n// TODO: [P2] #3975 We should consider building our own PcmRecorder:\n//       - Use Audio Worklet via blob URL\n//       - Not hardcoding the sample rate or other values\n// PcmRecorder always downscale to 16000 Hz. We cannot use the dynamic value from MediaConstraints or MediaTrackSettings.\nconst PCM_RECORDER_HARDCODED_SETTINGS: MediaTrackSettings = Object.freeze({\n  channelCount: 1,\n  sampleRate: 16000,\n  sampleSize: 16\n});\n\nconst PCM_RECORDER_HARDCODED_FORMAT: Format = Object.freeze({\n  bitsPerSample: PCM_RECORDER_HARDCODED_SETTINGS.sampleSize,\n  channels: PCM_RECORDER_HARDCODED_SETTINGS.channelCount,\n  samplesPerSec: PCM_RECORDER_HARDCODED_SETTINGS.sampleRate\n});\n\ntype MicrophoneAudioInputStreamOptions = {\n  /** Specifies the constraints for selecting an audio device. */\n  audioConstraints?: true | MediaTrackConstraints;\n\n  /** Specifies the `AudioContext` to use. This object must be primed and ready to use. */\n  audioContext: AudioContext;\n\n  /** Specifies the buffering delay on how often to flush audio data to network. Increasing the value will increase audio latency. Default is 100 ms. */\n  bufferDurationInMS?: number;\n\n  /** Specifies whether to display diagnostic information. */\n  debug?: true;\n\n  /** Specifies if telemetry data should be sent. If not specified, telemetry data will NOT be sent. */\n  enableTelemetry?: true;\n\n  /** Specifies the `AudioWorklet` URL for `PcmRecorder`. If not specified, will use script processor on UI thread instead. */\n  pcmRecorderWorkletUrl?: string;\n};\n\nfunction createMicrophoneAudioConfig(options: MicrophoneAudioInputStreamOptions) {\n  const { audioConstraints, audioContext, debug, enableTelemetry, pcmRecorderWorkletUrl } = options;\n  const bufferDurationInMS = options.bufferDurationInMS || DEFAULT_BUFFER_DURATION_IN_MS;\n\n  const pcmRecorder = new PcmRecorder();\n\n  pcmRecorderWorkletUrl && pcmRecorder.setWorkletUrl(pcmRecorderWorkletUrl);\n\n  return createAudioConfig({\n    async attach(audioNodeId: string): Promise<{\n      audioStreamNode: AudioStreamNode;\n      deviceInfo: DeviceInfo;\n      format: Format;\n    }> {\n      // We need to get new MediaStream on every attach().\n      // This is because PcmRecorder.releaseMediaResources() disconnected/stopped them.\n      const mediaStream = await getUserMedia({ audio: audioConstraints, video: false });\n\n      const [firstAudioTrack] = mediaStream.getAudioTracks();\n\n      if (!firstAudioTrack) {\n        throw new Error('No audio device is found.');\n      }\n\n      const outputStream = new ChunkedArrayBufferStream(\n        // Speech SDK quirks: PcmRecorder hardcoded sample rate of 16000 Hz.\n        bytesPerSample(PCM_RECORDER_HARDCODED_SETTINGS) *\n          // eslint-disable-next-line no-magic-numbers\n          ((bufferDurationInMS || DEFAULT_BUFFER_DURATION_IN_MS) / 1000),\n        audioNodeId\n      );\n\n      pcmRecorder.record(audioContext, mediaStream, outputStream);\n\n      return {\n        audioStreamNode: {\n          // Speech SDK quirks: In SDK's original MicAudioSource implementation, it call turnOff() during detach().\n          //                    That means, it call turnOff(), then detach(), then turnOff() again. Seems redundant.\n          //                    When using with Direct Line Speech, turnOff() is never called.\n          detach: (): Promise<void> => {\n            // Speech SDK quirks: In SDK, it call outputStream.close() in turnOff() before outputStream.readEnded() in detach().\n            //                    I think it make sense to call readEnded() before close().\n            outputStream.readEnded();\n            outputStream.close();\n\n            // PcmRecorder.releaseMediaResources() will disconnect/stop the MediaStream.\n            // We cannot use MediaStream again after turned off.\n            pcmRecorder.releaseMediaResources(audioContext);\n\n            // MediaStream will become inactive after all tracks are removed.\n            mediaStream.getTracks().forEach(track => mediaStream.removeTrack(track));\n\n            // ESLint: \"return\" is required by TypeScript\n            // eslint-disable-next-line no-useless-return\n            return;\n          },\n          id: () => audioNodeId,\n          read: () => outputStream.read()\n        },\n        deviceInfo: {\n          manufacturer: 'Bot Framework Web Chat',\n          model: enableTelemetry ? firstAudioTrack.label : '',\n          type: enableTelemetry ? 'Microphones' : 'Unknown'\n        },\n        // Speech SDK quirks: PcmRecorder hardcoded sample rate of 16000 Hz.\n        //                    We cannot obtain this number other than looking at their source code.\n        //                    I.e. no getter property.\n        // PcmRecorder always downscale to 16000 Hz. We cannot use the dynamic value from MediaConstraints or MediaTrackSettings.\n        format: PCM_RECORDER_HARDCODED_FORMAT\n      };\n    },\n    debug\n  });\n}\n\nexport default function createMicrophoneAudioConfigAndAudioContext({\n  audioContext,\n  audioInputDeviceId,\n  enableTelemetry\n}: {\n  audioContext?: AudioContext;\n  audioInputDeviceId?: string;\n  enableTelemetry?: true;\n}) {\n  // Web Chat has an implementation of AudioConfig for microphone that would enable better support on Safari:\n  // - Maintain same instance of `AudioContext` across recognitions;\n  // - Resume suspended `AudioContext` on user gestures.\n  audioContext || (audioContext = createAudioContext());\n\n  return {\n    audioConfig: createMicrophoneAudioConfig({\n      audioConstraints: audioInputDeviceId ? { deviceId: audioInputDeviceId } : true,\n      audioContext,\n      enableTelemetry: enableTelemetry ? true : undefined\n    }),\n    audioContext\n  };\n}\n"]},"metadata":{},"sourceType":"script"}