{"ast":null,"code":"\"use strict\";\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\");\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _regenerator = _interopRequireDefault(require(\"@babel/runtime/regenerator\"));\n\nvar _slicedToArray2 = _interopRequireDefault(require(\"@babel/runtime/helpers/slicedToArray\"));\n\nvar _asyncToGenerator2 = _interopRequireDefault(require(\"@babel/runtime/helpers/asyncToGenerator\"));\n\nvar _classCallCheck2 = _interopRequireDefault(require(\"@babel/runtime/helpers/classCallCheck\"));\n\nvar _createClass2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createClass\"));\n\nvar _assertThisInitialized2 = _interopRequireDefault(require(\"@babel/runtime/helpers/assertThisInitialized\"));\n\nvar _inherits2 = _interopRequireDefault(require(\"@babel/runtime/helpers/inherits\"));\n\nvar _possibleConstructorReturn2 = _interopRequireDefault(require(\"@babel/runtime/helpers/possibleConstructorReturn\"));\n\nvar _getPrototypeOf2 = _interopRequireDefault(require(\"@babel/runtime/helpers/getPrototypeOf\"));\n\nvar _defineProperty2 = _interopRequireDefault(require(\"@babel/runtime/helpers/defineProperty\"));\n\nvar _microsoftCognitiveservicesSpeechSdk = require(\"microsoft-cognitiveservices-speech-sdk\");\n\nvar _Exports = require(\"microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports\");\n\nvar _AudioStreamFormat = require(\"microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat\");\n\nvar _Exports2 = require(\"microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports\");\n\nvar _botframeworkWebchatCore = require(\"botframework-webchat-core\");\n\nvar _uuid = require(\"uuid\");\n\nvar _pDeferEs = _interopRequireDefault(require(\"p-defer-es5\"));\n\nfunction _createSuper(Derived) {\n  var hasNativeReflectConstruct = _isNativeReflectConstruct();\n\n  return function _createSuperInternal() {\n    var Super = (0, _getPrototypeOf2.default)(Derived),\n        result;\n\n    if (hasNativeReflectConstruct) {\n      var NewTarget = (0, _getPrototypeOf2.default)(this).constructor;\n      result = Reflect.construct(Super, arguments, NewTarget);\n    } else {\n      result = Super.apply(this, arguments);\n    }\n\n    return (0, _possibleConstructorReturn2.default)(this, result);\n  };\n}\n\nfunction _isNativeReflectConstruct() {\n  if (typeof Reflect === \"undefined\" || !Reflect.construct) return false;\n  if (Reflect.construct.sham) return false;\n  if (typeof Proxy === \"function\") return true;\n\n  try {\n    Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {}));\n    return true;\n  } catch (e) {\n    return false;\n  }\n}\n\nvar SYMBOL_DEVICE_INFO_DEFERRED = Symbol('deviceInfoDeferred');\nvar SYMBOL_EVENTS = Symbol('events');\nvar SYMBOL_FORMAT_DEFERRED = Symbol('formatDeferred');\nvar SYMBOL_OPTIONS = Symbol('options'); // Speech SDK quirks: Only 2 lifecycle functions are actually used.\n//                    They are: attach() and turnOff().\n//                    Others are not used, including: blob(), close(), detach(), turnOn().\n\nvar CustomAudioInputStream = /*#__PURE__*/function (_AudioInputStream) {\n  (0, _inherits2.default)(CustomAudioInputStream, _AudioInputStream);\n\n  var _super = _createSuper(CustomAudioInputStream);\n\n  function CustomAudioInputStream() {\n    var _this;\n\n    var options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n    (0, _classCallCheck2.default)(this, CustomAudioInputStream);\n    _this = _super.call(this);\n    (0, _defineProperty2.default)((0, _assertThisInitialized2.default)(_this), SYMBOL_DEVICE_INFO_DEFERRED, void 0);\n    (0, _defineProperty2.default)((0, _assertThisInitialized2.default)(_this), SYMBOL_EVENTS, void 0);\n    (0, _defineProperty2.default)((0, _assertThisInitialized2.default)(_this), SYMBOL_FORMAT_DEFERRED, void 0);\n    (0, _defineProperty2.default)((0, _assertThisInitialized2.default)(_this), SYMBOL_OPTIONS, void 0);\n    var normalizedOptions = {\n      debug: options.debug || false,\n      id: options.id || (0, _uuid.v4)().replace(/\\x2D/g, '')\n    }; // False alarm: indexer is a constant of type Symbol.\n    // eslint-disable-next-line security/detect-object-injection\n\n    _this[SYMBOL_DEVICE_INFO_DEFERRED] = (0, _pDeferEs.default)(); // False alarm: indexer is a constant of type Symbol.\n    // eslint-disable-next-line security/detect-object-injection\n\n    _this[SYMBOL_EVENTS] = new _Exports.EventSource(); // False alarm: indexer is a constant of type Symbol.\n    // eslint-disable-next-line security/detect-object-injection\n\n    _this[SYMBOL_FORMAT_DEFERRED] = (0, _pDeferEs.default)(); // False alarm: indexer is a constant of type Symbol.\n    // eslint-disable-next-line security/detect-object-injection\n\n    _this[SYMBOL_OPTIONS] = normalizedOptions;\n    return _this;\n  }\n\n  (0, _createClass2.default)(CustomAudioInputStream, [{\n    key: \"events\",\n    get:\n    /** Gets the event source for listening to events. */\n    // ESLint: This code will only works in browsers other than IE11. Only works in ES5 is okay.\n    // @ts-ignore Accessors are only available when targeting ECMAScript 5 and higher.ts(1056)\n    function get() {\n      // False alarm: indexer is a constant of type Symbol.\n      // eslint-disable-next-line security/detect-object-injection\n      return this[SYMBOL_EVENTS];\n    }\n    /** Gets the format of the audio stream. */\n    // Speech SDK quirks: `AudioStreamFormatImpl` is internal implementation while `AudioStreamFormat` is public.\n    //                    It is weird to expose `AudioStreamFormatImpl` instead of `AudioStreamFormat`.\n    // Speech SDK quirks: It is weird to return a `Promise` in a property.\n    // Speech SDK quirks: In normal speech recognition, getter of \"format\" is called only after \"attach\".\n    //                    But in Direct Line Speech, it is called before \"attach\".\n    // ESLint: This code will only works in browsers other than IE11. Only works in ES5 is okay.\n    // @ts-ignore Accessors are only available when targeting ECMAScript 5 and higher.ts(1056)\n\n  }, {\n    key: \"format\",\n    get: function get() {\n      this.debug('Getting \"format\".'); // False alarm: indexer is a constant of type Symbol.\n      // eslint-disable-next-line security/detect-object-injection\n\n      return this[SYMBOL_FORMAT_DEFERRED].promise;\n    }\n    /** Gets the ID of this audio stream. */\n\n  }, {\n    key: \"id\",\n    value: function id() {\n      // False alarm: indexer is a constant of type Symbol.\n      // eslint-disable-next-line security/detect-object-injection\n      return this[SYMBOL_OPTIONS].id;\n    }\n    /** Emits an event. */\n    // Speech SDK quirks: In JavaScript, onXxx means \"listen to event XXX\".\n    //                    Instead, in Speech SDK, it means \"emit event XXX\".\n\n  }, {\n    key: \"onEvent\",\n    value: function onEvent(event) {\n      // False alarm: indexer is a constant of type Symbol.\n      // eslint-disable-next-line security/detect-object-injection\n      this[SYMBOL_EVENTS].onEvent(event);\n\n      _Exports.Events.instance.onEvent(event);\n    }\n    /** Emits an `AudioSourceInitializingEvent`. */\n\n  }, {\n    key: \"emitInitializing\",\n    value: function emitInitializing() {\n      this.debug('Emitting \"AudioSourceInitializingEvent\".');\n      this.onEvent(new _Exports.AudioSourceInitializingEvent(this.id()));\n    }\n    /** Emits an `AudioSourceReadyEvent`. */\n\n  }, {\n    key: \"emitReady\",\n    value: function emitReady() {\n      this.debug('Emitting \"AudioSourceReadyEvent\".');\n      this.onEvent(new _Exports.AudioSourceReadyEvent(this.id()));\n    }\n    /** Emits an `AudioSourceErrorEvent`. */\n    // Speech SDK quirks: Since \"turnOn\" is never called and \"turnOff\" does not work in Direct Line Speech, the \"source error\" event is not emitted at all.\n    //                    Instead, we only emit \"node error\" event.\n\n  }, {\n    key: \"emitError\",\n    value: function emitError(error) {\n      this.debug('Emitting \"AudioSourceErrorEvent\".', {\n        error: error\n      }); // Speech SDK quirks: \"error\" is a string, instead of object of type \"Error\".\n\n      this.onEvent(new _Exports.AudioSourceErrorEvent(this.id(), error.message));\n    }\n    /** Emits an `AudioStreamNodeAttachingEvent`. */\n\n  }, {\n    key: \"emitNodeAttaching\",\n    value: function emitNodeAttaching(audioNodeId) {\n      this.debug(\"Emitting \\\"AudioStreamNodeAttachingEvent\\\" for node \\\"\".concat(audioNodeId, \"\\\".\"));\n      this.onEvent(new _Exports.AudioStreamNodeAttachingEvent(this.id(), audioNodeId));\n    }\n    /** Emits an `AudioStreamNodeAttachedEvent`. */\n\n  }, {\n    key: \"emitNodeAttached\",\n    value: function emitNodeAttached(audioNodeId) {\n      this.debug(\"Emitting \\\"AudioStreamNodeAttachedEvent\\\" for node \\\"\".concat(audioNodeId, \"\\\".\"));\n      this.onEvent(new _Exports.AudioStreamNodeAttachedEvent(this.id(), audioNodeId));\n    }\n    /** Emits an `AudioStreamNodeErrorEvent`. */\n\n  }, {\n    key: \"emitNodeError\",\n    value: function emitNodeError(audioNodeId, error) {\n      this.debug(\"Emitting \\\"AudioStreamNodeErrorEvent\\\" for node \\\"\".concat(audioNodeId, \"\\\".\"), {\n        error: error\n      }); // Speech SDK quirks: \"error\" is a string, instead of object of type \"Error\".\n\n      this.onEvent(new _Exports.AudioStreamNodeErrorEvent(this.id(), audioNodeId, error.message));\n    }\n    /** Emits an `AudioStreamNodeDetachedEvent`. */\n\n  }, {\n    key: \"emitNodeDetached\",\n    value: function emitNodeDetached(audioNodeId) {\n      this.debug('Emitting \"AudioStreamNodeDetachedEvent\".');\n      this.onEvent(new _Exports.AudioStreamNodeDetachedEvent(this.id(), audioNodeId));\n    }\n    /** Emits an `AudioSourceOffEvent`. */\n\n  }, {\n    key: \"emitOff\",\n    value: function emitOff() {\n      this.debug('Emitting \"AudioSourceOffEvent\".');\n      this.onEvent(new _Exports.AudioSourceOffEvent(this.id()));\n    } // Speech SDK quirks: Although \"close\" is marked as abstract, it is never called in our observations.\n    // ESLint: Speech SDK requires this function, but we are not implementing it.\n\n  }, {\n    key: \"close\",\n    value: function close() {\n      this.debug('Callback for \"close\".');\n      throw new Error('Not implemented');\n    } // Speech SDK quirks: Although \"turnOn\" is implemented in Speech SDK Push/PullAudioInputStream, it is never called in our observations.\n\n  }, {\n    key: \"turnOn\",\n    value: function turnOn() {\n      this.debug('Callback for \"turnOn\".');\n      throw new Error('Not implemented');\n    } // Speech SDK quirks: Although \"detach\" is implemented in Speech SDK Push/PullAudioInputStream, it is never called in our observations.\n\n  }, {\n    key: \"detach\",\n    value: function detach() {\n      this.debug('Callback for \"detach\".');\n      throw new Error('Not implemented');\n    }\n    /** Log the message to console if `debug` is set to `true`. */\n\n  }, {\n    key: \"debug\",\n    value: function debug(message) {\n      var _console;\n\n      for (var _len = arguments.length, args = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n        args[_key - 1] = arguments[_key];\n      } // ESLint: For debugging, will only log when \"debug\" is set to \"true\".\n      // False alarm: indexer is a constant of type Symbol.\n      // eslint-disable-next-line no-console, security/detect-object-injection\n\n\n      this[SYMBOL_OPTIONS].debug && (_console = console).info.apply(_console, [\"CustomAudioInputStream: \".concat(message)].concat(args));\n    }\n    /** Implements this function. When called, it should start recording and return an `IAudioStreamNode`. */\n\n  }, {\n    key: \"attach\",\n    value:\n    /** Attaches the device by returning an audio node. */\n    function attach(audioNodeId) {\n      var _this2 = this;\n\n      this.debug(\"Callback for \\\"attach\\\" with \\\"\".concat(audioNodeId, \"\\\".\"));\n      this.emitNodeAttaching(audioNodeId);\n      return Promise.resolve().then( /*#__PURE__*/(0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee2() {\n        var _yield$_this2$perform, audioStreamNode, deviceInfo, format;\n\n        return _regenerator.default.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                _this2.emitInitializing();\n\n                _context2.prev = 1;\n                _context2.next = 4;\n                return _this2.performAttach(audioNodeId);\n\n              case 4:\n                _yield$_this2$perform = _context2.sent;\n                audioStreamNode = _yield$_this2$perform.audioStreamNode;\n                deviceInfo = _yield$_this2$perform.deviceInfo;\n                format = _yield$_this2$perform.format; // Although only getter of \"format\" is called before \"attach\" (in Direct Line Speech),\n                // we are handling both \"deviceInfo\" and \"format\" in similar way for uniformity.\n                // False alarm: indexer is a constant of type Symbol.\n                // eslint-disable-next-line security/detect-object-injection\n\n                _this2[SYMBOL_DEVICE_INFO_DEFERRED].resolve(deviceInfo); // False alarm: indexer is a constant of type Symbol.\n                // eslint-disable-next-line security/detect-object-injection\n\n\n                _this2[SYMBOL_FORMAT_DEFERRED].resolve(new _AudioStreamFormat.AudioStreamFormatImpl(format.samplesPerSec, format.bitsPerSample, format.channels));\n\n                _this2.emitReady();\n\n                _this2.emitNodeAttached(audioNodeId);\n\n                return _context2.abrupt(\"return\", {\n                  detach: function () {\n                    var _detach = (0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee() {\n                      return _regenerator.default.wrap(function _callee$(_context) {\n                        while (1) {\n                          switch (_context.prev = _context.next) {\n                            case 0:\n                              _this2.debug(\"Detaching audio node \\\"\".concat(audioNodeId, \"\\\".\"));\n\n                              _context.next = 3;\n                              return audioStreamNode.detach();\n\n                            case 3:\n                              // Speech SDK quirks: Since \"turnOff\" is not called in Direct Line Speech, we will emit event \"source off\" here instead.\n                              _this2.emitOff();\n\n                              _this2.emitNodeDetached(audioNodeId);\n\n                            case 5:\n                            case \"end\":\n                              return _context.stop();\n                          }\n                        }\n                      }, _callee);\n                    }));\n\n                    function detach() {\n                      return _detach.apply(this, arguments);\n                    }\n\n                    return detach;\n                  }(),\n                  id: function id() {\n                    return audioStreamNode.id();\n                  },\n                  read: function read() {\n                    _this2.debug('Reading');\n\n                    return audioStreamNode.read();\n                  }\n                });\n\n              case 15:\n                _context2.prev = 15;\n                _context2.t0 = _context2[\"catch\"](1);\n\n                _this2.emitNodeError(audioNodeId, _context2.t0);\n\n                throw _context2.t0;\n\n              case 19:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2, null, [[1, 15]]);\n      })));\n    }\n    /**\n     * Implements this function. When called, it should stop recording. This is called before the `IAudioStreamNode.detach` function.\n     *\n     * Note: when using with Direct Line Speech, this function is never called.\n     */\n    // ESLint: We are not implementing this function because it is not called by Direct Line Speech.\n    // eslint-disable-next-line class-methods-use-this\n\n  }, {\n    key: \"performTurnOff\",\n    value: function performTurnOff() {\n      // ESLint: \"return\" is required by TypeScript\n      // eslint-disable-next-line no-useless-return\n      return;\n    }\n    /** Turn off the audio device. This is called before detaching from the graph. */\n    // Speech SDK quirks: It is confused to have both \"turnOff\" and \"detach\". \"turnOff\" is called before \"detach\".\n    //                    Why don't we put all logics at \"detach\"?\n    // Speech SDK quirks: Direct Line Speech never call \"turnOff\". \"Source off\" event need to be emitted during \"detach\" instead.\n    //                    Also, custom implementation should be done at \"detach\" instead, such as ending and closing output streams.\n\n  }, {\n    key: \"turnOff\",\n    value: function () {\n      var _turnOff = (0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee3() {\n        return _regenerator.default.wrap(function _callee3$(_context3) {\n          while (1) {\n            switch (_context3.prev = _context3.next) {\n              case 0:\n                this.debug(\"Callback for \\\"turnOff\\\".\");\n                _context3.next = 3;\n                return this.performTurnOff();\n\n              case 3:\n              case \"end\":\n                return _context3.stop();\n            }\n          }\n        }, _callee3, this);\n      }));\n\n      function turnOff() {\n        return _turnOff.apply(this, arguments);\n      }\n\n      return turnOff;\n    }()\n    /** Gets the device information. */\n    // ESLint: This code will only works in browsers other than IE11. Only works in ES5 is okay.\n    // @ts-ignore Accessors are only available when targeting ECMAScript 5 and higher.ts(1056)\n\n  }, {\n    key: \"deviceInfo\",\n    get: function get() {\n      this.debug(\"Getting \\\"deviceInfo\\\".\"); // False alarm: indexer is a constant of type Symbol.\n      // eslint-disable-next-line security/detect-object-injection\n\n      return Promise.all([this[SYMBOL_DEVICE_INFO_DEFERRED].promise, this[SYMBOL_FORMAT_DEFERRED].promise]).then(function (_ref2) {\n        var _ref3 = (0, _slicedToArray2.default)(_ref2, 2),\n            _ref3$ = _ref3[0],\n            connectivity = _ref3$.connectivity,\n            manufacturer = _ref3$.manufacturer,\n            model = _ref3$.model,\n            type = _ref3$.type,\n            _ref3$2 = _ref3[1],\n            bitsPerSample = _ref3$2.bitsPerSample,\n            channels = _ref3$2.channels,\n            samplesPerSec = _ref3$2.samplesPerSec;\n\n        return {\n          bitspersample: bitsPerSample,\n          channelcount: channels,\n          connectivity: typeof connectivity === 'string' && !(0, _botframeworkWebchatCore.isForbiddenPropertyName)(connectivity) ? // Mitigated through denylisting.\n          // eslint-disable-next-line security/detect-object-injection\n          _Exports2.connectivity[connectivity] : connectivity || _Exports2.connectivity.Unknown,\n          manufacturer: manufacturer || '',\n          model: model || '',\n          samplerate: samplesPerSec,\n          // Mitigated through denylisting.\n          // eslint-disable-next-line security/detect-object-injection\n          type: typeof type === 'string' && !(0, _botframeworkWebchatCore.isForbiddenPropertyName)(type) ? _Exports2.type[type] : type || _Exports2.type.Unknown\n        };\n      });\n    }\n  }]);\n  return CustomAudioInputStream;\n}(_microsoftCognitiveservicesSpeechSdk.AudioInputStream);\n\nvar _default = CustomAudioInputStream;\nexports.default = _default;","map":{"version":3,"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;;AAEA;;AAcA;;AAEA;;AAMA;;AACA;;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAgDA,IAAMA,2BAA2B,GAAGC,MAAM,CAAC,oBAAD,CAA1C;AACA,IAAMC,aAAa,GAAGD,MAAM,CAAC,QAAD,CAA5B;AACA,IAAME,sBAAsB,GAAGF,MAAM,CAAC,gBAAD,CAArC;AACA,IAAMG,cAAc,GAAGH,MAAM,CAAC,SAAD,CAA7B,C,CAEA;AACA;AACA;;IACeI,sB;;;;;AACb,oCAAmC;AAAA;;AAAA,QAAvBC,OAAuB,uEAAJ,EAAI;AAAA;AACjCC;AADiC,+EAyBlCP,2BAzBkC;AAAA,+EA0BlCE,aA1BkC;AAAA,+EA2BlCC,sBA3BkC;AAAA,+EA4BlCC,cA5BkC;AAGjC,QAAMI,iBAAoC,GAAG;AAC3CC,WAAK,EAAEH,OAAO,CAACG,KAARH,IAAiB,KADmB;AAE3CI,QAAE,EAAEJ,OAAO,CAACI,EAARJ,IAAc,gBAAKK,OAAL,CAAa,OAAb,EAAoB,EAApB;AAFyB,KAA7C,CAHiC,CAQjC;AACA;;AACAJ,UAAKP,2BAAL,IAAoC,wBAApC,CAViC,CAYjC;AACA;;AACAO,UAAKL,aAAL,IAAsB,IAAIU,oBAAJ,EAAtB,CAdiC,CAgBjC;AACA;;AACAL,UAAKJ,sBAAL,IAA+B,wBAA/B,CAlBiC,CAoBjC;AACA;;AACAI,UAAKH,cAAL,IAAuBI,iBAAvB;AAtBiC;AAuBlC;;;;;AAOD;AACA;AACA;AACA,mBAA4C;AAC1C;AACA;AACA,aAAO,KAAKN,aAAL,CAAP;AACD;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;SACA,eAA6C;AAC3C,WAAKO,KAAL,CAAW,mBAAX,EAD2C,CAG3C;AACA;;AACA,aAAO,KAAKN,sBAAL,EAA6BU,OAApC;AACD;AAED;;;;WACA,cAAa;AACX;AACA;AACA,aAAO,KAAKT,cAAL,EAAqBM,EAA5B;AACD;AAED;AACA;AACA;;;;WACA,iBAAkBI,KAAlB,EAAiD;AAC/C;AACA;AACA,WAAKZ,aAAL,EAAoBa,OAApB,CAA4BD,KAA5B;;AACAE,sBAAOC,QAAPD,CAAgBD,OAAhBC,CAAwBF,KAAxBE;AACD;AAED;;;;WACA,4BAAmC;AACjC,WAAKP,KAAL,CAAW,0CAAX;AACA,WAAKM,OAAL,CAAa,IAAIG,qCAAJ,CAAiC,KAAKR,EAAL,EAAjC,CAAb;AACD;AAED;;;;WACA,qBAA4B;AAC1B,WAAKD,KAAL,CAAW,mCAAX;AACA,WAAKM,OAAL,CAAa,IAAII,8BAAJ,CAA0B,KAAKT,EAAL,EAA1B,CAAb;AACD;AAED;AACA;AACA;;;;WACA,mBAAoBU,KAApB,EAAwC;AACtC,WAAKX,KAAL,CAAW,mCAAX,EAAgD;AAAEW,aAAK,EAALA;AAAF,OAAhD,EADsC,CAGtC;;AACA,WAAKL,OAAL,CAAa,IAAIM,8BAAJ,CAA0B,KAAKX,EAAL,EAA1B,EAAqCU,KAAK,CAACE,OAA3C,CAAb;AACD;AAED;;;;WACA,2BAA4BC,WAA5B,EAAuD;AACrD,WAAKd,KAAL,iEAAiEc,WAAjE;AACA,WAAKR,OAAL,CAAa,IAAIS,sCAAJ,CAAkC,KAAKd,EAAL,EAAlC,EAA6Ca,WAA7C,CAAb;AACD;AAED;;;;WACA,0BAA2BA,WAA3B,EAAsD;AACpD,WAAKd,KAAL,gEAAgEc,WAAhE;AACA,WAAKR,OAAL,CAAa,IAAIU,qCAAJ,CAAiC,KAAKf,EAAL,EAAjC,EAA4Ca,WAA5C,CAAb;AACD;AAED;;;;WACA,uBAAwBA,WAAxB,EAA6CH,KAA7C,EAAiE;AAC/D,WAAKX,KAAL,6DAA6Dc,WAA7D,UAA8E;AAAEH,aAAK,EAALA;AAAF,OAA9E,EAD+D,CAG/D;;AACA,WAAKL,OAAL,CAAa,IAAIW,kCAAJ,CAA8B,KAAKhB,EAAL,EAA9B,EAAyCa,WAAzC,EAAsDH,KAAK,CAACE,OAA5D,CAAb;AACD;AAED;;;;WACA,0BAA2BC,WAA3B,EAAsD;AACpD,WAAKd,KAAL,CAAW,0CAAX;AACA,WAAKM,OAAL,CAAa,IAAIY,qCAAJ,CAAiC,KAAKjB,EAAL,EAAjC,EAA4Ca,WAA5C,CAAb;AACD;AAED;;;;WACA,mBAA0B;AACxB,WAAKd,KAAL,CAAW,iCAAX;AACA,WAAKM,OAAL,CAAa,IAAIa,4BAAJ,CAAwB,KAAKlB,EAAL,EAAxB,CAAb;MAGF;AACA;;;;WACA,iBAAc;AACZ,WAAKD,KAAL,CAAW,uBAAX;AAEA,YAAM,IAAIoB,KAAJ,CAAU,iBAAV,CAAN;MAGF;;;;WACA,kBAAe;AACb,WAAKpB,KAAL,CAAW,wBAAX;AAEA,YAAM,IAAIoB,KAAJ,CAAU,iBAAV,CAAN;MAGF;;;;WACA,kBAAe;AACb,WAAKpB,KAAL,CAAW,wBAAX;AAEA,YAAM,IAAIoB,KAAJ,CAAU,iBAAV,CAAN;AACD;AAED;;;;WACA,eAAcP,OAAd,EAAgC;AAAA;;AAAA,wCAANQ,IAAM;AAANA,YAAM,UAANA,GAAMC,eAAND;AAAM,QAC9B;AACA;AACA;;;AACA,WAAK1B,cAAL,EAAqBK,KAArB,IAA8B,qBAAQuB,IAAR,oDAAwCV,OAAxC,UAAsDQ,IAAtD,EAA9B;AACD;AAED;;;;;AAOA;AACA,oBAAOP,WAAP,EAAsD;AAAA;;AACpD,WAAKd,KAAL,0CAA0Cc,WAA1C;AAEA,WAAKU,iBAAL,CAAuBV,WAAvB;AAEA,aAAOW,OAAO,CAACC,OAARD,GAAkBE,IAAlBF,uFAAwC;AAAA;;AAAA;AAAA;AAAA;AAAA;AAC7CG,sBAAI,CAACC,gBAAL;;AAD6CC;AAAAA;AAAA,uBAIWF,MAAI,CAACG,aAAL,CAAmBjB,WAAnB,CAJX;;AAAA;AAAAkB;AAInCC,+BAJmC,yBAInCA;AAAiBC,0BAJkB,yBAIlBA;AAAYC,sBAJM,yBAINA,OAJM,CAM3C;AACA;AAEA;AACA;;AACAP,sBAAI,CAACrC,2BAAD,CAAJ,CAAkCmC,OAAlC,CAA0CQ,UAA1C,EAX2C,CAa3C;AACA;;;AACAN,sBAAI,CAAClC,sBAAD,CAAJ,CAA6BgC,OAA7B,CACE,IAAIU,wCAAJ,CAA0BD,MAAM,CAACE,aAAjC,EAAgDF,MAAM,CAACG,aAAvD,EAAsEH,MAAM,CAACI,QAA7E,CADF;;AAIAX,sBAAI,CAACY,SAAL;;AACAZ,sBAAI,CAACa,gBAAL,CAAsB3B,WAAtB;;AApB2C,kDAsBpC;AACL4B,wBAAM;AAAA,0GAAE;AAAA;AAAA;AAAA;AAAA;AACNd,oCAAI,CAAC5B,KAAL,kCAAoCc,WAApC;;AADM6B;AAAA,qCAGAV,eAAe,CAACS,MAAhBT,EAHA;;AAAA;AAKN;AACAL,oCAAI,CAACgB,OAAL;;AACAhB,oCAAI,CAACiB,gBAAL,CAAsB/B,WAAtB;;AAPM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAF;;AAAA;AAAA;AAAA;;AAAA;AAAA,qBADD;AAULb,oBAAE,EAAE;AAAA,2BAAMgC,eAAe,CAAChC,EAAhBgC,EAAN;AAVC;AAWLa,sBAAI,EAAE,gBAAM;AACVlB,0BAAI,CAAC5B,KAAL,CAAW,SAAX;;AAEA,2BAAOiC,eAAe,CAACa,IAAhBb,EAAP;AACD;AAfI,iBAtBoC;;AAAA;AAAAH;AAAAA;;AAwC3CF,sBAAI,CAACmB,aAAL,CAAmBjC,WAAnB;;AAxC2C;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAxC,UAAP;AA6CD;AAED;AACF;AACA;AACA;AACA;AAEE;AACA;;;;WACA,0BAA0C;AACxC;AACA;AACA;AACD;AAED;AACA;AACA;AACA;AACA;;;;;6FACA;AAAA;AAAA;AAAA;AAAA;AACE,qBAAKd,KAAL;AADFgD;AAAA,uBAGQ,KAAKC,cAAL,EAHR;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;;;;;;;AAMA;AACA;AACA;;;;SACA,eAAoD;AAClD,WAAKjD,KAAL,4BADkD,CAGlD;AACA;;AACA,aAAOyB,OAAO,CAACyB,GAARzB,CAAY,CAAC,KAAKlC,2BAAL,EAAkCa,OAAnC,EAA4C,KAAKV,sBAAL,EAA6BU,OAAzE,CAAZqB,EAA+FE,IAA/FF,CACL;AAAA;AAAA;AAAA,YAAI0B,YAAJ,UAAIA,YAAJ;AAAA,YAAkBC,YAAlB,UAAkBA,YAAlB;AAAA,YAAgCC,KAAhC,UAAgCA,KAAhC;AAAA,YAAuCC,IAAvC,UAAuCA,IAAvC;AAAA;AAAA,YAAiDhB,aAAjD,WAAiDA,aAAjD;AAAA,YAAgEC,QAAhE,WAAgEA,QAAhE;AAAA,YAA0EF,aAA1E,WAA0EA,aAA1E;;AAAA,eAAgG;AAC9FkB,uBAAa,EAAEjB,aAD+E;AAE9FkB,sBAAY,EAAEjB,QAFgF;AAG9FY,sBAAY,EACV,OAAOA,YAAP,KAAwB,QAAxB,IAAoC,CAAC,sDAAwBA,YAAxB,CAArC,GACI;AACA;AACAM,iCAAaN,YAAbM,CAHJ,GAIIN,YAAY,IAAIM,uBAAaC,OAR2D;AAS9FN,sBAAY,EAAEA,YAAY,IAAI,EATgE;AAU9FC,eAAK,EAAEA,KAAK,IAAI,EAV8E;AAW9FM,oBAAU,EAAEtB,aAXkF;AAY9F;AACA;AACAiB,cAAI,EAAE,OAAOA,IAAP,KAAgB,QAAhB,IAA4B,CAAC,sDAAwBA,IAAxB,CAA7B,GAA6DM,eAAKN,IAALM,CAA7D,GAA0EN,IAAI,IAAIM,eAAKF;AAdC,SAAhG;AADK,QAAP;AAkBD;;;EA5Q2CG,qD;;eA+Q/BjE","names":["SYMBOL_DEVICE_INFO_DEFERRED","Symbol","SYMBOL_EVENTS","SYMBOL_FORMAT_DEFERRED","SYMBOL_OPTIONS","CustomAudioInputStream","options","_this","normalizedOptions","debug","id","replace","EventSource","promise","event","onEvent","Events","instance","AudioSourceInitializingEvent","AudioSourceReadyEvent","error","AudioSourceErrorEvent","message","audioNodeId","AudioStreamNodeAttachingEvent","AudioStreamNodeAttachedEvent","AudioStreamNodeErrorEvent","AudioStreamNodeDetachedEvent","AudioSourceOffEvent","Error","args","arguments","info","emitNodeAttaching","Promise","resolve","then","_this2","emitInitializing","_context2","performAttach","_yield$_this2$perform","audioStreamNode","deviceInfo","format","AudioStreamFormatImpl","samplesPerSec","bitsPerSample","channels","emitReady","emitNodeAttached","detach","_context","emitOff","emitNodeDetached","read","emitNodeError","_context3","performTurnOff","all","connectivity","manufacturer","model","type","bitspersample","channelcount","Connectivity","Unknown","samplerate","Type","AudioInputStream"],"sources":["/Users/dylanmurray/Sweng-2022/front/node_modules/botframework-webchat/lib/src/speech/CustomAudioInputStream.ts"],"sourcesContent":["import { AudioInputStream } from 'microsoft-cognitiveservices-speech-sdk';\n\nimport {\n  AudioSourceErrorEvent,\n  AudioSourceEvent,\n  AudioSourceInitializingEvent,\n  AudioSourceOffEvent,\n  AudioSourceReadyEvent,\n  AudioStreamNodeAttachedEvent,\n  AudioStreamNodeAttachingEvent,\n  AudioStreamNodeDetachedEvent,\n  AudioStreamNodeErrorEvent,\n  Events,\n  EventSource\n} from 'microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common/Exports';\n\nimport { AudioStreamFormatImpl } from 'microsoft-cognitiveservices-speech-sdk/distrib/lib/src/sdk/Audio/AudioStreamFormat';\n\nimport {\n  connectivity as Connectivity,\n  ISpeechConfigAudioDevice,\n  type as Type\n} from 'microsoft-cognitiveservices-speech-sdk/distrib/lib/src/common.speech/Exports';\n\nimport { isForbiddenPropertyName } from 'botframework-webchat-core';\nimport { v4 } from 'uuid';\nimport createDeferred, { DeferredPromise } from 'p-defer-es5';\n\ntype AudioStreamNode = {\n  detach: () => Promise<void>;\n  id: () => string;\n  read: () => Promise<StreamChunk<ArrayBuffer>>;\n};\n\ntype DeviceInfo = {\n  connectivity?: Connectivity | 'Bluetooth' | 'Wired' | 'WiFi' | 'Cellular' | 'InBuilt' | 'Unknown';\n  manufacturer?: string;\n  model?: string;\n  type?:\n    | Type\n    | 'Phone'\n    | 'Speaker'\n    | 'Car'\n    | 'Headset'\n    | 'Thermostat'\n    | 'Microphones'\n    | 'Deskphone'\n    | 'RemoteControl'\n    | 'Unknown'\n    | 'File'\n    | 'Stream';\n};\n\ntype Format = {\n  bitsPerSample: number;\n  channels: number;\n  samplesPerSec: number;\n};\n\ntype NormalizedOptions = Required<Omit<Options, 'debug'>> & {\n  debug: boolean;\n};\n\ntype Options = {\n  debug?: true;\n  id?: string;\n};\n\ntype StreamChunk<T> = {\n  isEnd: boolean;\n  buffer: T;\n  timeReceived: number;\n};\n\nconst SYMBOL_DEVICE_INFO_DEFERRED = Symbol('deviceInfoDeferred');\nconst SYMBOL_EVENTS = Symbol('events');\nconst SYMBOL_FORMAT_DEFERRED = Symbol('formatDeferred');\nconst SYMBOL_OPTIONS = Symbol('options');\n\n// Speech SDK quirks: Only 2 lifecycle functions are actually used.\n//                    They are: attach() and turnOff().\n//                    Others are not used, including: blob(), close(), detach(), turnOn().\nabstract class CustomAudioInputStream extends AudioInputStream {\n  constructor(options: Options = {}) {\n    super();\n\n    const normalizedOptions: NormalizedOptions = {\n      debug: options.debug || false,\n      id: options.id || v4().replace(/-/gu, '')\n    };\n\n    // False alarm: indexer is a constant of type Symbol.\n    // eslint-disable-next-line security/detect-object-injection\n    this[SYMBOL_DEVICE_INFO_DEFERRED] = createDeferred<DeviceInfo>();\n\n    // False alarm: indexer is a constant of type Symbol.\n    // eslint-disable-next-line security/detect-object-injection\n    this[SYMBOL_EVENTS] = new EventSource<AudioSourceEvent>();\n\n    // False alarm: indexer is a constant of type Symbol.\n    // eslint-disable-next-line security/detect-object-injection\n    this[SYMBOL_FORMAT_DEFERRED] = createDeferred<AudioStreamFormatImpl>();\n\n    // False alarm: indexer is a constant of type Symbol.\n    // eslint-disable-next-line security/detect-object-injection\n    this[SYMBOL_OPTIONS] = normalizedOptions;\n  }\n\n  [SYMBOL_DEVICE_INFO_DEFERRED]: DeferredPromise<DeviceInfo>;\n  [SYMBOL_EVENTS]: EventSource<AudioSourceEvent>;\n  [SYMBOL_FORMAT_DEFERRED]: DeferredPromise<AudioStreamFormatImpl>;\n  [SYMBOL_OPTIONS]: NormalizedOptions;\n\n  /** Gets the event source for listening to events. */\n  // ESLint: This code will only works in browsers other than IE11. Only works in ES5 is okay.\n  // @ts-ignore Accessors are only available when targeting ECMAScript 5 and higher.ts(1056)\n  get events(): EventSource<AudioSourceEvent> {\n    // False alarm: indexer is a constant of type Symbol.\n    // eslint-disable-next-line security/detect-object-injection\n    return this[SYMBOL_EVENTS];\n  }\n\n  /** Gets the format of the audio stream. */\n  // Speech SDK quirks: `AudioStreamFormatImpl` is internal implementation while `AudioStreamFormat` is public.\n  //                    It is weird to expose `AudioStreamFormatImpl` instead of `AudioStreamFormat`.\n  // Speech SDK quirks: It is weird to return a `Promise` in a property.\n  // Speech SDK quirks: In normal speech recognition, getter of \"format\" is called only after \"attach\".\n  //                    But in Direct Line Speech, it is called before \"attach\".\n  // ESLint: This code will only works in browsers other than IE11. Only works in ES5 is okay.\n  // @ts-ignore Accessors are only available when targeting ECMAScript 5 and higher.ts(1056)\n  get format(): Promise<AudioStreamFormatImpl> {\n    this.debug('Getting \"format\".');\n\n    // False alarm: indexer is a constant of type Symbol.\n    // eslint-disable-next-line security/detect-object-injection\n    return this[SYMBOL_FORMAT_DEFERRED].promise;\n  }\n\n  /** Gets the ID of this audio stream. */\n  id(): string {\n    // False alarm: indexer is a constant of type Symbol.\n    // eslint-disable-next-line security/detect-object-injection\n    return this[SYMBOL_OPTIONS].id;\n  }\n\n  /** Emits an event. */\n  // Speech SDK quirks: In JavaScript, onXxx means \"listen to event XXX\".\n  //                    Instead, in Speech SDK, it means \"emit event XXX\".\n  protected onEvent(event: AudioSourceEvent): void {\n    // False alarm: indexer is a constant of type Symbol.\n    // eslint-disable-next-line security/detect-object-injection\n    this[SYMBOL_EVENTS].onEvent(event);\n    Events.instance.onEvent(event);\n  }\n\n  /** Emits an `AudioSourceInitializingEvent`. */\n  protected emitInitializing(): void {\n    this.debug('Emitting \"AudioSourceInitializingEvent\".');\n    this.onEvent(new AudioSourceInitializingEvent(this.id()));\n  }\n\n  /** Emits an `AudioSourceReadyEvent`. */\n  protected emitReady(): void {\n    this.debug('Emitting \"AudioSourceReadyEvent\".');\n    this.onEvent(new AudioSourceReadyEvent(this.id()));\n  }\n\n  /** Emits an `AudioSourceErrorEvent`. */\n  // Speech SDK quirks: Since \"turnOn\" is never called and \"turnOff\" does not work in Direct Line Speech, the \"source error\" event is not emitted at all.\n  //                    Instead, we only emit \"node error\" event.\n  protected emitError(error: Error): void {\n    this.debug('Emitting \"AudioSourceErrorEvent\".', { error });\n\n    // Speech SDK quirks: \"error\" is a string, instead of object of type \"Error\".\n    this.onEvent(new AudioSourceErrorEvent(this.id(), error.message));\n  }\n\n  /** Emits an `AudioStreamNodeAttachingEvent`. */\n  protected emitNodeAttaching(audioNodeId: string): void {\n    this.debug(`Emitting \"AudioStreamNodeAttachingEvent\" for node \"${audioNodeId}\".`);\n    this.onEvent(new AudioStreamNodeAttachingEvent(this.id(), audioNodeId));\n  }\n\n  /** Emits an `AudioStreamNodeAttachedEvent`. */\n  protected emitNodeAttached(audioNodeId: string): void {\n    this.debug(`Emitting \"AudioStreamNodeAttachedEvent\" for node \"${audioNodeId}\".`);\n    this.onEvent(new AudioStreamNodeAttachedEvent(this.id(), audioNodeId));\n  }\n\n  /** Emits an `AudioStreamNodeErrorEvent`. */\n  protected emitNodeError(audioNodeId: string, error: Error): void {\n    this.debug(`Emitting \"AudioStreamNodeErrorEvent\" for node \"${audioNodeId}\".`, { error });\n\n    // Speech SDK quirks: \"error\" is a string, instead of object of type \"Error\".\n    this.onEvent(new AudioStreamNodeErrorEvent(this.id(), audioNodeId, error.message));\n  }\n\n  /** Emits an `AudioStreamNodeDetachedEvent`. */\n  protected emitNodeDetached(audioNodeId: string): void {\n    this.debug('Emitting \"AudioStreamNodeDetachedEvent\".');\n    this.onEvent(new AudioStreamNodeDetachedEvent(this.id(), audioNodeId));\n  }\n\n  /** Emits an `AudioSourceOffEvent`. */\n  protected emitOff(): void {\n    this.debug('Emitting \"AudioSourceOffEvent\".');\n    this.onEvent(new AudioSourceOffEvent(this.id()));\n  }\n\n  // Speech SDK quirks: Although \"close\" is marked as abstract, it is never called in our observations.\n  // ESLint: Speech SDK requires this function, but we are not implementing it.\n  close(): void {\n    this.debug('Callback for \"close\".');\n\n    throw new Error('Not implemented');\n  }\n\n  // Speech SDK quirks: Although \"turnOn\" is implemented in Speech SDK Push/PullAudioInputStream, it is never called in our observations.\n  turnOn(): void {\n    this.debug('Callback for \"turnOn\".');\n\n    throw new Error('Not implemented');\n  }\n\n  // Speech SDK quirks: Although \"detach\" is implemented in Speech SDK Push/PullAudioInputStream, it is never called in our observations.\n  detach(): void {\n    this.debug('Callback for \"detach\".');\n\n    throw new Error('Not implemented');\n  }\n\n  /** Log the message to console if `debug` is set to `true`. */\n  private debug(message, ...args) {\n    // ESLint: For debugging, will only log when \"debug\" is set to \"true\".\n    // False alarm: indexer is a constant of type Symbol.\n    // eslint-disable-next-line no-console, security/detect-object-injection\n    this[SYMBOL_OPTIONS].debug && console.info(`CustomAudioInputStream: ${message}`, ...args);\n  }\n\n  /** Implements this function. When called, it should start recording and return an `IAudioStreamNode`. */\n  protected abstract performAttach(audioNodeId: string): Promise<{\n    audioStreamNode: AudioStreamNode;\n    deviceInfo: DeviceInfo;\n    format: Format;\n  }>;\n\n  /** Attaches the device by returning an audio node. */\n  attach(audioNodeId: string): Promise<AudioStreamNode> {\n    this.debug(`Callback for \"attach\" with \"${audioNodeId}\".`);\n\n    this.emitNodeAttaching(audioNodeId);\n\n    return Promise.resolve().then<AudioStreamNode>(async () => {\n      this.emitInitializing();\n\n      try {\n        const { audioStreamNode, deviceInfo, format } = await this.performAttach(audioNodeId);\n\n        // Although only getter of \"format\" is called before \"attach\" (in Direct Line Speech),\n        // we are handling both \"deviceInfo\" and \"format\" in similar way for uniformity.\n\n        // False alarm: indexer is a constant of type Symbol.\n        // eslint-disable-next-line security/detect-object-injection\n        this[SYMBOL_DEVICE_INFO_DEFERRED].resolve(deviceInfo);\n\n        // False alarm: indexer is a constant of type Symbol.\n        // eslint-disable-next-line security/detect-object-injection\n        this[SYMBOL_FORMAT_DEFERRED].resolve(\n          new AudioStreamFormatImpl(format.samplesPerSec, format.bitsPerSample, format.channels)\n        );\n\n        this.emitReady();\n        this.emitNodeAttached(audioNodeId);\n\n        return {\n          detach: async () => {\n            this.debug(`Detaching audio node \"${audioNodeId}\".`);\n\n            await audioStreamNode.detach();\n\n            // Speech SDK quirks: Since \"turnOff\" is not called in Direct Line Speech, we will emit event \"source off\" here instead.\n            this.emitOff();\n            this.emitNodeDetached(audioNodeId);\n          },\n          id: () => audioStreamNode.id(),\n          read: () => {\n            this.debug('Reading');\n\n            return audioStreamNode.read();\n          }\n        };\n      } catch (error) {\n        this.emitNodeError(audioNodeId, error);\n\n        throw error;\n      }\n    });\n  }\n\n  /**\n   * Implements this function. When called, it should stop recording. This is called before the `IAudioStreamNode.detach` function.\n   *\n   * Note: when using with Direct Line Speech, this function is never called.\n   */\n\n  // ESLint: We are not implementing this function because it is not called by Direct Line Speech.\n  // eslint-disable-next-line class-methods-use-this\n  protected performTurnOff(): Promise<void> {\n    // ESLint: \"return\" is required by TypeScript\n    // eslint-disable-next-line no-useless-return\n    return;\n  }\n\n  /** Turn off the audio device. This is called before detaching from the graph. */\n  // Speech SDK quirks: It is confused to have both \"turnOff\" and \"detach\". \"turnOff\" is called before \"detach\".\n  //                    Why don't we put all logics at \"detach\"?\n  // Speech SDK quirks: Direct Line Speech never call \"turnOff\". \"Source off\" event need to be emitted during \"detach\" instead.\n  //                    Also, custom implementation should be done at \"detach\" instead, such as ending and closing output streams.\n  async turnOff(): Promise<void> {\n    this.debug(`Callback for \"turnOff\".`);\n\n    await this.performTurnOff();\n  }\n\n  /** Gets the device information. */\n  // ESLint: This code will only works in browsers other than IE11. Only works in ES5 is okay.\n  // @ts-ignore Accessors are only available when targeting ECMAScript 5 and higher.ts(1056)\n  get deviceInfo(): Promise<ISpeechConfigAudioDevice> {\n    this.debug(`Getting \"deviceInfo\".`);\n\n    // False alarm: indexer is a constant of type Symbol.\n    // eslint-disable-next-line security/detect-object-injection\n    return Promise.all([this[SYMBOL_DEVICE_INFO_DEFERRED].promise, this[SYMBOL_FORMAT_DEFERRED].promise]).then(\n      ([{ connectivity, manufacturer, model, type }, { bitsPerSample, channels, samplesPerSec }]) => ({\n        bitspersample: bitsPerSample,\n        channelcount: channels,\n        connectivity:\n          typeof connectivity === 'string' && !isForbiddenPropertyName(connectivity)\n            ? // Mitigated through denylisting.\n              // eslint-disable-next-line security/detect-object-injection\n              Connectivity[connectivity]\n            : connectivity || Connectivity.Unknown,\n        manufacturer: manufacturer || '',\n        model: model || '',\n        samplerate: samplesPerSec,\n        // Mitigated through denylisting.\n        // eslint-disable-next-line security/detect-object-injection\n        type: typeof type === 'string' && !isForbiddenPropertyName(type) ? Type[type] : type || Type.Unknown\n      })\n    );\n  }\n}\n\nexport default CustomAudioInputStream;\n\nexport type { AudioStreamNode, DeviceInfo, Format, Options };\n"]},"metadata":{},"sourceType":"script"}