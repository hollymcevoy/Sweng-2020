{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = createMultiBufferingPlayer; // Currently, Web Chat uses a triple-buffer approach.\n\nvar NUM_BUFFER = 3;\n\nfunction zeroBuffer(buffer) {\n  var channels = buffer.numberOfChannels;\n\n  for (var channel = 0; channel < channels; channel++) {\n    var audioData = buffer.getChannelData(channel);\n    [].fill.call(audioData, 0);\n  }\n}\n\nfunction copyBuffer(buffer, multiChannelArray) {\n  var channels = buffer.numberOfChannels;\n\n  for (var channel = 0; channel < channels; channel++) {\n    var float32Array = multiChannelArray[+channel]; // Note that Safari does not support AudioBuffer.copyToChannel yet.\n\n    if (buffer.copyToChannel) {\n      buffer.copyToChannel(float32Array, channel);\n    } else {\n      var float32ArrayLength = float32Array.length;\n      var perChannelBuffer = buffer.getChannelData(channel);\n\n      for (var offset = 0; offset < float32ArrayLength; offset++) {\n        perChannelBuffer[+offset] = float32Array[+offset];\n      }\n    }\n  }\n} // This is a multi-buffering player. Users can keep pushing buffer to Web Chat.\n// The buffer, realized as BufferSource, is queued to AudioContext.\n// Data will be queued as quickly and frequently as possible.\n// Web Chat does not support progressive buffering (pushing a partial buffer) and there are currently no plans to implement.\n\n\nfunction createMultiBufferingPlayer(audioContext, _ref, numSamplePerBuffer) {\n  var channels = _ref.channels,\n      samplesPerSec = _ref.samplesPerSec;\n  var freeBuffers = new Array(NUM_BUFFER).fill().map(function () {\n    return audioContext.createBuffer(channels, numSamplePerBuffer, samplesPerSec);\n  });\n  var queuedBufferSources = [];\n  var nextSchedule;\n  var queue = [];\n\n  var playNext = function playNext() {\n    if (typeof nextSchedule !== 'number') {\n      nextSchedule = audioContext.currentTime;\n    }\n\n    var bufferSource = audioContext.createBufferSource();\n    var multiChannelArray = queue.shift();\n\n    if (typeof multiChannelArray === 'function') {\n      // If the queued item is a function, it is because the user called \"flush\".\n      // The \"flush\" function will callback when all queued buffers before the \"flush\" call have played.\n      multiChannelArray();\n    } else if (multiChannelArray) {\n      var nextBuffer = freeBuffers.shift(); // If all buffers are currently occupied, prepend the data back to the queue.\n      // When one of the buffers finish, it will call playNext() again to pick up items from the queue.\n\n      if (!nextBuffer) {\n        queue.unshift(multiChannelArray);\n        return;\n      }\n\n      zeroBuffer(nextBuffer);\n      copyBuffer(nextBuffer, multiChannelArray);\n      bufferSource.buffer = nextBuffer;\n      bufferSource.connect(audioContext.destination);\n      bufferSource.start(nextSchedule); // All BufferSource data that is currently queued will be stored at the AudioContext, via bufferSource.start().\n      // This is for cancelAll() to effectively cancel all BufferSource queued at the AudioContext.\n\n      queuedBufferSources.push(bufferSource);\n      nextSchedule += nextBuffer.duration;\n      bufferSource.addEventListener('ended', function () {\n        queuedBufferSources = queuedBufferSources.filter(function (target) {\n          return target !== bufferSource;\n        }); // Declare the buffer is free to pick up on the next iteration.\n\n        freeBuffers.push(nextBuffer);\n        playNext();\n      });\n    }\n  };\n\n  return {\n    cancelAll: function cancelAll() {\n      queue.splice(0); // Although all buffers are cleared, there are still some BufferSources queued at the AudioContext that need to be stopped.\n\n      queuedBufferSources.forEach(function (bufferSource) {\n        return bufferSource.stop();\n      });\n    },\n    flush: function flush() {\n      return new Promise(function (resolve) {\n        return queue.push(resolve);\n      });\n    },\n    push: function push(multiChannelArray) {\n      if (!multiChannelArray) {\n        throw new Error('multiChannelArray must not be falsy.');\n      }\n\n      queue.push(multiChannelArray);\n      playNext();\n    }\n  };\n}","map":{"version":3,"mappings":";;;;;8CAAA;;AACA,IAAMA,UAAU,GAAG,CAAnB;;AAEA,SAASC,UAAT,CAAoBC,MAApB,EAA4B;AAC1B,MAAMC,QAAQ,GAAGD,MAAM,CAACE,gBAAxB;;AAEA,OAAK,IAAIC,OAAO,GAAG,CAAnB,EAAsBA,OAAO,GAAGF,QAAhC,EAA0CE,OAAO,EAAjD,EAAqD;AACnD,QAAMC,SAAS,GAAGJ,MAAM,CAACK,cAAPL,CAAsBG,OAAtBH,CAAlB;AAEA,OAAGM,IAAH,CAAQC,IAAR,CAAaH,SAAb,EAAwB,CAAxB;AACD;AACF;;AAED,SAASI,UAAT,CAAoBR,MAApB,EAA4BS,iBAA5B,EAA+C;AAC7C,MAAMR,QAAQ,GAAGD,MAAM,CAACE,gBAAxB;;AAEA,OAAK,IAAIC,OAAO,GAAG,CAAnB,EAAsBA,OAAO,GAAGF,QAAhC,EAA0CE,OAAO,EAAjD,EAAqD;AACnD,QAAMO,YAAY,GAAGD,iBAAiB,CAAC,CAACN,OAAF,CAAtC,CADmD,CAGnD;;AACA,QAAIH,MAAM,CAACW,aAAX,EAA0B;AACxBX,YAAM,CAACW,aAAPX,CAAqBU,YAArBV,EAAmCG,OAAnCH;AADF,WAEO;AACL,UAAgBY,kBAAhB,GAAuCF,YAAvC,CAAQG,MAAR;AACA,UAAMC,gBAAgB,GAAGd,MAAM,CAACK,cAAPL,CAAsBG,OAAtBH,CAAzB;;AAEA,WAAK,IAAIe,MAAM,GAAG,CAAlB,EAAqBA,MAAM,GAAGH,kBAA9B,EAAkDG,MAAM,EAAxD,EAA4D;AAC1DD,wBAAgB,CAAC,CAACC,MAAF,CAAhBD,GAA4BJ,YAAY,CAAC,CAACK,MAAF,CAAxCD;AACD;AACF;AACF;EAGH;AACA;AACA;AACA;;;AAEe,SAASE,0BAAT,CAAoCC,YAApC,QAA+EC,kBAA/E,EAAmG;AAAA,MAA/CjB,QAA+C,QAA/CA,QAA+C;AAAA,MAArCkB,aAAqC,QAArCA,aAAqC;AAChH,MAAMC,WAAW,GAAG,IAAIC,KAAJ,CAAUvB,UAAV,EACjBQ,IADiB,GAEjBgB,GAFiB,CAEb;AAAA,WAAML,YAAY,CAACM,YAAbN,CAA0BhB,QAA1BgB,EAAoCC,kBAApCD,EAAwDE,aAAxDF,CAAN;AAFa,IAApB;AAGA,MAAIO,mBAAmB,GAAG,EAA1B;AACA,MAAIC,YAAJ;AAEA,MAAMC,KAAK,GAAG,EAAd;;AAEA,MAAMC,QAAQ,GAAG,SAAXA,QAAW,GAAM;AACrB,QAAI,OAAOF,YAAP,KAAwB,QAA5B,EAAsC;AACpCA,kBAAY,GAAGR,YAAY,CAACW,WAA5BH;AACD;;AAED,QAAMI,YAAY,GAAGZ,YAAY,CAACa,kBAAbb,EAArB;AACA,QAAMR,iBAAiB,GAAGiB,KAAK,CAACK,KAANL,EAA1B;;AAEA,QAAI,OAAOjB,iBAAP,KAA6B,UAAjC,EAA6C;AAC3C;AACA;AACAA,uBAAiB;AAHnB,WAIO,IAAIA,iBAAJ,EAAuB;AAC5B,UAAMuB,UAAU,GAAGZ,WAAW,CAACW,KAAZX,EAAnB,CAD4B,CAG5B;AACA;;AACA,UAAI,CAACY,UAAL,EAAiB;AACfN,aAAK,CAACO,OAANP,CAAcjB,iBAAdiB;AAEA;AACD;;AAED3B,gBAAU,CAACiC,UAAD,CAAVjC;AACAS,gBAAU,CAACwB,UAAD,EAAavB,iBAAb,CAAVD;AAEAqB,kBAAY,CAAC7B,MAAb6B,GAAsBG,UAAtBH;AACAA,kBAAY,CAACK,OAAbL,CAAqBZ,YAAY,CAACkB,WAAlCN;AACAA,kBAAY,CAACO,KAAbP,CAAmBJ,YAAnBI,EAhB4B,CAkB5B;AACA;;AACAL,yBAAmB,CAACa,IAApBb,CAAyBK,YAAzBL;AAEAC,kBAAY,IAAIO,UAAU,CAACM,QAA3Bb;AAEAI,kBAAY,CAACU,gBAAbV,CAA8B,OAA9BA,EAAuC,YAAM;AAC3CL,2BAAmB,GAAGA,mBAAmB,CAACgB,MAApBhB,CAA2B,kBAAM;AAAA,iBAAIiB,MAAM,KAAKZ,YAAf;AAAjC,UAAtBL,CAD2C,CAG3C;;AACAJ,mBAAW,CAACiB,IAAZjB,CAAiBY,UAAjBZ;AACAO,gBAAQ;AALV;AAOD;AA3CH;;AA8CA,SAAO;AACLe,aAAS,EAAE,qBAAM;AACfhB,WAAK,CAACiB,MAANjB,CAAa,CAAbA,EADe,CAGf;;AACAF,yBAAmB,CAACoB,OAApBpB,CAA4B,wBAAY;AAAA,eAAIK,YAAY,CAACgB,IAAbhB,EAAJ;AAAxC;AALG;AAOLiB,SAAK,EAAE;AAAA,aAAM,IAAIC,OAAJ,CAAY,mBAAO;AAAA,eAAIrB,KAAK,CAACW,IAANX,CAAWsB,OAAXtB,CAAJ;AAAnB,QAAN;AAPF;AAQLW,QAAI,EAAE,iCAAqB;AACzB,UAAI,CAAC5B,iBAAL,EAAwB;AACtB,cAAM,IAAIwC,KAAJ,CAAU,sCAAV,CAAN;AACD;;AAEDvB,WAAK,CAACW,IAANX,CAAWjB,iBAAXiB;AAEAC,cAAQ;AACT;AAhBI,GAAP;AAkBD","names":["NUM_BUFFER","zeroBuffer","buffer","channels","numberOfChannels","channel","audioData","getChannelData","fill","call","copyBuffer","multiChannelArray","float32Array","copyToChannel","float32ArrayLength","length","perChannelBuffer","offset","createMultiBufferingPlayer","audioContext","numSamplePerBuffer","samplesPerSec","freeBuffers","Array","map","createBuffer","queuedBufferSources","nextSchedule","queue","playNext","currentTime","bufferSource","createBufferSource","shift","nextBuffer","unshift","connect","destination","start","push","duration","addEventListener","filter","target","cancelAll","splice","forEach","stop","flush","Promise","resolve","Error"],"sources":["/Users/dylanmurray/Sweng-2022/front/node_modules/botframework-directlinespeech-sdk/lib/src/createMultiBufferingPlayer.js"],"sourcesContent":["// Currently, Web Chat uses a triple-buffer approach.\nconst NUM_BUFFER = 3;\n\nfunction zeroBuffer(buffer) {\n  const channels = buffer.numberOfChannels;\n\n  for (let channel = 0; channel < channels; channel++) {\n    const audioData = buffer.getChannelData(channel);\n\n    [].fill.call(audioData, 0);\n  }\n}\n\nfunction copyBuffer(buffer, multiChannelArray) {\n  const channels = buffer.numberOfChannels;\n\n  for (let channel = 0; channel < channels; channel++) {\n    const float32Array = multiChannelArray[+channel];\n\n    // Note that Safari does not support AudioBuffer.copyToChannel yet.\n    if (buffer.copyToChannel) {\n      buffer.copyToChannel(float32Array, channel);\n    } else {\n      const { length: float32ArrayLength } = float32Array;\n      const perChannelBuffer = buffer.getChannelData(channel);\n\n      for (let offset = 0; offset < float32ArrayLength; offset++) {\n        perChannelBuffer[+offset] = float32Array[+offset];\n      }\n    }\n  }\n}\n\n// This is a multi-buffering player. Users can keep pushing buffer to Web Chat.\n// The buffer, realized as BufferSource, is queued to AudioContext.\n// Data will be queued as quickly and frequently as possible.\n// Web Chat does not support progressive buffering (pushing a partial buffer) and there are currently no plans to implement.\n\nexport default function createMultiBufferingPlayer(audioContext, { channels, samplesPerSec }, numSamplePerBuffer) {\n  const freeBuffers = new Array(NUM_BUFFER)\n    .fill()\n    .map(() => audioContext.createBuffer(channels, numSamplePerBuffer, samplesPerSec));\n  let queuedBufferSources = [];\n  let nextSchedule;\n\n  const queue = [];\n\n  const playNext = () => {\n    if (typeof nextSchedule !== 'number') {\n      nextSchedule = audioContext.currentTime;\n    }\n\n    const bufferSource = audioContext.createBufferSource();\n    const multiChannelArray = queue.shift();\n\n    if (typeof multiChannelArray === 'function') {\n      // If the queued item is a function, it is because the user called \"flush\".\n      // The \"flush\" function will callback when all queued buffers before the \"flush\" call have played.\n      multiChannelArray();\n    } else if (multiChannelArray) {\n      const nextBuffer = freeBuffers.shift();\n\n      // If all buffers are currently occupied, prepend the data back to the queue.\n      // When one of the buffers finish, it will call playNext() again to pick up items from the queue.\n      if (!nextBuffer) {\n        queue.unshift(multiChannelArray);\n\n        return;\n      }\n\n      zeroBuffer(nextBuffer);\n      copyBuffer(nextBuffer, multiChannelArray);\n\n      bufferSource.buffer = nextBuffer;\n      bufferSource.connect(audioContext.destination);\n      bufferSource.start(nextSchedule);\n\n      // All BufferSource data that is currently queued will be stored at the AudioContext, via bufferSource.start().\n      // This is for cancelAll() to effectively cancel all BufferSource queued at the AudioContext.\n      queuedBufferSources.push(bufferSource);\n\n      nextSchedule += nextBuffer.duration;\n\n      bufferSource.addEventListener('ended', () => {\n        queuedBufferSources = queuedBufferSources.filter(target => target !== bufferSource);\n\n        // Declare the buffer is free to pick up on the next iteration.\n        freeBuffers.push(nextBuffer);\n        playNext();\n      });\n    }\n  };\n\n  return {\n    cancelAll: () => {\n      queue.splice(0);\n\n      // Although all buffers are cleared, there are still some BufferSources queued at the AudioContext that need to be stopped.\n      queuedBufferSources.forEach(bufferSource => bufferSource.stop());\n    },\n    flush: () => new Promise(resolve => queue.push(resolve)),\n    push: multiChannelArray => {\n      if (!multiChannelArray) {\n        throw new Error('multiChannelArray must not be falsy.');\n      }\n\n      queue.push(multiChannelArray);\n\n      playNext();\n    }\n  };\n}\n"]},"metadata":{},"sourceType":"script"}