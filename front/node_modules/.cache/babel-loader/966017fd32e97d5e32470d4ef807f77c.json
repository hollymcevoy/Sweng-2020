{"ast":null,"code":"\"use strict\";\n\nfunction _typeof(obj) {\n  \"@babel/helpers - typeof\";\n\n  if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") {\n    _typeof = function _typeof(obj) {\n      return typeof obj;\n    };\n  } else {\n    _typeof = function _typeof(obj) {\n      return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj;\n    };\n  }\n\n  return _typeof(obj);\n}\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = exports.connectSpeakActivity = void 0;\n\nvar _botframeworkWebchatApi = require(\"botframework-webchat-api\");\n\nvar _propTypes = _interopRequireDefault(require(\"prop-types\"));\n\nvar _react = _interopRequireWildcard(require(\"react\"));\n\nvar _reactSay = _interopRequireWildcard(require(\"react-say\"));\n\nvar _connectToWebChat = _interopRequireDefault(require(\"../connectToWebChat\"));\n\nvar _SayAlt = _interopRequireDefault(require(\"./SayAlt\"));\n\nfunction _getRequireWildcardCache(nodeInterop) {\n  if (typeof WeakMap !== \"function\") return null;\n  var cacheBabelInterop = new WeakMap();\n  var cacheNodeInterop = new WeakMap();\n  return (_getRequireWildcardCache = function _getRequireWildcardCache(nodeInterop) {\n    return nodeInterop ? cacheNodeInterop : cacheBabelInterop;\n  })(nodeInterop);\n}\n\nfunction _interopRequireWildcard(obj, nodeInterop) {\n  if (!nodeInterop && obj && obj.__esModule) {\n    return obj;\n  }\n\n  if (obj === null || _typeof(obj) !== \"object\" && typeof obj !== \"function\") {\n    return {\n      default: obj\n    };\n  }\n\n  var cache = _getRequireWildcardCache(nodeInterop);\n\n  if (cache && cache.has(obj)) {\n    return cache.get(obj);\n  }\n\n  var newObj = {};\n  var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor;\n\n  for (var key in obj) {\n    if (key !== \"default\" && Object.prototype.hasOwnProperty.call(obj, key)) {\n      var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null;\n\n      if (desc && (desc.get || desc.set)) {\n        Object.defineProperty(newObj, key, desc);\n      } else {\n        newObj[key] = obj[key];\n      }\n    }\n  }\n\n  newObj.default = obj;\n\n  if (cache) {\n    cache.set(obj, newObj);\n  }\n\n  return newObj;\n}\n\nfunction _interopRequireDefault(obj) {\n  return obj && obj.__esModule ? obj : {\n    default: obj\n  };\n}\n\nfunction _toConsumableArray(arr) {\n  return _arrayWithoutHoles(arr) || _iterableToArray(arr) || _unsupportedIterableToArray(arr) || _nonIterableSpread();\n}\n\nfunction _nonIterableSpread() {\n  throw new TypeError(\"Invalid attempt to spread non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n}\n\nfunction _iterableToArray(iter) {\n  if (typeof Symbol !== \"undefined\" && iter[Symbol.iterator] != null || iter[\"@@iterator\"] != null) return Array.from(iter);\n}\n\nfunction _arrayWithoutHoles(arr) {\n  if (Array.isArray(arr)) return _arrayLikeToArray(arr);\n}\n\nfunction _slicedToArray(arr, i) {\n  return _arrayWithHoles(arr) || _iterableToArrayLimit(arr, i) || _unsupportedIterableToArray(arr, i) || _nonIterableRest();\n}\n\nfunction _nonIterableRest() {\n  throw new TypeError(\"Invalid attempt to destructure non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n}\n\nfunction _unsupportedIterableToArray(o, minLen) {\n  if (!o) return;\n  if (typeof o === \"string\") return _arrayLikeToArray(o, minLen);\n  var n = Object.prototype.toString.call(o).slice(8, -1);\n  if (n === \"Object\" && o.constructor) n = o.constructor.name;\n  if (n === \"Map\" || n === \"Set\") return Array.from(o);\n  if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen);\n}\n\nfunction _arrayLikeToArray(arr, len) {\n  if (len == null || len > arr.length) len = arr.length;\n\n  for (var i = 0, arr2 = new Array(len); i < len; i++) {\n    arr2[i] = arr[i];\n  }\n\n  return arr2;\n}\n\nfunction _iterableToArrayLimit(arr, i) {\n  var _i = arr == null ? null : typeof Symbol !== \"undefined\" && arr[Symbol.iterator] || arr[\"@@iterator\"];\n\n  if (_i == null) return;\n  var _arr = [];\n  var _n = true;\n  var _d = false;\n\n  var _s, _e;\n\n  try {\n    for (_i = _i.call(arr); !(_n = (_s = _i.next()).done); _n = true) {\n      _arr.push(_s.value);\n\n      if (i && _arr.length === i) break;\n    }\n  } catch (err) {\n    _d = true;\n    _e = err;\n  } finally {\n    try {\n      if (!_n && _i[\"return\"] != null) _i[\"return\"]();\n    } finally {\n      if (_d) throw _e;\n    }\n  }\n\n  return _arr;\n}\n\nfunction _arrayWithHoles(arr) {\n  if (Array.isArray(arr)) return arr;\n}\n\nvar useMarkActivityAsSpoken = _botframeworkWebchatApi.hooks.useMarkActivityAsSpoken,\n    useStyleOptions = _botframeworkWebchatApi.hooks.useStyleOptions,\n    useVoiceSelector = _botframeworkWebchatApi.hooks.useVoiceSelector; // TODO: [P4] Consider moving this feature into BasicActivity\n//       And it has better DOM position for showing visual spoken text\n// TODO: [P3] We should add a \"spoken\" or \"speakState\" flag to indicate whether this activity is going to speak, or spoken\n\nvar connectSpeakActivity = function connectSpeakActivity() {\n  for (var _len = arguments.length, selectors = new Array(_len), _key = 0; _key < _len; _key++) {\n    selectors[_key] = arguments[_key];\n  }\n\n  return _connectToWebChat.default.apply(void 0, [function (_ref, _ref2) {\n    var language = _ref.language,\n        markActivity = _ref.markActivity,\n        _selectVoice = _ref.selectVoice;\n    var activity = _ref2.activity;\n    return {\n      language: language,\n      markAsSpoken: function markAsSpoken() {\n        return markActivity(activity, 'speak', false);\n      },\n      selectVoice: function selectVoice(voices) {\n        return _selectVoice(voices, activity);\n      }\n    };\n  }].concat(selectors));\n};\n\nexports.connectSpeakActivity = connectSpeakActivity;\n\nvar Speak = function Speak(_ref3) {\n  var activity = _ref3.activity;\n\n  var _useStyleOptions = useStyleOptions(),\n      _useStyleOptions2 = _slicedToArray(_useStyleOptions, 1),\n      showSpokenText = _useStyleOptions2[0].showSpokenText;\n\n  var markActivityAsSpoken = useMarkActivityAsSpoken();\n  var selectVoice = useVoiceSelector(activity);\n  var markAsSpoken = (0, _react.useCallback)(function () {\n    markActivityAsSpoken(activity);\n  }, [activity, markActivityAsSpoken]);\n  var singleLine = (0, _react.useMemo)(function () {\n    var _activity$attachments = activity.attachments,\n        attachments = _activity$attachments === void 0 ? [] : _activity$attachments,\n        speak = activity.speak,\n        text = activity.text;\n    return !!activity && [speak || text].concat(_toConsumableArray(attachments.filter(function (_ref4) {\n      var contentType = _ref4.contentType;\n      return contentType === 'application/vnd.microsoft.card.adaptive';\n    }).map(function (attachment) {\n      var _attachment$content;\n\n      return attachment === null || attachment === void 0 ? void 0 : (_attachment$content = attachment.content) === null || _attachment$content === void 0 ? void 0 : _attachment$content.speak;\n    }))).filter(function (line) {\n      return line;\n    }).join('\\r\\n');\n  }, [activity]);\n  var _activity$channelData = activity.channelData;\n  _activity$channelData = _activity$channelData === void 0 ? {} : _activity$channelData;\n  var speechSynthesisUtterance = _activity$channelData.speechSynthesisUtterance;\n  return !!activity && /*#__PURE__*/_react.default.createElement(_react.default.Fragment, null, speechSynthesisUtterance ? /*#__PURE__*/_react.default.createElement(_reactSay.SayUtterance, {\n    onEnd: markAsSpoken,\n    onError: markAsSpoken,\n    utterance: speechSynthesisUtterance\n  }) : /*#__PURE__*/_react.default.createElement(_reactSay.default, {\n    onEnd: markAsSpoken,\n    onError: markAsSpoken,\n    text: singleLine,\n    voice: selectVoice\n  }), !!showSpokenText && /*#__PURE__*/_react.default.createElement(_SayAlt.default, {\n    speak: singleLine\n  }));\n};\n\nSpeak.propTypes = {\n  activity: _propTypes.default.shape({\n    attachments: _propTypes.default.arrayOf(_propTypes.default.shape({\n      speak: _propTypes.default.string,\n      subtitle: _propTypes.default.string,\n      text: _propTypes.default.string,\n      title: _propTypes.default.string\n    })),\n    channelData: _propTypes.default.shape({\n      speechSynthesisUtterance: _propTypes.default.any\n    }),\n    speak: _propTypes.default.string,\n    text: _propTypes.default.string\n  }).isRequired\n};\nvar _default = Speak;\nexports.default = _default;","map":{"version":3,"mappings":";;;;;;;;;;;;;;;;;;;;;;;AACA;;AACA;;AACA;;AACA;;AAEA;;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAEA,IAAQA,uBAAR,GAAuEC,8BAA/DD,uBAAR;AAAA,IAAiCE,eAAjC,GAAuED,8BAAtCC,eAAjC;AAAA,IAAkDC,gBAAlD,GAAuEF,8BAArBE,gBAAlD,C,CAEA;AACA;AAEA;;AACA,IAAMC,oBAAoB,GAAG,SAAvBA,oBAAuB;AAAA,oCAAIC,SAAJ;AAAIA,aAAJ,MAAIA,GAAJC,eAAID;AAAJ;;AAAA,SAC3BE,yCACE;AAAA,QAAGC,QAAH,QAAGA,QAAH;AAAA,QAAaC,YAAb,QAAaA,YAAb;AAAA,QAA2BC,YAA3B,QAA2BA,WAA3B;AAAA,QAA4CC,QAA5C,SAA4CA,QAA5C;AAAA,WAA4D;AAC1DH,cAAQ,EAARA,QAD0D;AAE1DI,kBAAY,EAAE;AAAA,eAAMH,YAAY,CAACE,QAAD,EAAW,OAAX,EAAoB,KAApB,CAAlB;AAF4C;AAG1DD,iBAAW,EAAE,6BAAM;AAAA,eAAIA,YAAW,CAACG,MAAD,EAASF,QAAT,CAAf;AAAA;AAHuC,KAA5D;AADF,YAMKN,SANLE,EAD2B;AAA7B;;;;AAcA,IAAMO,KAAqB,GAAG,SAAxBA,KAAwB,QAAkB;AAAA,MAAfH,QAAe,SAAfA,QAAe;;AAC9C,yBAA6BT,eAAe,EAA5C;AAAA;AAAA,MAASa,cAAT,wBAASA,cAAT;;AACA,MAAMC,oBAAoB,GAAGhB,uBAAuB,EAApD;AACA,MAAMU,WAAW,GAAGP,gBAAgB,CAACQ,QAAD,CAApC;AAEA,MAAMC,YAAY,GAAG,wBAAY,YAAM;AACrCI,wBAAoB,CAACL,QAAD,CAApBK;AADmB,KAElB,CAACL,QAAD,EAAWK,oBAAX,CAFkB,CAArB;AAIA,MAAMC,UAAU,GAAG,oBAAQ,YAAM;AAC/B,gCAA0CN,QAA1C,CAAQO,WAAR;AAAA,QAAQA,WAAR,sCAAsB,EAAtB;AAAA,QAA0BC,KAA1B,GAA0CR,QAA1C,CAA0BQ,KAA1B;AAAA,QAAiCC,IAAjC,GAA0CT,QAA1C,CAAiCS,IAAjC;AAEA,WACE,CAAC,CAACT,QAAF,IACA,CACEQ,KAAK,IAAIC,IADX,4BAEKF,WAAW,CACXG,MADAH,CACO;AAAA,UAAGI,WAAH,SAAGA,WAAH;AAAA,aAAqBA,WAAW,KAAK,yCAArC;AADP,OAEAC,GAFAL,CAEI,sBAAU;AAAA;;AAAA,aAAIM,UAAJ,SAAIA,cAAJ,WAAIA,GAAJ,MAAIA,GAAJ,uBAAIA,UAAU,CAAEC,OAAhB,wDAAIC,oBAAqBP,KAAzB;AAFd,MAFL,GAMGE,MANH,CAMU,gBAAI;AAAA,aAAIM,IAAJ;AANd,OAOGC,IAPH,CAOQ,MAPR,CAFF;AAHiB,KAchB,CAACjB,QAAD,CAdgB,CAAnB;AAgBA,8BAE8EA,QAF9E,CACEkB,WADF;AAAAC,6DAC8C,EAD9C;AAAA,MACiBC,wBADjB,yBACiBA,wBADjB;AAIA,SACE,CAAC,CAACpB,QAAF,iBACEqB,6BAACA,eAAMC,QAAP,QACGF,wBAAwB,gBACvBC,6BAACE,sBAAD;AAAcC,SAAK,EAAEvB,YAArB;AAAmCwB,WAAO,EAAExB,YAA5C;AAA0DyB,aAAS,EAAEN;AAArE,IADuB,gBAGvBC,6BAACE,iBAAD;AAAKC,SAAK,EAAEvB,YAAZ;AAA0BwB,WAAO,EAAExB,YAAnC;AAAiDQ,QAAI,EAAEH,UAAvD;AAAmEqB,SAAK,EAAE5B;AAA1E,IAJJ,EAMG,CAAC,CAACK,cAAF,iBAAoBiB,6BAACO,eAAD;AAAQpB,SAAK,EAAEF;AAAf,IANvB,CAFJ;AA7BF;;AA2CAH,KAAK,CAAC0B,SAAN1B,GAAkB;AAChBH,UAAQ,EAAE8B,mBAAUC,KAAVD,CAAgB;AACxBvB,eAAW,EAAEuB,mBAAUE,OAAVF,CACXA,mBAAUC,KAAVD,CAAgB;AACdtB,WAAK,EAAEsB,mBAAUG,MADH;AAEdC,cAAQ,EAAEJ,mBAAUG,MAFN;AAGdxB,UAAI,EAAEqB,mBAAUG,MAHF;AAIdE,WAAK,EAAEL,mBAAUG;AAJH,KAAhBH,CADWA,CADW;AASxBZ,eAAW,EAAEY,mBAAUC,KAAVD,CAAgB;AAC3BV,8BAAwB,EAAEU,mBAAUM;AADT,KAAhBN,CATW;AAYxBtB,SAAK,EAAEsB,mBAAUG,MAZO;AAaxBxB,QAAI,EAAEqB,mBAAUG;AAbQ,GAAhBH,EAcPO;AAfa,CAAlBlC;eAkBeA","names":["useMarkActivityAsSpoken","hooks","useStyleOptions","useVoiceSelector","connectSpeakActivity","selectors","arguments","connectToWebChat","language","markActivity","selectVoice","activity","markAsSpoken","voices","Speak","showSpokenText","markActivityAsSpoken","singleLine","attachments","speak","text","filter","contentType","map","attachment","content","_attachment$content","line","join","channelData","_activity$channelData","speechSynthesisUtterance","_react","Fragment","_reactSay","onEnd","onError","utterance","voice","_SayAlt","propTypes","PropTypes","shape","arrayOf","string","subtitle","title","any","isRequired"],"sources":["/Users/dylanmurray/Sweng-2022/front/node_modules/botframework-webchat-component/lib/src/Activity/Speak.tsx"],"sourcesContent":["import { DirectLineActivity } from 'botframework-webchat-core';\nimport { hooks } from 'botframework-webchat-api';\nimport PropTypes from 'prop-types';\nimport React, { FC, useCallback, useMemo } from 'react';\nimport Say, { SayUtterance } from 'react-say';\n\nimport connectToWebChat from '../connectToWebChat';\nimport SayAlt from './SayAlt';\n\nconst { useMarkActivityAsSpoken, useStyleOptions, useVoiceSelector } = hooks;\n\n// TODO: [P4] Consider moving this feature into BasicActivity\n//       And it has better DOM position for showing visual spoken text\n\n// TODO: [P3] We should add a \"spoken\" or \"speakState\" flag to indicate whether this activity is going to speak, or spoken\nconst connectSpeakActivity = (...selectors) =>\n  connectToWebChat(\n    ({ language, markActivity, selectVoice }, { activity }) => ({\n      language,\n      markAsSpoken: () => markActivity(activity, 'speak', false),\n      selectVoice: voices => selectVoice(voices, activity)\n    }),\n    ...selectors\n  );\n\ntype SpeakProps = {\n  activity: DirectLineActivity;\n};\n\nconst Speak: FC<SpeakProps> = ({ activity }) => {\n  const [{ showSpokenText }] = useStyleOptions();\n  const markActivityAsSpoken = useMarkActivityAsSpoken();\n  const selectVoice = useVoiceSelector(activity);\n\n  const markAsSpoken = useCallback(() => {\n    markActivityAsSpoken(activity);\n  }, [activity, markActivityAsSpoken]);\n\n  const singleLine = useMemo(() => {\n    const { attachments = [], speak, text } = activity;\n\n    return (\n      !!activity &&\n      [\n        speak || text,\n        ...attachments\n          .filter(({ contentType }) => contentType === 'application/vnd.microsoft.card.adaptive')\n          .map(attachment => attachment?.content?.speak)\n      ]\n        .filter(line => line)\n        .join('\\r\\n')\n    );\n  }, [activity]);\n\n  const {\n    channelData: { speechSynthesisUtterance } = {}\n  }: { channelData: { speechSynthesisUtterance?: SpeechSynthesisUtterance } } = activity;\n\n  return (\n    !!activity && (\n      <React.Fragment>\n        {speechSynthesisUtterance ? (\n          <SayUtterance onEnd={markAsSpoken} onError={markAsSpoken} utterance={speechSynthesisUtterance} />\n        ) : (\n          <Say onEnd={markAsSpoken} onError={markAsSpoken} text={singleLine} voice={selectVoice} />\n        )}\n        {!!showSpokenText && <SayAlt speak={singleLine} />}\n      </React.Fragment>\n    )\n  );\n};\n\nSpeak.propTypes = {\n  activity: PropTypes.shape({\n    attachments: PropTypes.arrayOf(\n      PropTypes.shape({\n        speak: PropTypes.string,\n        subtitle: PropTypes.string,\n        text: PropTypes.string,\n        title: PropTypes.string\n      })\n    ),\n    channelData: PropTypes.shape({\n      speechSynthesisUtterance: PropTypes.any\n    }),\n    speak: PropTypes.string,\n    text: PropTypes.string\n  }).isRequired\n};\n\nexport default Speak;\n\nexport { connectSpeakActivity };\n"]},"metadata":{},"sourceType":"script"}