{"ast":null,"code":"\"use strict\";\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\");\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = create;\n\nvar _regenerator = _interopRequireDefault(require(\"@babel/runtime/regenerator\"));\n\nvar _asyncToGenerator2 = _interopRequireDefault(require(\"@babel/runtime/helpers/asyncToGenerator\"));\n\nvar _microsoftCognitiveservicesSpeechSdk = require(\"microsoft-cognitiveservices-speech-sdk\");\n\nvar _createWebSpeechPonyfillFactory = _interopRequireDefault(require(\"./createWebSpeechPonyfillFactory\"));\n\nvar _DirectLineSpeech = _interopRequireDefault(require(\"./DirectLineSpeech\"));\n\nvar _patchDialogServiceConnectorInline = _interopRequireDefault(require(\"./patchDialogServiceConnectorInline\"));\n\nvar _refreshDirectLineToken = _interopRequireDefault(require(\"./utils/refreshDirectLineToken\"));\n\nvar _resolveFunctionOrReturnValue = _interopRequireDefault(require(\"./resolveFunctionOrReturnValue\"));\n/* eslint complexity: [\"error\", 33] */\n\n\nvar DIRECT_LINE_TOKEN_RENEWAL_INTERVAL = 900000; // 15 minutes\n\nvar TOKEN_RENEWAL_INTERVAL = 120000; // eslint-disable-next-line complexity\n\nfunction create(_x) {\n  return _create.apply(this, arguments);\n}\n\nfunction _create() {\n  _create = (0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee3(_ref) {\n    var audioConfig, audioContext, audioInputDeviceId, enableInternalHTTPSupport, enableTelemetry, fetchCredentials, speechRecognitionEndpointId, _ref$speechRecognitio, speechRecognitionLanguage, speechSynthesisDeploymentId, speechSynthesisOutputFormat, textNormalization, userID, username, _yield$resolveFunctio, authorizationToken, directLineToken, directLineSpeechHostname, region, subscriptionKey, config, dialogServiceConnector, interval, _interval, directLine, webSpeechPonyfillFactory;\n\n    return _regenerator.default.wrap(function _callee3$(_context3) {\n      while (1) {\n        switch (_context3.prev = _context3.next) {\n          case 0:\n            audioConfig = _ref.audioConfig, audioContext = _ref.audioContext, audioInputDeviceId = _ref.audioInputDeviceId, enableInternalHTTPSupport = _ref.enableInternalHTTPSupport, enableTelemetry = _ref.enableTelemetry, fetchCredentials = _ref.fetchCredentials, speechRecognitionEndpointId = _ref.speechRecognitionEndpointId, _ref$speechRecognitio = _ref.speechRecognitionLanguage, speechRecognitionLanguage = _ref$speechRecognitio === void 0 ? typeof window !== 'undefined' && typeof window.navigator !== 'undefined' && window.navigator.language || 'en-US' : _ref$speechRecognitio, speechSynthesisDeploymentId = _ref.speechSynthesisDeploymentId, speechSynthesisOutputFormat = _ref.speechSynthesisOutputFormat, textNormalization = _ref.textNormalization, userID = _ref.userID, username = _ref.username;\n\n            if (fetchCredentials) {\n              _context3.next = 3;\n              break;\n            }\n\n            throw new Error('\"fetchCredentials\" must be specified.');\n\n          case 3:\n            _context3.next = 5;\n            return (0, _resolveFunctionOrReturnValue.default)(fetchCredentials);\n\n          case 5:\n            _yield$resolveFunctio = _context3.sent;\n            authorizationToken = _yield$resolveFunctio.authorizationToken;\n            directLineToken = _yield$resolveFunctio.directLineToken;\n            directLineSpeechHostname = _yield$resolveFunctio.directLineSpeechHostname;\n            region = _yield$resolveFunctio.region;\n            subscriptionKey = _yield$resolveFunctio.subscriptionKey;\n\n            if (!(!authorizationToken && !subscriptionKey || authorizationToken && subscriptionKey || authorizationToken && typeof authorizationToken !== 'string' || subscriptionKey && typeof subscriptionKey !== 'string' || enableInternalHTTPSupport && !directLineToken)) {\n              _context3.next = 13;\n              break;\n            }\n\n            throw new Error('\"fetchCredentials\" must return either \"authorizationToken\" or \"subscriptionKey\" as a non-empty string only. If enableInternalHTTPSupport is set to true, then it should also return a non-empty \"directLineToken\"');\n\n          case 13:\n            if (typeof enableTelemetry !== 'undefined') {\n              console.warn('botframework-directlinespeech: Telemetry options are not yet supported. Please refer to Cognitive Services documentation for details.');\n            }\n\n            if (!(directLineSpeechHostname && region || !directLineSpeechHostname && !region)) {\n              _context3.next = 16;\n              break;\n            }\n\n            throw new Error('\"fetchCredentials\" must return either \"directLineSpeechHostname\" or \"region\" and it must not be an empty string.');\n\n          case 16:\n            if (!directLineSpeechHostname) {\n              _context3.next = 23;\n              break;\n            }\n\n            if (!(typeof directLineSpeechHostname !== 'string')) {\n              _context3.next = 19;\n              break;\n            }\n\n            throw new Error('\"fetchCredentials\" must return \"directLineSpeechHostname\" as a string.');\n\n          case 19:\n            if (!enableInternalHTTPSupport) {\n              _context3.next = 21;\n              break;\n            }\n\n            throw new Error('\"fetchCredentials\" must not return \"directLineSpeechHostname\" if \"enableInternalHTTPSupport\" is set.');\n\n          case 21:\n            _context3.next = 25;\n            break;\n\n          case 23:\n            if (!(typeof region !== 'string')) {\n              _context3.next = 25;\n              break;\n            }\n\n            throw new Error('\"fetchCredentials\" must return \"region\" as a string.');\n\n          case 25:\n            if (audioConfig && audioInputDeviceId) {\n              console.warn('botframework-directlinespeech-sdk: Only \"audioConfig\" or \"audioInputDeviceId\" can be specified, but not both; ignoring \"audioInputDeviceId\".');\n            } else if (!audioConfig) {\n              if (audioInputDeviceId) {\n                audioConfig = _microsoftCognitiveservicesSpeechSdk.AudioConfig.fromMicrophoneInput(audioInputDeviceId);\n              } else {\n                audioConfig = _microsoftCognitiveservicesSpeechSdk.AudioConfig.fromDefaultMicrophoneInput();\n              }\n            }\n\n            if (speechRecognitionEndpointId) {\n              console.warn('botframework-directlinespeech: Custom Speech is currently not supported; ignoring \"speechRecognitionEndpointId\".');\n            }\n\n            if (speechSynthesisDeploymentId) {\n              console.warn('botframework-directlinespeech: Custom Voice is currently not supported; ignoring \"speechSynthesisDeploymentId\".');\n            }\n\n            if (speechSynthesisOutputFormat) {\n              console.warn('botframework-directlinespeech: Synthesis output format is currently not supported; ignoring \"speechSynthesisOutputFormat\".');\n            }\n\n            if (textNormalization) {\n              console.warn('botframework-directlinespeech: Text normalization is currently not supported; ignoring \"textNormalization\".');\n            }\n\n            if (userID || username) {\n              console.warn('botframework-directlinespeech: Custom \"userId\" and \"username\" are currently not supported and are ignored.');\n            }\n\n            if (directLineSpeechHostname) {\n              if (authorizationToken) {\n                config = _microsoftCognitiveservicesSpeechSdk.BotFrameworkConfig.fromHost(new URL(\"wss://\".concat(directLineSpeechHostname)));\n                config.setProperty(_microsoftCognitiveservicesSpeechSdk.PropertyId.SpeechServiceAuthorization_Token, authorizationToken);\n              } else {\n                config = _microsoftCognitiveservicesSpeechSdk.BotFrameworkConfig.fromHost(new URL(\"wss://\".concat(directLineSpeechHostname)), subscriptionKey);\n              }\n            } else {\n              if (authorizationToken) {\n                config = _microsoftCognitiveservicesSpeechSdk.BotFrameworkConfig.fromAuthorizationToken(authorizationToken, region);\n              } else {\n                config = _microsoftCognitiveservicesSpeechSdk.BotFrameworkConfig.fromSubscription(subscriptionKey, region);\n              } // If internal HTTP support is enabled, switch the endpoint to Direct Line on Direct Line Speech service.\n\n\n              if (enableInternalHTTPSupport) {\n                config.setProperty(_microsoftCognitiveservicesSpeechSdk.PropertyId.SpeechServiceConnection_Endpoint, \"wss://\".concat(encodeURI(region), \".convai.speech.microsoft.com/directline/api/v1\"));\n                config.setProperty(_microsoftCognitiveservicesSpeechSdk.PropertyId.Conversation_Agent_Connection_Id, directLineToken);\n              }\n            } // Supported options can be found in DialogConnectorFactory.js.\n            // Set the language used for recognition.\n\n\n            config.setProperty(_microsoftCognitiveservicesSpeechSdk.PropertyId.SpeechServiceConnection_RecoLanguage, speechRecognitionLanguage); // The following code sets the output format.\n            // As advised by the Speech team, this API may be subject to future changes.\n            // We are not enabling output format option because it does not send detailed output format to the bot, rendering this option useless.\n            // config.setProperty(PropertyId.SpeechServiceResponse_OutputFormatOption, OutputFormat[OutputFormat.Detailed]);\n            // Set the user ID for starting the conversation.\n\n            userID && config.setProperty(_microsoftCognitiveservicesSpeechSdk.PropertyId.Conversation_From_Id, userID); // Set Custom Speech and Custom Voice.\n            // The following code is copied from C#, and it is not working yet.\n            // https://github.com/Azure-Samples/Cognitive-Services-Direct-Line-Speech-Client/blob/master/DLSpeechClient/MainWindow.xaml.cs\n            // speechRecognitionEndpointId && config.setServiceProperty('cid', speechRecognitionEndpointId, ServicePropertyChannel.UriQueryParameter);\n            // speechSynthesisDeploymentId && config.setProperty(PropertyId.conversation_Custom_Voice_Deployment_Ids, speechSynthesisDeploymentId);\n\n            dialogServiceConnector = (0, _patchDialogServiceConnectorInline.default)(new _microsoftCognitiveservicesSpeechSdk.DialogServiceConnector(config, audioConfig)); // Renew token per interval.\n\n            if (authorizationToken) {\n              interval = setInterval( /*#__PURE__*/(0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee() {\n                var _yield$resolveFunctio2, authorizationToken, nextDirectLineSpeechHostname, nextRegion;\n\n                return _regenerator.default.wrap(function _callee$(_context) {\n                  while (1) {\n                    switch (_context.prev = _context.next) {\n                      case 0:\n                        // #2660 If the connector has been disposed, we should stop renewing the token.\n                        // TODO: We should use a public implementation if Speech SDK has one related to \"privIsDisposed\".\n                        if (dialogServiceConnector.privIsDisposed) {\n                          clearInterval(interval);\n                        }\n\n                        _context.next = 3;\n                        return (0, _resolveFunctionOrReturnValue.default)(fetchCredentials);\n\n                      case 3:\n                        _yield$resolveFunctio2 = _context.sent;\n                        authorizationToken = _yield$resolveFunctio2.authorizationToken;\n                        nextDirectLineSpeechHostname = _yield$resolveFunctio2.directLineSpeechHostname;\n                        nextRegion = _yield$resolveFunctio2.region;\n\n                        if (authorizationToken) {\n                          _context.next = 9;\n                          break;\n                        }\n\n                        return _context.abrupt(\"return\", console.warn('botframework-directlinespeech-sdk: Renew token failed because \"fetchCredentials\" call returned no authorization token.'));\n\n                      case 9:\n                        if (!directLineSpeechHostname) {\n                          _context.next = 14;\n                          break;\n                        }\n\n                        if (!(directLineSpeechHostname !== nextDirectLineSpeechHostname)) {\n                          _context.next = 12;\n                          break;\n                        }\n\n                        return _context.abrupt(\"return\", console.warn('botframework-directlinespeech-sdk: \"directLineSpeechHostname\" change is not supported for renewed token. Authorization token is not renewed.'));\n\n                      case 12:\n                        _context.next = 16;\n                        break;\n\n                      case 14:\n                        if (!(region !== nextRegion)) {\n                          _context.next = 16;\n                          break;\n                        }\n\n                        return _context.abrupt(\"return\", console.warn('botframework-directlinespeech-sdk: Region change is not supported for renewed token. Authorization token is not renewed.'));\n\n                      case 16:\n                        dialogServiceConnector.authorizationToken = authorizationToken;\n                      // eslint-disable-line require-atomic-updates\n\n                      case 17:\n                      case \"end\":\n                        return _context.stop();\n                    }\n                  }\n                }, _callee);\n              })), TOKEN_RENEWAL_INTERVAL);\n            } // Renew token per interval.\n\n\n            if (enableInternalHTTPSupport) {\n              _interval = setInterval( /*#__PURE__*/(0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee2() {\n                var refreshedDirectLineToken;\n                return _regenerator.default.wrap(function _callee2$(_context2) {\n                  while (1) {\n                    switch (_context2.prev = _context2.next) {\n                      case 0:\n                        // #2660 If the connector has been disposed, we should stop renewing the token.\n                        // TODO: We should use a public implementation if Speech SDK has one related to \"privIsDisposed\".\n                        if (dialogServiceConnector.privIsDisposed) {\n                          clearInterval(_interval);\n                        }\n\n                        _context2.next = 3;\n                        return (0, _refreshDirectLineToken.default)(directLineToken);\n\n                      case 3:\n                        refreshedDirectLineToken = _context2.sent;\n\n                        if (refreshedDirectLineToken) {\n                          _context2.next = 6;\n                          break;\n                        }\n\n                        return _context2.abrupt(\"return\", console.warn('botframework-directlinespeech-sdk: Renew token failed because call to refresh token Direct Line API did not return a new token.'));\n\n                      case 6:\n                        config.setProperty(_microsoftCognitiveservicesSpeechSdk.PropertyId.Conversation_Agent_Connection_Id, refreshedDirectLineToken);\n                        dialogServiceConnector.properties.setProperty(_microsoftCognitiveservicesSpeechSdk.PropertyId.Conversation_Agent_Connection_Id, refreshedDirectLineToken);\n                        dialogServiceConnector.connect();\n\n                      case 9:\n                      case \"end\":\n                        return _context2.stop();\n                    }\n                  }\n                }, _callee2);\n              })), DIRECT_LINE_TOKEN_RENEWAL_INTERVAL);\n            }\n\n            directLine = new _DirectLineSpeech.default({\n              dialogServiceConnector: dialogServiceConnector\n            });\n            webSpeechPonyfillFactory = (0, _createWebSpeechPonyfillFactory.default)({\n              audioContext: audioContext,\n              enableTelemetry: enableTelemetry,\n              recognizer: dialogServiceConnector,\n              textNormalization: textNormalization\n            });\n            return _context3.abrupt(\"return\", {\n              directLine: directLine,\n              webSpeechPonyfillFactory: webSpeechPonyfillFactory\n            });\n\n          case 40:\n          case \"end\":\n            return _context3.stop();\n        }\n      }\n    }, _callee3);\n  }));\n  return _create.apply(this, arguments);\n}","map":{"version":3,"mappings":";;;;;;;;;;;;;AAEA;;AAOA;;AACA;;AACA;;AACA;;AACA;AAbA;;;AAeA,IAAMA,kCAAkC,GAAG,MAA3C,C,CAAmD;;AACnD,IAAMC,sBAAsB,GAAG,MAA/B,C,CAEA;;SAC8BC,O;;;;;oFAAf;AAAA;;AAAA;AAAA;AAAA;AAAA;AACbC,uBADa,QACbA,aACAC,YAFa,QAEbA,YADAD,EAEAE,kBAHa,QAGbA,kBAFAF,EAGAG,yBAJa,QAIbA,yBAHAH,EAIAI,eALa,QAKbA,eAJAJ,EAKAK,gBANa,QAMbA,gBALAL,EAMAM,2BAPa,QAObA,2BANAN,EADaO,6BAQbC,yBAPAR,EAOAQ,yBARa,sCAQgB,OAAOC,MAAP,KAAkB,WAAlB,IAC3B,OAAOA,MAAM,CAACC,SAAd,KAA4B,WADD,IAE3BD,MAAM,CAACC,SAAPD,CAAiBE,QAFU,IAG3B,OAXW,wBACbX,EAWAY,2BAZa,QAYbA,2BAXAZ,EAYAa,2BAba,QAabA,2BAZAb,EAaAc,iBAda,QAcbA,iBAbAd,EAcAe,MAfa,QAebA,MAdAf,EAeAgB,QAhBa,QAgBbA,QAfAhB;;AADa,gBAkBRK,gBAlBQ;AAAAY;AAAA;AAAA;;AAAA,kBAmBL,IAAIC,KAAJ,CAAU,uCAAV,CAnBK;;AAAA;AAAAD;AAAA,mBAuBL,2CAA6BZ,gBAA7B,CAvBK;;AAAA;AAAAc;AAsBLC,8BAtBK,yBAsBLA;AAAoBC,2BAtBf,yBAsBeA;AAAiBC,oCAtBhC,yBAsBgCA;AAA0BC,kBAtB1D,yBAsB0DA;AAAQC,2BAtBlE,yBAsBkEA;;AAtBlE,kBA0BV,CAACJ,kBAAD,IAAuB,CAACI,eAAxB,IACAJ,kBAAkB,IAAII,eADtB,IAEAJ,kBAAkB,IAAI,OAAOA,kBAAP,KAA8B,QAFpD,IAGAI,eAAe,IAAI,OAAOA,eAAP,KAA2B,QAH9C,IAIArB,yBAAyB,IAAI,CAACkB,eA9BpB;AAAAJ;AAAA;AAAA;;AAAA,kBAgCL,IAAIC,KAAJ,CACJ,mNADI,CAhCK;;AAAA;AAqCb,gBAAI,OAAOd,eAAP,KAA2B,WAA/B,EAA4C;AAC1CqB,qBAAO,CAACC,IAARD,CACE,uIADFA;AAGD;;AAzCY,kBA2CRH,wBAAwB,IAAIC,MAA5BD,IAAwC,CAACA,wBAAD,IAA6B,CAACC,MA3C9D;AAAAN;AAAA;AAAA;;AAAA,kBA4CL,IAAIC,KAAJ,CACJ,kHADI,CA5CK;;AAAA;AAAA,iBAiDTI,wBAjDS;AAAAL;AAAA;AAAA;;AAAA,kBAkDP,OAAOK,wBAAP,KAAoC,QAlD7B;AAAAL;AAAA;AAAA;;AAAA,kBAmDH,IAAIC,KAAJ,CAAU,wEAAV,CAnDG;;AAAA;AAAA,iBAsDPf,yBAtDO;AAAAc;AAAA;AAAA;;AAAA,kBAuDH,IAAIC,KAAJ,CACJ,sGADI,CAvDG;;AAAA;AAAAD;AAAA;;AAAA;AAAA,kBA4DP,OAAOM,MAAP,KAAkB,QA5DX;AAAAN;AAAA;AAAA;;AAAA,kBA6DH,IAAIC,KAAJ,CAAU,sDAAV,CA7DG;;AAAA;AAiEb,gBAAIlB,WAAW,IAAIE,kBAAnB,EAAuC;AACrCuB,qBAAO,CAACC,IAARD,CACE,8IADFA;AADF,mBAIO,IAAI,CAACzB,WAAL,EAAkB;AACvB,kBAAIE,kBAAJ,EAAwB;AACtBF,2BAAW,GAAG2B,iDAAYC,mBAAZD,CAAgCzB,kBAAhCyB,CAAd3B;AADF,qBAEO;AACLA,2BAAW,GAAG2B,iDAAYE,0BAAZF,EAAd3B;AACD;AACF;;AAED,gBAAIM,2BAAJ,EAAiC;AAC/BmB,qBAAO,CAACC,IAARD,CACE,kHADFA;AAGD;;AAED,gBAAIb,2BAAJ,EAAiC;AAC/Ba,qBAAO,CAACC,IAARD,CACE,iHADFA;AAGD;;AAED,gBAAIZ,2BAAJ,EAAiC;AAC/BY,qBAAO,CAACC,IAARD,CACE,4HADFA;AAGD;;AAED,gBAAIX,iBAAJ,EAAuB;AACrBW,qBAAO,CAACC,IAARD,CACE,6GADFA;AAGD;;AAED,gBAAIV,MAAM,IAAIC,QAAd,EAAwB;AACtBS,qBAAO,CAACC,IAARD,CACE,4GADFA;AAGD;;AAID,gBAAIH,wBAAJ,EAA8B;AAC5B,kBAAIF,kBAAJ,EAAwB;AACtBU,sBAAM,GAAGC,wDAAmBC,QAAnBD,CAA4B,IAAIE,GAAJ,iBAAiBX,wBAAjB,EAA5BS,CAATD;AAEAA,sBAAM,CAACI,WAAPJ,CAAmBK,gDAAWC,gCAA9BN,EAAgEV,kBAAhEU;AAHF,qBAIO;AACLA,sBAAM,GAAGC,wDAAmBC,QAAnBD,CAA4B,IAAIE,GAAJ,iBAAiBX,wBAAjB,EAA5BS,EAA0EP,eAA1EO,CAATD;AACD;AAPH,mBAQO;AACL,kBAAIV,kBAAJ,EAAwB;AACtBU,sBAAM,GAAGC,wDAAmBM,sBAAnBN,CAA0CX,kBAA1CW,EAA8DR,MAA9DQ,CAATD;AADF,qBAEO;AACLA,sBAAM,GAAGC,wDAAmBO,gBAAnBP,CAAoCP,eAApCO,EAAqDR,MAArDQ,CAATD;AAJG,gBAOL;;;AACA,kBAAI3B,yBAAJ,EAA+B;AAC7B2B,sBAAM,CAACI,WAAPJ,CACEK,gDAAWI,gCADbT,kBAEWU,SAAS,CAACjB,MAAD,CAFpB;AAKAO,sBAAM,CAACI,WAAPJ,CAAmBK,gDAAWM,gCAA9BX,EAAgET,eAAhES;AACD;AApIU,cAuIb;AAEA;;;AACAA,kBAAM,CAACI,WAAPJ,CAAmBK,gDAAWO,oCAA9BZ,EAAoEtB,yBAApEsB,EA1Ia,CA4Ib;AACA;AACA;AACA;AAEA;;AACAf,kBAAM,IAAIe,MAAM,CAACI,WAAPJ,CAAmBK,gDAAWQ,oBAA9Bb,EAAoDf,MAApDe,CAAVf,CAlJa,CAoJb;AACA;AACA;AACA;AACA;;AAEM6B,kCA1JO,GA0JkB,gDAAkC,IAAIC,2DAAJ,CAA2Bf,MAA3B,EAAmC9B,WAAnC,CAAlC,CAAzB4C,CA1JO,CA4Jb;;AACA,gBAAIxB,kBAAJ,EAAwB;AAChB0B,sBADgB,GACLC,WAAW,uFAAC;AAAA;;AAAA;AAAA;AAAA;AAAA;AAC3B;AAEA;AACA,4BAAIH,sBAAsB,CAACI,cAA3B,EAA2C;AACzCC,uCAAa,CAACH,QAAD,CAAbG;AACD;;AAN0BC;AAAA,+BAYjB,2CAA6B7C,gBAA7B,CAZiB;;AAAA;AAAA8C;AASzB/B,0CATyB,0BASzBA;AAC0BgC,oDAVD,0BAUzB9B,wBAA0B8B;AAClBC,kCAXiB,0BAWzB9B,MAAQ8B;;AAXiB,4BActBjC,kBAdsB;AAAA8B;AAAA;AAAA;;AAAA,yDAelBzB,OAAO,CAACC,IAARD,CACL,wHADKA,CAfkB;;AAAA;AAAA,6BAoBvBH,wBApBuB;AAAA4B;AAAA;AAAA;;AAAA,8BAqBrB5B,wBAAwB,KAAK8B,4BArBR;AAAAF;AAAA;AAAA;;AAAA,yDAsBhBzB,OAAO,CAACC,IAARD,CACL,8IADKA,CAtBgB;;AAAA;AAAAyB;AAAA;;AAAA;AAAA,8BA2BrB3B,MAAM,KAAK8B,UA3BU;AAAAH;AAAA;AAAA;;AAAA,yDA4BhBzB,OAAO,CAACC,IAARD,CACL,0HADKA,CA5BgB;;AAAA;AAkC3BmB,8CAAsB,CAACxB,kBAAvBwB,GAA4CxB,kBAA5CwB;AAAgE;;AAlCrC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAD,mBAmCzB9C,sBAnCyB,CAAtBgD;AA9JK,cAoMb;;;AACA,gBAAI3C,yBAAJ,EAA+B;AACvB2C,uBADuB,GACZC,WAAW,uFAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAC3B;AAEA;AACA,4BAAIH,sBAAsB,CAACI,cAA3B,EAA2C;AACzCC,uCAAa,CAACH,SAAD,CAAbG;AACD;;AAN0BK;AAAA,+BAQY,qCAAuBjC,eAAvB,CARZ;;AAAA;AAQrBkC,gDARqB,iBAQrBA;;AARqB,4BAUtBA,wBAVsB;AAAAD;AAAA;AAAA;;AAAA,0DAWlB7B,OAAO,CAACC,IAARD,CACL,iIADKA,CAXkB;;AAAA;AAgB3BK,8BAAM,CAACI,WAAPJ,CAAmBK,gDAAWM,gCAA9BX,EAAgEyB,wBAAhEzB;AAEAc,8CAAsB,CAACY,UAAvBZ,CAAkCV,WAAlCU,CACET,gDAAWM,gCADbG,EAEEW,wBAFFX;AAIAA,8CAAsB,CAACa,OAAvBb;;AAtB2B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAD,mBAuBzB/C,kCAvByB,CAAtBiD;AAwBP;;AAEKY,sBAhOO,GAgOM,IAAIC,yBAAJ,CAAqB;AAAEf,oCAAsB,EAAtBA;AAAF,aAArB,CAAbc;AAEAE,oCAlOO,GAkOoB,6CAA+B;AAC9D3D,0BAAY,EAAZA,YAD8D;AAE9DG,6BAAe,EAAfA,eAF8D;AAG9DyD,wBAAU,EAAEjB,sBAHkD;AAI9D9B,+BAAiB,EAAjBA;AAJ8D,aAA/B,CAA3B8C;AAlOO,8CAyON;AACLF,wBAAU,EAAVA,UADK;AAELE,sCAAwB,EAAxBA;AAFK,aAzOM;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA","names":["DIRECT_LINE_TOKEN_RENEWAL_INTERVAL","TOKEN_RENEWAL_INTERVAL","create","audioConfig","audioContext","audioInputDeviceId","enableInternalHTTPSupport","enableTelemetry","fetchCredentials","speechRecognitionEndpointId","_ref$speechRecognitio","speechRecognitionLanguage","window","navigator","language","speechSynthesisDeploymentId","speechSynthesisOutputFormat","textNormalization","userID","username","_context3","Error","_yield$resolveFunctio","authorizationToken","directLineToken","directLineSpeechHostname","region","subscriptionKey","console","warn","AudioConfig","fromMicrophoneInput","fromDefaultMicrophoneInput","config","BotFrameworkConfig","fromHost","URL","setProperty","PropertyId","SpeechServiceAuthorization_Token","fromAuthorizationToken","fromSubscription","SpeechServiceConnection_Endpoint","encodeURI","Conversation_Agent_Connection_Id","SpeechServiceConnection_RecoLanguage","Conversation_From_Id","dialogServiceConnector","DialogServiceConnector","interval","setInterval","privIsDisposed","clearInterval","_context","_yield$resolveFunctio2","nextDirectLineSpeechHostname","nextRegion","_context2","refreshedDirectLineToken","properties","connect","directLine","DirectLineSpeech","webSpeechPonyfillFactory","recognizer"],"sources":["/Users/dylanmurray/Sweng-2022/front/node_modules/botframework-directlinespeech-sdk/lib/src/createAdapters.js"],"sourcesContent":["/* eslint complexity: [\"error\", 33] */\n\nimport {\n  AudioConfig,\n  BotFrameworkConfig,\n  DialogServiceConnector,\n  PropertyId\n} from 'microsoft-cognitiveservices-speech-sdk';\n\nimport createWebSpeechPonyfillFactory from './createWebSpeechPonyfillFactory';\nimport DirectLineSpeech from './DirectLineSpeech';\nimport patchDialogServiceConnectorInline from './patchDialogServiceConnectorInline';\nimport refreshDirectLineToken from './utils/refreshDirectLineToken';\nimport resolveFunctionOrReturnValue from './resolveFunctionOrReturnValue';\n\nconst DIRECT_LINE_TOKEN_RENEWAL_INTERVAL = 900000; // 15 minutes\nconst TOKEN_RENEWAL_INTERVAL = 120000;\n\n// eslint-disable-next-line complexity\nexport default async function create({\n  audioConfig,\n  audioContext,\n  audioInputDeviceId,\n  enableInternalHTTPSupport,\n  enableTelemetry,\n  fetchCredentials,\n  speechRecognitionEndpointId,\n  speechRecognitionLanguage = (typeof window !== 'undefined' &&\n    typeof window.navigator !== 'undefined' &&\n    window.navigator.language) ||\n    'en-US',\n  speechSynthesisDeploymentId,\n  speechSynthesisOutputFormat,\n  textNormalization,\n  userID,\n  username\n}) {\n  if (!fetchCredentials) {\n    throw new Error('\"fetchCredentials\" must be specified.');\n  }\n\n  const { authorizationToken, directLineToken, directLineSpeechHostname, region, subscriptionKey } =\n    await resolveFunctionOrReturnValue(fetchCredentials);\n\n  if (\n    (!authorizationToken && !subscriptionKey) ||\n    (authorizationToken && subscriptionKey) ||\n    (authorizationToken && typeof authorizationToken !== 'string') ||\n    (subscriptionKey && typeof subscriptionKey !== 'string') ||\n    (enableInternalHTTPSupport && !directLineToken)\n  ) {\n    throw new Error(\n      '\"fetchCredentials\" must return either \"authorizationToken\" or \"subscriptionKey\" as a non-empty string only. If enableInternalHTTPSupport is set to true, then it should also return a non-empty \"directLineToken\"'\n    );\n  }\n\n  if (typeof enableTelemetry !== 'undefined') {\n    console.warn(\n      'botframework-directlinespeech: Telemetry options are not yet supported. Please refer to Cognitive Services documentation for details.'\n    );\n  }\n\n  if ((directLineSpeechHostname && region) || (!directLineSpeechHostname && !region)) {\n    throw new Error(\n      '\"fetchCredentials\" must return either \"directLineSpeechHostname\" or \"region\" and it must not be an empty string.'\n    );\n  }\n\n  if (directLineSpeechHostname) {\n    if (typeof directLineSpeechHostname !== 'string') {\n      throw new Error('\"fetchCredentials\" must return \"directLineSpeechHostname\" as a string.');\n    }\n\n    if (enableInternalHTTPSupport) {\n      throw new Error(\n        '\"fetchCredentials\" must not return \"directLineSpeechHostname\" if \"enableInternalHTTPSupport\" is set.'\n      );\n    }\n  } else {\n    if (typeof region !== 'string') {\n      throw new Error('\"fetchCredentials\" must return \"region\" as a string.');\n    }\n  }\n\n  if (audioConfig && audioInputDeviceId) {\n    console.warn(\n      'botframework-directlinespeech-sdk: Only \"audioConfig\" or \"audioInputDeviceId\" can be specified, but not both; ignoring \"audioInputDeviceId\".'\n    );\n  } else if (!audioConfig) {\n    if (audioInputDeviceId) {\n      audioConfig = AudioConfig.fromMicrophoneInput(audioInputDeviceId);\n    } else {\n      audioConfig = AudioConfig.fromDefaultMicrophoneInput();\n    }\n  }\n\n  if (speechRecognitionEndpointId) {\n    console.warn(\n      'botframework-directlinespeech: Custom Speech is currently not supported; ignoring \"speechRecognitionEndpointId\".'\n    );\n  }\n\n  if (speechSynthesisDeploymentId) {\n    console.warn(\n      'botframework-directlinespeech: Custom Voice is currently not supported; ignoring \"speechSynthesisDeploymentId\".'\n    );\n  }\n\n  if (speechSynthesisOutputFormat) {\n    console.warn(\n      'botframework-directlinespeech: Synthesis output format is currently not supported; ignoring \"speechSynthesisOutputFormat\".'\n    );\n  }\n\n  if (textNormalization) {\n    console.warn(\n      'botframework-directlinespeech: Text normalization is currently not supported; ignoring \"textNormalization\".'\n    );\n  }\n\n  if (userID || username) {\n    console.warn(\n      'botframework-directlinespeech: Custom \"userId\" and \"username\" are currently not supported and are ignored.'\n    );\n  }\n\n  let config;\n\n  if (directLineSpeechHostname) {\n    if (authorizationToken) {\n      config = BotFrameworkConfig.fromHost(new URL(`wss://${directLineSpeechHostname}`));\n\n      config.setProperty(PropertyId.SpeechServiceAuthorization_Token, authorizationToken);\n    } else {\n      config = BotFrameworkConfig.fromHost(new URL(`wss://${directLineSpeechHostname}`), subscriptionKey);\n    }\n  } else {\n    if (authorizationToken) {\n      config = BotFrameworkConfig.fromAuthorizationToken(authorizationToken, region);\n    } else {\n      config = BotFrameworkConfig.fromSubscription(subscriptionKey, region);\n    }\n\n    // If internal HTTP support is enabled, switch the endpoint to Direct Line on Direct Line Speech service.\n    if (enableInternalHTTPSupport) {\n      config.setProperty(\n        PropertyId.SpeechServiceConnection_Endpoint,\n        `wss://${encodeURI(region)}.convai.speech.microsoft.com/directline/api/v1`\n      );\n\n      config.setProperty(PropertyId.Conversation_Agent_Connection_Id, directLineToken);\n    }\n  }\n\n  // Supported options can be found in DialogConnectorFactory.js.\n\n  // Set the language used for recognition.\n  config.setProperty(PropertyId.SpeechServiceConnection_RecoLanguage, speechRecognitionLanguage);\n\n  // The following code sets the output format.\n  // As advised by the Speech team, this API may be subject to future changes.\n  // We are not enabling output format option because it does not send detailed output format to the bot, rendering this option useless.\n  // config.setProperty(PropertyId.SpeechServiceResponse_OutputFormatOption, OutputFormat[OutputFormat.Detailed]);\n\n  // Set the user ID for starting the conversation.\n  userID && config.setProperty(PropertyId.Conversation_From_Id, userID);\n\n  // Set Custom Speech and Custom Voice.\n  // The following code is copied from C#, and it is not working yet.\n  // https://github.com/Azure-Samples/Cognitive-Services-Direct-Line-Speech-Client/blob/master/DLSpeechClient/MainWindow.xaml.cs\n  // speechRecognitionEndpointId && config.setServiceProperty('cid', speechRecognitionEndpointId, ServicePropertyChannel.UriQueryParameter);\n  // speechSynthesisDeploymentId && config.setProperty(PropertyId.conversation_Custom_Voice_Deployment_Ids, speechSynthesisDeploymentId);\n\n  const dialogServiceConnector = patchDialogServiceConnectorInline(new DialogServiceConnector(config, audioConfig));\n\n  // Renew token per interval.\n  if (authorizationToken) {\n    const interval = setInterval(async () => {\n      // #2660 If the connector has been disposed, we should stop renewing the token.\n\n      // TODO: We should use a public implementation if Speech SDK has one related to \"privIsDisposed\".\n      if (dialogServiceConnector.privIsDisposed) {\n        clearInterval(interval);\n      }\n\n      const {\n        authorizationToken,\n        directLineSpeechHostname: nextDirectLineSpeechHostname,\n        region: nextRegion\n      } = await resolveFunctionOrReturnValue(fetchCredentials);\n\n      if (!authorizationToken) {\n        return console.warn(\n          'botframework-directlinespeech-sdk: Renew token failed because \"fetchCredentials\" call returned no authorization token.'\n        );\n      }\n\n      if (directLineSpeechHostname) {\n        if (directLineSpeechHostname !== nextDirectLineSpeechHostname) {\n          return console.warn(\n            'botframework-directlinespeech-sdk: \"directLineSpeechHostname\" change is not supported for renewed token. Authorization token is not renewed.'\n          );\n        }\n      } else {\n        if (region !== nextRegion) {\n          return console.warn(\n            'botframework-directlinespeech-sdk: Region change is not supported for renewed token. Authorization token is not renewed.'\n          );\n        }\n      }\n\n      dialogServiceConnector.authorizationToken = authorizationToken; // eslint-disable-line require-atomic-updates\n    }, TOKEN_RENEWAL_INTERVAL);\n  }\n\n  // Renew token per interval.\n  if (enableInternalHTTPSupport) {\n    const interval = setInterval(async () => {\n      // #2660 If the connector has been disposed, we should stop renewing the token.\n\n      // TODO: We should use a public implementation if Speech SDK has one related to \"privIsDisposed\".\n      if (dialogServiceConnector.privIsDisposed) {\n        clearInterval(interval);\n      }\n\n      const refreshedDirectLineToken = await refreshDirectLineToken(directLineToken);\n\n      if (!refreshedDirectLineToken) {\n        return console.warn(\n          'botframework-directlinespeech-sdk: Renew token failed because call to refresh token Direct Line API did not return a new token.'\n        );\n      }\n\n      config.setProperty(PropertyId.Conversation_Agent_Connection_Id, refreshedDirectLineToken);\n\n      dialogServiceConnector.properties.setProperty(\n        PropertyId.Conversation_Agent_Connection_Id,\n        refreshedDirectLineToken\n      );\n      dialogServiceConnector.connect();\n    }, DIRECT_LINE_TOKEN_RENEWAL_INTERVAL);\n  }\n\n  const directLine = new DirectLineSpeech({ dialogServiceConnector });\n\n  const webSpeechPonyfillFactory = createWebSpeechPonyfillFactory({\n    audioContext,\n    enableTelemetry,\n    recognizer: dialogServiceConnector,\n    textNormalization\n  });\n\n  return {\n    directLine,\n    webSpeechPonyfillFactory\n  };\n}\n"]},"metadata":{},"sourceType":"script"}