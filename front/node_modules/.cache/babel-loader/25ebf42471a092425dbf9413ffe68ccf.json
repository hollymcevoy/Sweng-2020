{"ast":null,"code":"\"use strict\";\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\");\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _regenerator = _interopRequireDefault(require(\"@babel/runtime/regenerator\"));\n\nvar _asyncToGenerator2 = _interopRequireDefault(require(\"@babel/runtime/helpers/asyncToGenerator\"));\n\nvar _classCallCheck2 = _interopRequireDefault(require(\"@babel/runtime/helpers/classCallCheck\"));\n\nvar _createClass2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createClass\"));\n\nvar _inherits2 = _interopRequireDefault(require(\"@babel/runtime/helpers/inherits\"));\n\nvar _possibleConstructorReturn2 = _interopRequireDefault(require(\"@babel/runtime/helpers/possibleConstructorReturn\"));\n\nvar _getPrototypeOf2 = _interopRequireDefault(require(\"@babel/runtime/helpers/getPrototypeOf\"));\n\nvar _es = require(\"event-target-shim/es5\");\n\nvar _pDeferEs = _interopRequireDefault(require(\"p-defer-es5\"));\n\nvar _onErrorResumeNext = _interopRequireDefault(require(\"on-error-resume-next\"));\n\nvar _AudioContextQueue = _interopRequireDefault(require(\"./AudioContextQueue\"));\n\nvar _fetchCustomVoices = _interopRequireDefault(require(\"./fetchCustomVoices\"));\n\nvar _fetchVoices = _interopRequireDefault(require(\"./fetchVoices\"));\n\nvar _patchOptions2 = _interopRequireDefault(require(\"../patchOptions\"));\n\nvar _SpeechSynthesisEvent = _interopRequireDefault(require(\"./SpeechSynthesisEvent\"));\n\nvar _SpeechSynthesisUtterance = _interopRequireDefault(require(\"./SpeechSynthesisUtterance\"));\n\nfunction _createSuper(Derived) {\n  var hasNativeReflectConstruct = _isNativeReflectConstruct();\n\n  return function _createSuperInternal() {\n    var Super = (0, _getPrototypeOf2.default)(Derived),\n        result;\n\n    if (hasNativeReflectConstruct) {\n      var NewTarget = (0, _getPrototypeOf2.default)(this).constructor;\n      result = Reflect.construct(Super, arguments, NewTarget);\n    } else {\n      result = Super.apply(this, arguments);\n    }\n\n    return (0, _possibleConstructorReturn2.default)(this, result);\n  };\n}\n\nfunction _isNativeReflectConstruct() {\n  if (typeof Reflect === \"undefined\" || !Reflect.construct) return false;\n  if (Reflect.construct.sham) return false;\n  if (typeof Proxy === \"function\") return true;\n\n  try {\n    Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {}));\n    return true;\n  } catch (e) {\n    return false;\n  }\n} // Supported output format can be found at https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/rest-text-to-speech#audio-outputs\n\n\nvar DEFAULT_OUTPUT_FORMAT = 'audio-24khz-160kbitrate-mono-mp3';\nvar EMPTY_ARRAY = [];\n\nvar _default = function _default(options) {\n  var _patchOptions = (0, _patchOptions2.default)(options),\n      audioContext = _patchOptions.audioContext,\n      fetchCredentials = _patchOptions.fetchCredentials,\n      _patchOptions$ponyfil = _patchOptions.ponyfill,\n      ponyfill = _patchOptions$ponyfil === void 0 ? {\n    AudioContext: window.AudioContext || window.webkitAudioContext\n  } : _patchOptions$ponyfil,\n      speechSynthesisDeploymentId = _patchOptions.speechSynthesisDeploymentId,\n      _patchOptions$speechS = _patchOptions.speechSynthesisOutputFormat,\n      speechSynthesisOutputFormat = _patchOptions$speechS === void 0 ? DEFAULT_OUTPUT_FORMAT : _patchOptions$speechS;\n\n  if (!audioContext && !ponyfill.AudioContext) {\n    console.warn('web-speech-cognitive-services: This browser does not support Web Audio and it will not work with Cognitive Services Speech Services.');\n    return {};\n  }\n\n  var SpeechSynthesis = /*#__PURE__*/function (_EventTarget) {\n    (0, _inherits2.default)(SpeechSynthesis, _EventTarget);\n\n    var _super = _createSuper(SpeechSynthesis);\n\n    function SpeechSynthesis() {\n      var _this;\n\n      (0, _classCallCheck2.default)(this, SpeechSynthesis);\n      _this = _super.call(this);\n      _this.queue = new _AudioContextQueue.default({\n        audioContext: audioContext,\n        ponyfill: ponyfill\n      });\n\n      _this.updateVoices();\n\n      return _this;\n    }\n\n    (0, _createClass2.default)(SpeechSynthesis, [{\n      key: \"cancel\",\n      value: function cancel() {\n        this.queue.stop();\n      }\n    }, {\n      key: \"getVoices\",\n      value: function getVoices() {\n        return EMPTY_ARRAY;\n      }\n    }, {\n      key: \"onvoiceschanged\",\n      get: function get() {\n        return (0, _es.getEventAttributeValue)(this, 'voiceschanged');\n      },\n      set: function set(value) {\n        (0, _es.setEventAttributeValue)(this, 'voiceschanged', value);\n      }\n    }, {\n      key: \"pause\",\n      value: function pause() {\n        this.queue.pause();\n      }\n    }, {\n      key: \"resume\",\n      value: function resume() {\n        this.queue.resume();\n      }\n    }, {\n      key: \"speak\",\n      value: function speak(utterance) {\n        if (!(utterance instanceof _SpeechSynthesisUtterance.default)) {\n          throw new Error('invalid utterance');\n        }\n\n        var _createDeferred = (0, _pDeferEs.default)(),\n            reject = _createDeferred.reject,\n            resolve = _createDeferred.resolve,\n            promise = _createDeferred.promise;\n\n        var handleError = function handleError(_ref) {\n          var errorCode = _ref.error,\n              message = _ref.message;\n          var error = new Error(errorCode);\n          error.stack = message;\n          reject(error);\n        };\n\n        utterance.addEventListener('end', resolve);\n        utterance.addEventListener('error', handleError);\n        utterance.preload({\n          deploymentId: speechSynthesisDeploymentId,\n          fetchCredentials: fetchCredentials,\n          outputFormat: speechSynthesisOutputFormat\n        });\n        this.queue.push(utterance);\n        return promise.finally(function () {\n          utterance.removeEventListener('end', resolve);\n          utterance.removeEventListener('error', handleError);\n        });\n      }\n    }, {\n      key: \"speaking\",\n      get: function get() {\n        return this.queue.speaking;\n      }\n    }, {\n      key: \"updateVoices\",\n      value: function () {\n        var _updateVoices = (0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee3() {\n          var _this2 = this;\n\n          var _yield$fetchCredentia, customVoiceHostname, region, speechSynthesisHostname, subscriptionKey;\n\n          return _regenerator.default.wrap(function _callee3$(_context3) {\n            while (1) {\n              switch (_context3.prev = _context3.next) {\n                case 0:\n                  _context3.next = 2;\n                  return fetchCredentials();\n\n                case 2:\n                  _yield$fetchCredentia = _context3.sent;\n                  customVoiceHostname = _yield$fetchCredentia.customVoiceHostname;\n                  region = _yield$fetchCredentia.region;\n                  speechSynthesisHostname = _yield$fetchCredentia.speechSynthesisHostname;\n                  subscriptionKey = _yield$fetchCredentia.subscriptionKey;\n\n                  if (!speechSynthesisDeploymentId) {\n                    _context3.next = 14;\n                    break;\n                  }\n\n                  if (!subscriptionKey) {\n                    _context3.next = 12;\n                    break;\n                  }\n\n                  console.warn('web-speech-cognitive-services: Listing of custom voice models are only available when using subscription key.');\n                  _context3.next = 12;\n                  return (0, _onErrorResumeNext.default)( /*#__PURE__*/(0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee() {\n                    var voices;\n                    return _regenerator.default.wrap(function _callee$(_context) {\n                      while (1) {\n                        switch (_context.prev = _context.next) {\n                          case 0:\n                            _context.next = 2;\n                            return (0, _fetchCustomVoices.default)({\n                              customVoiceHostname: customVoiceHostname,\n                              deploymentId: speechSynthesisDeploymentId,\n                              region: region,\n                              speechSynthesisHostname: speechSynthesisHostname,\n                              subscriptionKey: subscriptionKey\n                            });\n\n                          case 2:\n                            voices = _context.sent;\n\n                            _this2.getVoices = function () {\n                              return voices;\n                            };\n\n                          case 4:\n                          case \"end\":\n                            return _context.stop();\n                        }\n                      }\n                    }, _callee);\n                  })));\n\n                case 12:\n                  _context3.next = 16;\n                  break;\n\n                case 14:\n                  _context3.next = 16;\n                  return (0, _onErrorResumeNext.default)( /*#__PURE__*/(0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee2() {\n                    var voices;\n                    return _regenerator.default.wrap(function _callee2$(_context2) {\n                      while (1) {\n                        switch (_context2.prev = _context2.next) {\n                          case 0:\n                            _context2.t0 = _fetchVoices.default;\n                            _context2.next = 3;\n                            return fetchCredentials();\n\n                          case 3:\n                            _context2.t1 = _context2.sent;\n                            _context2.next = 6;\n                            return (0, _context2.t0)(_context2.t1);\n\n                          case 6:\n                            voices = _context2.sent;\n\n                            _this2.getVoices = function () {\n                              return voices;\n                            };\n\n                          case 8:\n                          case \"end\":\n                            return _context2.stop();\n                        }\n                      }\n                    }, _callee2);\n                  })));\n\n                case 16:\n                  this.dispatchEvent(new _SpeechSynthesisEvent.default('voiceschanged'));\n\n                case 17:\n                case \"end\":\n                  return _context3.stop();\n              }\n            }\n          }, _callee3, this);\n        }));\n\n        function updateVoices() {\n          return _updateVoices.apply(this, arguments);\n        }\n\n        return updateVoices;\n      }()\n    }]);\n    return SpeechSynthesis;\n  }(_es.EventTarget);\n\n  return {\n    speechSynthesis: new SpeechSynthesis(),\n    SpeechSynthesisEvent: _SpeechSynthesisEvent.default,\n    SpeechSynthesisUtterance: _SpeechSynthesisUtterance.default\n  };\n};\n\nexports.default = _default;","map":{"version":3,"mappings":";;;;;;;;;;;;;;;;;;;;;;;AAEA;;AACA;;AACA;;AAEA;;AACA;;AACA;;AACA;;AACA;;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAEA;;;AACA,IAAMA,qBAAqB,GAAG,kCAA9B;AACA,IAAMC,WAAW,GAAG,EAApB;;eAEe,2BAAW;AACxB,sBAQI,4BAAaC,OAAb,CARJ;AAAA,MACEC,YADF,iBACEA,YADF;AAAA,MAEEC,gBAFF,iBAEEA,gBAFF;AAAA,4CAGEC,QAHF;AAAA,MAGEA,QAHF,sCAGa;AACTC,gBAAY,EAAEC,MAAM,CAACD,YAAPC,IAAuBA,MAAM,CAACC;AADnC,GAHb;AAAA,MAMEC,2BANF,iBAMEA,2BANF;AAAA,4CAOEC,2BAPF;AAAA,MAOEA,2BAPF,sCAOgCV,qBAPhC;;AAUA,MAAI,CAACG,YAAD,IAAiB,CAACE,QAAQ,CAACC,YAA/B,EAA6C;AAC3CK,WAAO,CAACC,IAARD,CACE,sIADFA;AAIA,WAAO,EAAP;AACD;;AAjBuB,MAmBlBE,eAnBkB;AAAA;;AAAA;;AAoBtB,+BAAc;AAAA;;AAAA;AACZC;AAEAA,YAAKC,KAAL,GAAa,IAAIC,0BAAJ,CAAsB;AAAEb,oBAAY,EAAZA,YAAF;AAAgBE,gBAAQ,EAARA;AAAhB,OAAtB,CAAb;;AAEAS,YAAKG,YAAL;;AALY;AAMb;;AA1BqB;AAAAC;AAAAC,aA4BtB,kBAAS;AACP,aAAKJ,KAAL,CAAWK,IAAX;AACD;AA9BqB;AAAAF;AAAAC,aAgCtB,qBAAY;AACV,eAAOlB,WAAP;AACD;AAlCqB;AAAAiB;AAAAG,WAoCtB,eAAsB;AACpB,eAAO,gCAAuB,IAAvB,EAA6B,eAA7B,CAAP;AArCoB;AAAAC,WAwCtB,aAAoBH,KAApB,EAA2B;AACzB,wCAAuB,IAAvB,EAA6B,eAA7B,EAA8CA,KAA9C;AACD;AA1CqB;AAAAD;AAAAC,aA4CtB,iBAAQ;AACN,aAAKJ,KAAL,CAAWQ,KAAX;AACD;AA9CqB;AAAAL;AAAAC,aAgDtB,kBAAS;AACP,aAAKJ,KAAL,CAAWS,MAAX;AACD;AAlDqB;AAAAN;AAAAC,aAoDtB,eAAMM,SAAN,EAAiB;AACf,YAAI,EAAEA,SAAS,YAAYC,iCAAvB,CAAJ,EAAsD;AACpD,gBAAM,IAAIC,KAAJ,CAAU,mBAAV,CAAN;AACD;;AAED,8BAAqC,wBAArC;AAAA,YAAQC,MAAR,mBAAQA,MAAR;AAAA,YAAgBC,OAAhB,mBAAgBA,OAAhB;AAAA,YAAyBC,OAAzB,mBAAyBA,OAAzB;;AACA,YAAMC,WAAW,GAAG,SAAdA,WAAc,OAAmC;AAAA,cAAzBC,SAAyB,QAAhCC,KAAgC;AAAA,cAAdC,OAAc,QAAdA,OAAc;AACrD,cAAMD,KAAK,GAAG,IAAIN,KAAJ,CAAUK,SAAV,CAAd;AAEAC,eAAK,CAACE,KAANF,GAAcC,OAAdD;AAEAL,gBAAM,CAACK,KAAD,CAANL;AALF;;AAQAH,iBAAS,CAACW,gBAAVX,CAA2B,KAA3BA,EAAkCI,OAAlCJ;AACAA,iBAAS,CAACW,gBAAVX,CAA2B,OAA3BA,EAAoCM,WAApCN;AAEAA,iBAAS,CAACY,OAAVZ,CAAkB;AAChBa,sBAAY,EAAE7B,2BADE;AAEhBL,0BAAgB,EAAhBA,gBAFgB;AAGhBmC,sBAAY,EAAE7B;AAHE,SAAlBe;AAMA,aAAKV,KAAL,CAAWyB,IAAX,CAAgBf,SAAhB;AAEA,eAAOK,OAAO,CAACW,OAARX,CAAgB,YAAM;AAC3BL,mBAAS,CAACiB,mBAAVjB,CAA8B,KAA9BA,EAAqCI,OAArCJ;AACAA,mBAAS,CAACiB,mBAAVjB,CAA8B,OAA9BA,EAAuCM,WAAvCN;AAFK,UAAP;AAID;AAjFqB;AAAAP;AAAAG,WAmFtB,eAAe;AACb,eAAO,KAAKN,KAAL,CAAW4B,QAAlB;AACD;AArFqB;AAAAzB;AAAAC;AAAA,oGAuFtB;AAAA;;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAAyB;AAAA,yBAC0FxC,gBAAgB,EAD1G;;AAAA;AAAAyC;AACUC,qCADV,yBACUA;AAAqBC,wBAD/B,yBAC+BA;AAAQC,yCADvC,yBACuCA;AAAyBC,iCADhE,yBACgEA;;AADhE,uBAGMxC,2BAHN;AAAAmC;AAAA;AAAA;;AAAA,uBAIQK,eAJR;AAAAL;AAAA;AAAA;;AAKMjC,yBAAO,CAACC,IAARD,CACE,+GADFA;AALNiC;AAAA,yBASY,sHAAkB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAAM;AAAA,mCACD,gCAAkB;AACrCJ,iDAAmB,EAAnBA,mBADqC;AAErCR,0CAAY,EAAE7B,2BAFuB;AAGrCsC,oCAAM,EAANA,MAHqC;AAIrCC,qDAAuB,EAAvBA,uBAJqC;AAKrCC,6CAAe,EAAfA;AALqC,6BAAlB,CADC;;AAAA;AAChBE,kCADgB,gBAChBA;;AAQNC,kCAAI,CAACC,SAAL,GAAiB;AAAA,qCAAMF,MAAN;AAAjB;;AATsB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAlB,sBATZ;;AAAA;AAAAP;AAAA;;AAAA;AAAAA;AAAA,yBAyBU,sHAAkB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAAU,2CACDC,oBADC;AAAAD;AAAA,mCACiBlD,gBAAgB,EADjC;;AAAA;AAAAkD;AAAAA;AAAA;;AAAA;AAChBH,kCADgB,iBAChBA;;AAENC,kCAAI,CAACC,SAAL,GAAiB;AAAA,qCAAMF,MAAN;AAAjB;;AAHsB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAlB,sBAzBV;;AAAA;AAgCE,uBAAKK,aAAL,CAAmB,IAAIC,6BAAJ,CAAyB,eAAzB,CAAnB;;AAhCF;AAAA;AAAA;AAAA;AAAA;AAAA;AAvFsB;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA,IAmBMC,eAnBN;;AA2HxB,SAAO;AACLC,mBAAe,EAAE,IAAI9C,eAAJ,EADZ;AAEL4C,wBAAoB,EAApBA,6BAFK;AAGL/B,4BAAwB,EAAxBA;AAHK,GAAP","names":["DEFAULT_OUTPUT_FORMAT","EMPTY_ARRAY","options","audioContext","fetchCredentials","ponyfill","AudioContext","window","webkitAudioContext","speechSynthesisDeploymentId","speechSynthesisOutputFormat","console","warn","SpeechSynthesis","_this","queue","AudioContextQueue","updateVoices","key","value","stop","get","set","pause","resume","utterance","SpeechSynthesisUtterance","Error","reject","resolve","promise","handleError","errorCode","error","message","stack","addEventListener","preload","deploymentId","outputFormat","push","finally","removeEventListener","speaking","_context3","_yield$fetchCredentia","customVoiceHostname","region","speechSynthesisHostname","subscriptionKey","_context","voices","_this2","getVoices","_context2","fetchVoices","dispatchEvent","SpeechSynthesisEvent","EventTarget","speechSynthesis"],"sources":["/Users/dylanmurray/Sweng-2022/front/node_modules/web-speech-cognitive-services/src/SpeechServices/TextToSpeech/createSpeechSynthesisPonyfill.js"],"sourcesContent":["/* eslint class-methods-use-this: 0 */\n\nimport { EventTarget, getEventAttributeValue, setEventAttributeValue } from 'event-target-shim/es5';\nimport createDeferred from 'p-defer-es5';\nimport onErrorResumeNext from 'on-error-resume-next';\n\nimport AudioContextQueue from './AudioContextQueue';\nimport fetchCustomVoices from './fetchCustomVoices';\nimport fetchVoices from './fetchVoices';\nimport patchOptions from '../patchOptions';\nimport SpeechSynthesisEvent from './SpeechSynthesisEvent';\nimport SpeechSynthesisUtterance from './SpeechSynthesisUtterance';\n\n// Supported output format can be found at https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/rest-text-to-speech#audio-outputs\nconst DEFAULT_OUTPUT_FORMAT = 'audio-24khz-160kbitrate-mono-mp3';\nconst EMPTY_ARRAY = [];\n\nexport default options => {\n  const {\n    audioContext,\n    fetchCredentials,\n    ponyfill = {\n      AudioContext: window.AudioContext || window.webkitAudioContext\n    },\n    speechSynthesisDeploymentId,\n    speechSynthesisOutputFormat = DEFAULT_OUTPUT_FORMAT\n  } = patchOptions(options);\n\n  if (!audioContext && !ponyfill.AudioContext) {\n    console.warn(\n      'web-speech-cognitive-services: This browser does not support Web Audio and it will not work with Cognitive Services Speech Services.'\n    );\n\n    return {};\n  }\n\n  class SpeechSynthesis extends EventTarget {\n    constructor() {\n      super();\n\n      this.queue = new AudioContextQueue({ audioContext, ponyfill });\n\n      this.updateVoices();\n    }\n\n    cancel() {\n      this.queue.stop();\n    }\n\n    getVoices() {\n      return EMPTY_ARRAY;\n    }\n\n    get onvoiceschanged() {\n      return getEventAttributeValue(this, 'voiceschanged');\n    }\n\n    set onvoiceschanged(value) {\n      setEventAttributeValue(this, 'voiceschanged', value);\n    }\n\n    pause() {\n      this.queue.pause();\n    }\n\n    resume() {\n      this.queue.resume();\n    }\n\n    speak(utterance) {\n      if (!(utterance instanceof SpeechSynthesisUtterance)) {\n        throw new Error('invalid utterance');\n      }\n\n      const { reject, resolve, promise } = createDeferred();\n      const handleError = ({ error: errorCode, message }) => {\n        const error = new Error(errorCode);\n\n        error.stack = message;\n\n        reject(error);\n      };\n\n      utterance.addEventListener('end', resolve);\n      utterance.addEventListener('error', handleError);\n\n      utterance.preload({\n        deploymentId: speechSynthesisDeploymentId,\n        fetchCredentials,\n        outputFormat: speechSynthesisOutputFormat\n      });\n\n      this.queue.push(utterance);\n\n      return promise.finally(() => {\n        utterance.removeEventListener('end', resolve);\n        utterance.removeEventListener('error', handleError);\n      });\n    }\n\n    get speaking() {\n      return this.queue.speaking;\n    }\n\n    async updateVoices() {\n      const { customVoiceHostname, region, speechSynthesisHostname, subscriptionKey } = await fetchCredentials();\n\n      if (speechSynthesisDeploymentId) {\n        if (subscriptionKey) {\n          console.warn(\n            'web-speech-cognitive-services: Listing of custom voice models are only available when using subscription key.'\n          );\n\n          await onErrorResumeNext(async () => {\n            const voices = await fetchCustomVoices({\n              customVoiceHostname,\n              deploymentId: speechSynthesisDeploymentId,\n              region,\n              speechSynthesisHostname,\n              subscriptionKey\n            });\n\n            this.getVoices = () => voices;\n          });\n        }\n      } else {\n        // If fetch voice list failed, we will not emit \"voiceschanged\" event.\n        // In the spec, there is no \"error\" event.\n\n        await onErrorResumeNext(async () => {\n          const voices = await fetchVoices(await fetchCredentials());\n\n          this.getVoices = () => voices;\n        });\n      }\n\n      this.dispatchEvent(new SpeechSynthesisEvent('voiceschanged'));\n    }\n  }\n\n  return {\n    speechSynthesis: new SpeechSynthesis(),\n    SpeechSynthesisEvent,\n    SpeechSynthesisUtterance\n  };\n};\n"]},"metadata":{},"sourceType":"script"}