{"ast":null,"code":"\"use strict\";\n\nvar _interopRequireDefault = require(\"@babel/runtime/helpers/interopRequireDefault\");\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.createSpeechRecognitionPonyfillFromRecognizer = createSpeechRecognitionPonyfillFromRecognizer;\nexports.default = void 0;\n\nvar _regenerator = _interopRequireDefault(require(\"@babel/runtime/regenerator\"));\n\nvar _toConsumableArray2 = _interopRequireDefault(require(\"@babel/runtime/helpers/toConsumableArray\"));\n\nvar _createClass2 = _interopRequireDefault(require(\"@babel/runtime/helpers/createClass\"));\n\nvar _defineProperty2 = _interopRequireDefault(require(\"@babel/runtime/helpers/defineProperty\"));\n\nvar _asyncToGenerator2 = _interopRequireDefault(require(\"@babel/runtime/helpers/asyncToGenerator\"));\n\nvar _classCallCheck2 = _interopRequireDefault(require(\"@babel/runtime/helpers/classCallCheck\"));\n\nvar _inherits2 = _interopRequireDefault(require(\"@babel/runtime/helpers/inherits\"));\n\nvar _possibleConstructorReturn2 = _interopRequireDefault(require(\"@babel/runtime/helpers/possibleConstructorReturn\"));\n\nvar _getPrototypeOf2 = _interopRequireDefault(require(\"@babel/runtime/helpers/getPrototypeOf\"));\n\nvar _es = require(\"event-target-shim/es5\");\n\nvar _cognitiveServiceEventResultToWebSpeechRecognitionResultList = _interopRequireDefault(require(\"./cognitiveServiceEventResultToWebSpeechRecognitionResultList\"));\n\nvar _createPromiseQueue = _interopRequireDefault(require(\"../../Util/createPromiseQueue\"));\n\nvar _patchOptions2 = _interopRequireDefault(require(\"../patchOptions\"));\n\nvar _SpeechGrammarList = _interopRequireDefault(require(\"./SpeechGrammarList\"));\n\nvar _SpeechSDK = _interopRequireDefault(require(\"../SpeechSDK\"));\n\nfunction ownKeys(object, enumerableOnly) {\n  var keys = Object.keys(object);\n\n  if (Object.getOwnPropertySymbols) {\n    var symbols = Object.getOwnPropertySymbols(object);\n\n    if (enumerableOnly) {\n      symbols = symbols.filter(function (sym) {\n        return Object.getOwnPropertyDescriptor(object, sym).enumerable;\n      });\n    }\n\n    keys.push.apply(keys, symbols);\n  }\n\n  return keys;\n}\n\nfunction _objectSpread(target) {\n  for (var i = 1; i < arguments.length; i++) {\n    var source = arguments[i] != null ? arguments[i] : {};\n\n    if (i % 2) {\n      ownKeys(Object(source), true).forEach(function (key) {\n        (0, _defineProperty2.default)(target, key, source[key]);\n      });\n    } else if (Object.getOwnPropertyDescriptors) {\n      Object.defineProperties(target, Object.getOwnPropertyDescriptors(source));\n    } else {\n      ownKeys(Object(source)).forEach(function (key) {\n        Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key));\n      });\n    }\n  }\n\n  return target;\n}\n\nfunction _createSuper(Derived) {\n  var hasNativeReflectConstruct = _isNativeReflectConstruct();\n\n  return function _createSuperInternal() {\n    var Super = (0, _getPrototypeOf2.default)(Derived),\n        result;\n\n    if (hasNativeReflectConstruct) {\n      var NewTarget = (0, _getPrototypeOf2.default)(this).constructor;\n      result = Reflect.construct(Super, arguments, NewTarget);\n    } else {\n      result = Super.apply(this, arguments);\n    }\n\n    return (0, _possibleConstructorReturn2.default)(this, result);\n  };\n}\n\nfunction _isNativeReflectConstruct() {\n  if (typeof Reflect === \"undefined\" || !Reflect.construct) return false;\n  if (Reflect.construct.sham) return false;\n  if (typeof Proxy === \"function\") return true;\n\n  try {\n    Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {}));\n    return true;\n  } catch (e) {\n    return false;\n  }\n} // https://docs.microsoft.com/en-us/javascript/api/microsoft-cognitiveservices-speech-sdk/speechconfig?view=azure-node-latest#outputformat\n// {\n//   \"RecognitionStatus\": \"Success\",\n//   \"Offset\": 900000,\n//   \"Duration\": 49000000,\n//   \"NBest\": [\n//     {\n//       \"Confidence\": 0.738919,\n//       \"Lexical\": \"second\",\n//       \"ITN\": \"second\",\n//       \"MaskedITN\": \"second\",\n//       \"Display\": \"Second.\"\n//     }\n//   ]\n// }\n// {\n//   \"RecognitionStatus\": \"InitialSilenceTimeout\",\n//   \"Offset\": 50000000,\n//   \"Duration\": 0\n// }\n\n\nvar AudioConfig = _SpeechSDK.default.AudioConfig,\n    OutputFormat = _SpeechSDK.default.OutputFormat,\n    ResultReason = _SpeechSDK.default.ResultReason,\n    SpeechConfig = _SpeechSDK.default.SpeechConfig,\n    SpeechRecognizer = _SpeechSDK.default.SpeechRecognizer;\n\nfunction serializeRecognitionResult(_ref) {\n  var duration = _ref.duration,\n      errorDetails = _ref.errorDetails,\n      json = _ref.json,\n      offset = _ref.offset,\n      properties = _ref.properties,\n      reason = _ref.reason,\n      resultId = _ref.resultId,\n      text = _ref.text;\n  return {\n    duration: duration,\n    errorDetails: errorDetails,\n    json: JSON.parse(json),\n    offset: offset,\n    properties: properties,\n    reason: reason,\n    resultId: resultId,\n    text: text\n  };\n}\n\nfunction averageAmplitude(arrayBuffer) {\n  var array = new Int16Array(arrayBuffer);\n  return [].reduce.call(array, function (averageAmplitude, amplitude) {\n    return averageAmplitude + Math.abs(amplitude);\n  }, 0) / array.length;\n}\n\nfunction cognitiveServicesAsyncToPromise(fn) {\n  return function () {\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n\n    return new Promise(function (resolve, reject) {\n      return fn.apply(void 0, args.concat([resolve, reject]));\n    });\n  };\n}\n\nvar SpeechRecognitionEvent = /*#__PURE__*/function (_Event) {\n  (0, _inherits2.default)(SpeechRecognitionEvent, _Event);\n\n  var _super = _createSuper(SpeechRecognitionEvent);\n\n  function SpeechRecognitionEvent(type) {\n    var _this;\n\n    var _ref2 = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {},\n        data = _ref2.data,\n        emma = _ref2.emma,\n        interpretation = _ref2.interpretation,\n        resultIndex = _ref2.resultIndex,\n        results = _ref2.results;\n\n    (0, _classCallCheck2.default)(this, SpeechRecognitionEvent);\n    _this = _super.call(this, type);\n    _this.data = data;\n    _this.emma = emma;\n    _this.interpretation = interpretation;\n    _this.resultIndex = resultIndex;\n    _this.results = results;\n    return _this;\n  }\n\n  return SpeechRecognitionEvent;\n}(_es.Event);\n\nfunction prepareAudioConfig(audioConfig) {\n  var originalAttach = audioConfig.attach;\n  var boundOriginalAttach = audioConfig.attach.bind(audioConfig);\n  var firstChunk;\n  var muted; // We modify \"attach\" function and detect when audible chunk is read.\n  // We will only modify \"attach\" function once.\n\n  audioConfig.attach = /*#__PURE__*/(0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee2() {\n    var reader;\n    return _regenerator.default.wrap(function _callee2$(_context2) {\n      while (1) {\n        switch (_context2.prev = _context2.next) {\n          case 0:\n            _context2.next = 2;\n            return boundOriginalAttach();\n\n          case 2:\n            reader = _context2.sent;\n            return _context2.abrupt(\"return\", _objectSpread(_objectSpread({}, reader), {}, {\n              read: function () {\n                var _read = (0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee() {\n                  var chunk;\n                  return _regenerator.default.wrap(function _callee$(_context) {\n                    while (1) {\n                      switch (_context.prev = _context.next) {\n                        case 0:\n                          _context.next = 2;\n                          return reader.read();\n\n                        case 2:\n                          chunk = _context.sent; // The magic number 150 is measured by:\n                          // 1. Set microphone volume to 0\n                          // 2. Observe the amplitude (100-110) for the first few chunks\n                          //    (There is a short static caught when turning on the microphone)\n                          // 3. Set the number a bit higher than the observation\n\n                          if (!firstChunk && averageAmplitude(chunk.buffer) > 150) {\n                            audioConfig.events.onEvent({\n                              name: 'FirstAudibleChunk'\n                            });\n                            firstChunk = true;\n                          }\n\n                          if (!muted) {\n                            _context.next = 6;\n                            break;\n                          }\n\n                          return _context.abrupt(\"return\", {\n                            buffer: new ArrayBuffer(0),\n                            isEnd: true,\n                            timeReceived: Date.now()\n                          });\n\n                        case 6:\n                          return _context.abrupt(\"return\", chunk);\n\n                        case 7:\n                        case \"end\":\n                          return _context.stop();\n                      }\n                    }\n                  }, _callee);\n                }));\n\n                function read() {\n                  return _read.apply(this, arguments);\n                }\n\n                return read;\n              }()\n            }));\n\n          case 4:\n          case \"end\":\n            return _context2.stop();\n        }\n      }\n    }, _callee2);\n  }));\n  return {\n    audioConfig: audioConfig,\n    pause: function pause() {\n      muted = true;\n    },\n    unprepare: function unprepare() {\n      audioConfig.attach = originalAttach;\n    }\n  };\n}\n\nfunction createSpeechRecognitionPonyfillFromRecognizer(_ref4) {\n  var createRecognizer = _ref4.createRecognizer,\n      enableTelemetry = _ref4.enableTelemetry,\n      looseEvents = _ref4.looseEvents,\n      referenceGrammars = _ref4.referenceGrammars,\n      textNormalization = _ref4.textNormalization; // If enableTelemetry is set to null or non-boolean, we will default to true.\n\n  SpeechRecognizer.enableTelemetry(enableTelemetry !== false);\n\n  var SpeechRecognition = /*#__PURE__*/function (_EventTarget) {\n    (0, _inherits2.default)(SpeechRecognition, _EventTarget);\n\n    var _super2 = _createSuper(SpeechRecognition);\n\n    function SpeechRecognition() {\n      var _this2;\n\n      (0, _classCallCheck2.default)(this, SpeechRecognition);\n      _this2 = _super2.call(this);\n      _this2._continuous = false;\n      _this2._interimResults = false;\n      _this2._lang = typeof window !== 'undefined' ? window.document.documentElement.getAttribute('lang') || window.navigator.language : 'en-US';\n      _this2._grammars = new _SpeechGrammarList.default();\n      _this2._maxAlternatives = 1;\n      return _this2;\n    }\n\n    (0, _createClass2.default)(SpeechRecognition, [{\n      key: \"emitCognitiveServices\",\n      value: function emitCognitiveServices(type, event) {\n        this.dispatchEvent(new SpeechRecognitionEvent('cognitiveservices', {\n          data: _objectSpread(_objectSpread({}, event), {}, {\n            type: type\n          })\n        }));\n      }\n    }, {\n      key: \"continuous\",\n      get: function get() {\n        return this._continuous;\n      },\n      set: function set(value) {\n        this._continuous = value;\n      }\n    }, {\n      key: \"grammars\",\n      get: function get() {\n        return this._grammars;\n      },\n      set: function set(value) {\n        if (value instanceof _SpeechGrammarList.default) {\n          this._grammars = value;\n        } else {\n          throw new Error(\"The provided value is not of type 'SpeechGrammarList'\");\n        }\n      }\n    }, {\n      key: \"interimResults\",\n      get: function get() {\n        return this._interimResults;\n      },\n      set: function set(value) {\n        this._interimResults = value;\n      }\n    }, {\n      key: \"maxAlternatives\",\n      get: function get() {\n        return this._maxAlternatives;\n      },\n      set: function set(value) {\n        this._maxAlternatives = value;\n      }\n    }, {\n      key: \"lang\",\n      get: function get() {\n        return this._lang;\n      },\n      set: function set(value) {\n        this._lang = value;\n      }\n    }, {\n      key: \"onaudioend\",\n      get: function get() {\n        return (0, _es.getEventAttributeValue)(this, 'audioend');\n      },\n      set: function set(value) {\n        (0, _es.setEventAttributeValue)(this, 'audioend', value);\n      }\n    }, {\n      key: \"onaudiostart\",\n      get: function get() {\n        return (0, _es.getEventAttributeValue)(this, 'audiostart');\n      },\n      set: function set(value) {\n        (0, _es.setEventAttributeValue)(this, 'audiostart', value);\n      }\n    }, {\n      key: \"oncognitiveservices\",\n      get: function get() {\n        return (0, _es.getEventAttributeValue)(this, 'cognitiveservices');\n      },\n      set: function set(value) {\n        (0, _es.setEventAttributeValue)(this, 'cognitiveservices', value);\n      }\n    }, {\n      key: \"onend\",\n      get: function get() {\n        return (0, _es.getEventAttributeValue)(this, 'end');\n      },\n      set: function set(value) {\n        (0, _es.setEventAttributeValue)(this, 'end', value);\n      }\n    }, {\n      key: \"onerror\",\n      get: function get() {\n        return (0, _es.getEventAttributeValue)(this, 'error');\n      },\n      set: function set(value) {\n        (0, _es.setEventAttributeValue)(this, 'error', value);\n      }\n    }, {\n      key: \"onresult\",\n      get: function get() {\n        return (0, _es.getEventAttributeValue)(this, 'result');\n      },\n      set: function set(value) {\n        (0, _es.setEventAttributeValue)(this, 'result', value);\n      }\n    }, {\n      key: \"onsoundend\",\n      get: function get() {\n        return (0, _es.getEventAttributeValue)(this, 'soundend');\n      },\n      set: function set(value) {\n        (0, _es.setEventAttributeValue)(this, 'soundend', value);\n      }\n    }, {\n      key: \"onsoundstart\",\n      get: function get() {\n        return (0, _es.getEventAttributeValue)(this, 'soundstart');\n      },\n      set: function set(value) {\n        (0, _es.setEventAttributeValue)(this, 'soundstart', value);\n      }\n    }, {\n      key: \"onspeechend\",\n      get: function get() {\n        return (0, _es.getEventAttributeValue)(this, 'speechend');\n      },\n      set: function set(value) {\n        (0, _es.setEventAttributeValue)(this, 'speechend', value);\n      }\n    }, {\n      key: \"onspeechstart\",\n      get: function get() {\n        return (0, _es.getEventAttributeValue)(this, 'speechstart');\n      },\n      set: function set(value) {\n        (0, _es.setEventAttributeValue)(this, 'speechstart', value);\n      }\n    }, {\n      key: \"onstart\",\n      get: function get() {\n        return (0, _es.getEventAttributeValue)(this, 'start');\n      },\n      set: function set(value) {\n        (0, _es.setEventAttributeValue)(this, 'start', value);\n      }\n    }, {\n      key: \"start\",\n      value: function start() {\n        var _this3 = this;\n\n        this._startOnce().catch(function (err) {\n          _this3.dispatchEvent(new ErrorEvent('error', {\n            error: err,\n            message: err && (err.stack || err.message)\n          }));\n        });\n      }\n    }, {\n      key: \"_startOnce\",\n      value: function () {\n        var _startOnce2 = (0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee3() {\n          var _this4 = this;\n\n          var recognizer, _prepareAudioConfig, pause, unprepare, queue, soundStarted, speechStarted, stopping, _recognizer$audioConf, detachAudioConfigEvent, phrases, dynamicGrammar, audioStarted, finalEvent, finalizedResults, _loop, loop, _ret;\n\n          return _regenerator.default.wrap(function _callee3$(_context4) {\n            while (1) {\n              switch (_context4.prev = _context4.next) {\n                case 0:\n                  _context4.next = 2;\n                  return createRecognizer(this.lang);\n\n                case 2:\n                  recognizer = _context4.sent;\n                  _prepareAudioConfig = prepareAudioConfig(recognizer.audioConfig), pause = _prepareAudioConfig.pause, unprepare = _prepareAudioConfig.unprepare;\n                  _context4.prev = 4;\n                  queue = (0, _createPromiseQueue.default)();\n                  _recognizer$audioConf = recognizer.audioConfig.events.attach(function (event) {\n                    var name = event.name;\n\n                    if (name === 'AudioSourceReadyEvent') {\n                      queue.push({\n                        audioSourceReady: {}\n                      });\n                    } else if (name === 'AudioSourceOffEvent') {\n                      queue.push({\n                        audioSourceOff: {}\n                      });\n                    } else if (name === 'FirstAudibleChunk') {\n                      queue.push({\n                        firstAudibleChunk: {}\n                      });\n                    }\n                  }), detachAudioConfigEvent = _recognizer$audioConf.detach;\n\n                  recognizer.canceled = function (_, _ref5) {\n                    var errorDetails = _ref5.errorDetails,\n                        offset = _ref5.offset,\n                        reason = _ref5.reason,\n                        sessionId = _ref5.sessionId;\n                    queue.push({\n                      canceled: {\n                        errorDetails: errorDetails,\n                        offset: offset,\n                        reason: reason,\n                        sessionId: sessionId\n                      }\n                    });\n                  };\n\n                  recognizer.recognized = function (_, _ref6) {\n                    var offset = _ref6.offset,\n                        result = _ref6.result,\n                        sessionId = _ref6.sessionId;\n                    queue.push({\n                      recognized: {\n                        offset: offset,\n                        result: serializeRecognitionResult(result),\n                        sessionId: sessionId\n                      }\n                    });\n                  };\n\n                  recognizer.recognizing = function (_, _ref7) {\n                    var offset = _ref7.offset,\n                        result = _ref7.result,\n                        sessionId = _ref7.sessionId;\n                    queue.push({\n                      recognizing: {\n                        offset: offset,\n                        result: serializeRecognitionResult(result),\n                        sessionId: sessionId\n                      }\n                    });\n                  };\n\n                  recognizer.sessionStarted = function (_, _ref8) {\n                    var sessionId = _ref8.sessionId;\n                    queue.push({\n                      sessionStarted: {\n                        sessionId: sessionId\n                      }\n                    });\n                  };\n\n                  recognizer.sessionStopped = function (_, _ref9) {\n                    var sessionId = _ref9.sessionId; // \"sessionStopped\" is never fired, probably because we are using startContinuousRecognitionAsync instead of recognizeOnceAsync.\n\n                    queue.push({\n                      sessionStopped: {\n                        sessionId: sessionId\n                      }\n                    });\n                  };\n\n                  recognizer.speechStartDetected = function (_, _ref10) {\n                    var offset = _ref10.offset,\n                        sessionId = _ref10.sessionId;\n                    queue.push({\n                      speechStartDetected: {\n                        offset: offset,\n                        sessionId: sessionId\n                      }\n                    });\n                  };\n\n                  recognizer.speechEndDetected = function (_, _ref11) {\n                    var sessionId = _ref11.sessionId; // \"speechEndDetected\" is never fired, probably because we are using startContinuousRecognitionAsync instead of recognizeOnceAsync.\n                    // Update: \"speechEndDetected\" is fired for DLSpeech.listenOnceAsync()\n\n                    queue.push({\n                      speechEndDetected: {\n                        sessionId: sessionId\n                      }\n                    });\n                  };\n\n                  phrases = this.grammars.phrases; // HACK: We are using the internal of SpeechRecognizer because they did not expose it\n\n                  dynamicGrammar = recognizer.privReco.dynamicGrammar;\n                  referenceGrammars && referenceGrammars.length && dynamicGrammar.addReferenceGrammar(referenceGrammars);\n                  phrases && phrases.length && dynamicGrammar.addPhrase(phrases);\n                  _context4.next = 20;\n                  return cognitiveServicesAsyncToPromise(recognizer.startContinuousRecognitionAsync.bind(recognizer))();\n\n                case 20:\n                  if (recognizer.stopContinuousRecognitionAsync) {\n                    this.abort = function () {\n                      return queue.push({\n                        abort: {}\n                      });\n                    };\n\n                    this.stop = function () {\n                      return queue.push({\n                        stop: {}\n                      });\n                    };\n                  } else {\n                    this.abort = this.stop = undefined;\n                  }\n\n                  finalizedResults = [];\n                  _loop = /*#__PURE__*/_regenerator.default.mark(function _loop(loop) {\n                    var event, abort, audioSourceOff, audioSourceReady, canceled, firstAudibleChunk, recognized, recognizing, stop, errorMessage, result, recognizable;\n                    return _regenerator.default.wrap(function _loop$(_context3) {\n                      while (1) {\n                        switch (_context3.prev = _context3.next) {\n                          case 0:\n                            _context3.next = 2;\n                            return queue.shift();\n\n                          case 2:\n                            event = _context3.sent;\n                            abort = event.abort, audioSourceOff = event.audioSourceOff, audioSourceReady = event.audioSourceReady, canceled = event.canceled, firstAudibleChunk = event.firstAudibleChunk, recognized = event.recognized, recognizing = event.recognizing, stop = event.stop; // We are emitting event \"cognitiveservices\" for debugging purpose.\n\n                            Object.keys(event).forEach(function (name) {\n                              return _this4.emitCognitiveServices(name, event[name]);\n                            });\n                            errorMessage = canceled && canceled.errorDetails;\n\n                            if (!/Permission[\\t-\\r \\xA0\\u1680\\u2000-\\u200A\\u2028\\u2029\\u202F\\u205F\\u3000\\uFEFF]denied/.test(errorMessage || '')) {\n                              _context3.next = 9;\n                              break;\n                            } // If microphone is not allowed, we should not emit \"start\" event.\n\n\n                            finalEvent = {\n                              error: 'not-allowed',\n                              type: 'error'\n                            };\n                            return _context3.abrupt(\"return\", \"break\");\n\n                          case 9:\n                            if (!loop) {\n                              _this4.dispatchEvent(new SpeechRecognitionEvent('start'));\n                            }\n\n                            if (!errorMessage) {\n                              _context3.next = 15;\n                              break;\n                            }\n\n                            if (/1006/.test(errorMessage)) {\n                              if (!audioStarted) {\n                                _this4.dispatchEvent(new SpeechRecognitionEvent('audiostart'));\n\n                                _this4.dispatchEvent(new SpeechRecognitionEvent('audioend'));\n                              }\n\n                              finalEvent = {\n                                error: 'network',\n                                type: 'error'\n                              };\n                            } else {\n                              finalEvent = {\n                                error: 'unknown',\n                                type: 'error'\n                              };\n                            }\n\n                            return _context3.abrupt(\"return\", \"break\");\n\n                          case 15:\n                            if (!(abort || stop)) {\n                              _context3.next = 22;\n                              break;\n                            }\n\n                            if (abort) {\n                              finalEvent = {\n                                error: 'aborted',\n                                type: 'error'\n                              }; // If we are aborting, we will ignore lingering recognizing/recognized events. But if we are stopping, we need them.\n\n                              stopping = 'abort';\n                            } else {\n                              // When we pause, we will send { isEnd: true }, Speech Services will send us \"recognized\" event.\n                              pause();\n                              stopping = 'stop';\n                            } // Abort should not be dispatched without support of \"stopContinuousRecognitionAsync\".\n                            // But for defensive purpose, we make sure \"stopContinuousRecognitionAsync\" is available before we can call.\n\n\n                            if (!(abort && recognizer.stopContinuousRecognitionAsync)) {\n                              _context3.next = 20;\n                              break;\n                            }\n\n                            _context3.next = 20;\n                            return cognitiveServicesAsyncToPromise(recognizer.stopContinuousRecognitionAsync.bind(recognizer))();\n\n                          case 20:\n                            _context3.next = 61;\n                            break;\n\n                          case 22:\n                            if (!audioSourceReady) {\n                              _context3.next = 27;\n                              break;\n                            }\n\n                            _this4.dispatchEvent(new SpeechRecognitionEvent('audiostart'));\n\n                            audioStarted = true;\n                            _context3.next = 61;\n                            break;\n\n                          case 27:\n                            if (!firstAudibleChunk) {\n                              _context3.next = 32;\n                              break;\n                            }\n\n                            _this4.dispatchEvent(new SpeechRecognitionEvent('soundstart'));\n\n                            soundStarted = true;\n                            _context3.next = 61;\n                            break;\n\n                          case 32:\n                            if (!audioSourceOff) {\n                              _context3.next = 40;\n                              break;\n                            } // Looks like we don't need this line and all the tests are still working.\n                            // Guessing probably stopping is already truthy.\n                            // stopping = true;\n\n\n                            speechStarted && _this4.dispatchEvent(new SpeechRecognitionEvent('speechend'));\n                            soundStarted && _this4.dispatchEvent(new SpeechRecognitionEvent('soundend'));\n                            audioStarted && _this4.dispatchEvent(new SpeechRecognitionEvent('audioend'));\n                            audioStarted = soundStarted = speechStarted = false;\n                            return _context3.abrupt(\"return\", \"break\");\n\n                          case 40:\n                            if (!(stopping !== 'abort')) {\n                              _context3.next = 61;\n                              break;\n                            }\n\n                            if (!(recognized && recognized.result && recognized.result.reason === ResultReason.NoMatch)) {\n                              _context3.next = 45;\n                              break;\n                            }\n\n                            finalEvent = {\n                              error: 'no-speech',\n                              type: 'error'\n                            };\n                            _context3.next = 61;\n                            break;\n\n                          case 45:\n                            if (!(recognized || recognizing)) {\n                              _context3.next = 61;\n                              break;\n                            }\n\n                            if (!audioStarted) {\n                              // Unconfirmed prevention of quirks\n                              _this4.dispatchEvent(new SpeechRecognitionEvent('audiostart'));\n\n                              audioStarted = true;\n                            }\n\n                            if (!soundStarted) {\n                              _this4.dispatchEvent(new SpeechRecognitionEvent('soundstart'));\n\n                              soundStarted = true;\n                            }\n\n                            if (!speechStarted) {\n                              _this4.dispatchEvent(new SpeechRecognitionEvent('speechstart'));\n\n                              speechStarted = true;\n                            }\n\n                            if (!recognized) {\n                              _context3.next = 60;\n                              break;\n                            }\n\n                            result = (0, _cognitiveServiceEventResultToWebSpeechRecognitionResultList.default)(recognized.result, {\n                              maxAlternatives: _this4.maxAlternatives,\n                              textNormalization: textNormalization\n                            });\n                            recognizable = !!result[0].transcript;\n\n                            if (recognizable) {\n                              finalizedResults = [].concat((0, _toConsumableArray2.default)(finalizedResults), [result]);\n                              _this4.continuous && _this4.dispatchEvent(new SpeechRecognitionEvent('result', {\n                                results: finalizedResults\n                              }));\n                            } // If it is continuous, we just sent the finalized results. So we don't need to send it again after \"audioend\" event.\n\n\n                            if (_this4.continuous && recognizable) {\n                              finalEvent = null;\n                            } else {\n                              finalEvent = {\n                                results: finalizedResults,\n                                type: 'result'\n                              };\n                            }\n\n                            if (!(!_this4.continuous && recognizer.stopContinuousRecognitionAsync)) {\n                              _context3.next = 57;\n                              break;\n                            }\n\n                            _context3.next = 57;\n                            return cognitiveServicesAsyncToPromise(recognizer.stopContinuousRecognitionAsync.bind(recognizer))();\n\n                          case 57:\n                            // If event order can be loosened, we can send the recognized event as soon as we receive it.\n                            // 1. If it is not recognizable (no-speech), we should send an \"error\" event just before \"end\" event. We will not loosen \"error\" events.\n                            if (looseEvents && finalEvent && recognizable) {\n                              _this4.dispatchEvent(new SpeechRecognitionEvent(finalEvent.type, finalEvent));\n\n                              finalEvent = null;\n                            }\n\n                            _context3.next = 61;\n                            break;\n\n                          case 60:\n                            if (recognizing) {\n                              _this4.interimResults && _this4.dispatchEvent(new SpeechRecognitionEvent('result', {\n                                results: [].concat((0, _toConsumableArray2.default)(finalizedResults), [(0, _cognitiveServiceEventResultToWebSpeechRecognitionResultList.default)(recognizing.result, {\n                                  maxAlternatives: _this4.maxAlternatives,\n                                  textNormalization: textNormalization\n                                })])\n                              }));\n                            }\n\n                          case 61:\n                          case \"end\":\n                            return _context3.stop();\n                        }\n                      }\n                    }, _loop);\n                  });\n                  loop = 0;\n\n                case 24:\n                  if (!(!stopping || audioStarted)) {\n                    _context4.next = 32;\n                    break;\n                  }\n\n                  return _context4.delegateYield(_loop(loop), \"t0\", 26);\n\n                case 26:\n                  _ret = _context4.t0;\n\n                  if (!(_ret === \"break\")) {\n                    _context4.next = 29;\n                    break;\n                  }\n\n                  return _context4.abrupt(\"break\", 32);\n\n                case 29:\n                  loop++;\n                  _context4.next = 24;\n                  break;\n\n                case 32:\n                  if (speechStarted) {\n                    this.dispatchEvent(new SpeechRecognitionEvent('speechend'));\n                  }\n\n                  if (soundStarted) {\n                    this.dispatchEvent(new SpeechRecognitionEvent('soundend'));\n                  }\n\n                  if (audioStarted) {\n                    this.dispatchEvent(new SpeechRecognitionEvent('audioend'));\n                  }\n\n                  if (finalEvent) {\n                    if (finalEvent.type === 'result' && !finalEvent.results.length) {\n                      finalEvent = {\n                        error: 'no-speech',\n                        type: 'error'\n                      };\n                    }\n\n                    if (finalEvent.type === 'error') {\n                      this.dispatchEvent(new ErrorEvent('error', finalEvent));\n                    } else {\n                      this.dispatchEvent(new SpeechRecognitionEvent(finalEvent.type, finalEvent));\n                    }\n                  } // Even though there is no \"start\" event emitted, we will still emit \"end\" event\n                  // This is mainly for \"microphone blocked\" story.\n\n\n                  this.dispatchEvent(new SpeechRecognitionEvent('end'));\n                  detachAudioConfigEvent();\n                  _context4.next = 44;\n                  break;\n\n                case 40:\n                  _context4.prev = 40;\n                  _context4.t1 = _context4[\"catch\"](4); // Logging out the erorr because Speech SDK would fail silently.\n\n                  console.error(_context4.t1);\n                  throw _context4.t1;\n\n                case 44:\n                  _context4.prev = 44;\n                  unprepare();\n                  recognizer.dispose();\n                  return _context4.finish(44);\n\n                case 48:\n                case \"end\":\n                  return _context4.stop();\n              }\n            }\n          }, _callee3, this, [[4, 40, 44, 48]]);\n        }));\n\n        function _startOnce() {\n          return _startOnce2.apply(this, arguments);\n        }\n\n        return _startOnce;\n      }()\n    }]);\n    return SpeechRecognition;\n  }(_es.EventTarget);\n\n  return {\n    SpeechGrammarList: _SpeechGrammarList.default,\n    SpeechRecognition: SpeechRecognition,\n    SpeechRecognitionEvent: SpeechRecognitionEvent\n  };\n}\n\nvar _default = function _default(options) {\n  var _patchOptions = (0, _patchOptions2.default)(options),\n      _patchOptions$audioCo = _patchOptions.audioConfig,\n      audioConfig = _patchOptions$audioCo === void 0 ? AudioConfig.fromDefaultMicrophoneInput() : _patchOptions$audioCo,\n      _patchOptions$enableT = _patchOptions.enableTelemetry,\n      enableTelemetry = _patchOptions$enableT === void 0 ? true : _patchOptions$enableT,\n      fetchCredentials = _patchOptions.fetchCredentials,\n      looseEvents = _patchOptions.looseEvents,\n      referenceGrammars = _patchOptions.referenceGrammars,\n      speechRecognitionEndpointId = _patchOptions.speechRecognitionEndpointId,\n      _patchOptions$textNor = _patchOptions.textNormalization,\n      textNormalization = _patchOptions$textNor === void 0 ? 'display' : _patchOptions$textNor;\n\n  if (!audioConfig && (!window.navigator.mediaDevices || !window.navigator.mediaDevices.getUserMedia)) {\n    console.warn('web-speech-cognitive-services: This browser does not support WebRTC and it will not work with Cognitive Services Speech Services.');\n    return {};\n  }\n\n  var createRecognizer = /*#__PURE__*/function () {\n    var _ref12 = (0, _asyncToGenerator2.default)( /*#__PURE__*/_regenerator.default.mark(function _callee4(lang) {\n      var _yield$fetchCredentia, authorizationToken, region, speechRecognitionHostname, subscriptionKey, speechConfig, host;\n\n      return _regenerator.default.wrap(function _callee4$(_context5) {\n        while (1) {\n          switch (_context5.prev = _context5.next) {\n            case 0:\n              _context5.next = 2;\n              return fetchCredentials();\n\n            case 2:\n              _yield$fetchCredentia = _context5.sent;\n              authorizationToken = _yield$fetchCredentia.authorizationToken;\n              region = _yield$fetchCredentia.region;\n              speechRecognitionHostname = _yield$fetchCredentia.speechRecognitionHostname;\n              subscriptionKey = _yield$fetchCredentia.subscriptionKey;\n\n              if (speechRecognitionHostname) {\n                host = {\n                  hostname: speechRecognitionHostname,\n                  port: 443,\n                  protocol: 'wss:'\n                };\n\n                if (authorizationToken) {\n                  speechConfig = SpeechConfig.fromHost(host);\n                  speechConfig.authorizationToken = authorizationToken;\n                } else {\n                  speechConfig = SpeechConfig.fromHost(host, subscriptionKey);\n                }\n              } else {\n                speechConfig = authorizationToken ? SpeechConfig.fromAuthorizationToken(authorizationToken, region) : SpeechConfig.fromSubscription(subscriptionKey, region);\n              }\n\n              if (speechRecognitionEndpointId) {\n                speechConfig.endpointId = speechRecognitionEndpointId;\n              }\n\n              speechConfig.outputFormat = OutputFormat.Detailed;\n              speechConfig.speechRecognitionLanguage = lang || 'en-US';\n              return _context5.abrupt(\"return\", new SpeechRecognizer(speechConfig, audioConfig));\n\n            case 12:\n            case \"end\":\n              return _context5.stop();\n          }\n        }\n      }, _callee4);\n    }));\n\n    return function createRecognizer(_x) {\n      return _ref12.apply(this, arguments);\n    };\n  }();\n\n  return createSpeechRecognitionPonyfillFromRecognizer({\n    audioConfig: audioConfig,\n    createRecognizer: createRecognizer,\n    enableTelemetry: enableTelemetry,\n    looseEvents: looseEvents,\n    referenceGrammars: referenceGrammars,\n    textNormalization: textNormalization\n  });\n};\n\nexports.default = _default;","map":{"version":3,"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;AAMA;;AAEA;;AACA;;AACA;;AACA;;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;;;AAEA,IAAQA,WAAR,GAAoFC,mBAA5ED,WAAR;AAAA,IAAqBE,YAArB,GAAoFD,mBAA/DC,YAArB;AAAA,IAAmCC,YAAnC,GAAoFF,mBAAjDE,YAAnC;AAAA,IAAiDC,YAAjD,GAAoFH,mBAAnCG,YAAjD;AAAA,IAA+DC,gBAA/D,GAAoFJ,mBAArBI,gBAA/D;;AAEA,SAASC,0BAAT,OAAkH;AAAA,MAA5EC,QAA4E,QAA5EA,QAA4E;AAAA,MAAlEC,YAAkE,QAAlEA,YAAkE;AAAA,MAApDC,IAAoD,QAApDA,IAAoD;AAAA,MAA9CC,MAA8C,QAA9CA,MAA8C;AAAA,MAAtCC,UAAsC,QAAtCA,UAAsC;AAAA,MAA1BC,MAA0B,QAA1BA,MAA0B;AAAA,MAAlBC,QAAkB,QAAlBA,QAAkB;AAAA,MAARC,IAAQ,QAARA,IAAQ;AAChH,SAAO;AACLP,YAAQ,EAARA,QADK;AAELC,gBAAY,EAAZA,YAFK;AAGLC,QAAI,EAAEM,IAAI,CAACC,KAALD,CAAWN,IAAXM,CAHD;AAILL,UAAM,EAANA,MAJK;AAKLC,cAAU,EAAVA,UALK;AAMLC,UAAM,EAANA,MANK;AAOLC,YAAQ,EAARA,QAPK;AAQLC,QAAI,EAAJA;AARK,GAAP;AAUD;;AAED,SAASG,gBAAT,CAA0BC,WAA1B,EAAuC;AACrC,MAAMC,KAAK,GAAG,IAAIC,UAAJ,CAAeF,WAAf,CAAd;AAEA,SACE,GAAGG,MAAH,CAAUC,IAAV,CAAeH,KAAf,EAAsB,UAACF,gBAAD,EAAmBM,SAAnB;AAAA,WAAiCN,gBAAgB,GAAGO,IAAI,CAACC,GAALD,CAASD,SAATC,CAApD;AAAtB,KAA+F,CAA/F,IAAoGL,KAAK,CAACO,MAD5G;AAGD;;AAED,SAASC,+BAAT,CAAyCC,EAAzC,EAA6C;AAC3C,SAAO;AAAA,sCAAIC,IAAJ;AAAIA,UAAJ,MAAIA,GAAJC,eAAID;AAAJ;;AAAA,WAAa,IAAIE,OAAJ,CAAY,UAACC,OAAD,EAAUC,MAAV;AAAA,aAAqBL,EAAE,MAAFA,SAAMC,IAAN,OAAMA,CAAN,CAAYG,OAAZ,EAAqBC,MAArB,CAAMJ,CAAND,CAArB;AAAZ,MAAb;AAAP;AACD;;IAEKM,sB;;;;;AACJ,kCAAYC,IAAZ,EAA6E;AAAA;;AAAA,oFAAJ,EAAI;AAAA,QAAzDC,IAAyD,SAAzDA,IAAyD;AAAA,QAAnDC,IAAmD,SAAnDA,IAAmD;AAAA,QAA7CC,cAA6C,SAA7CA,cAA6C;AAAA,QAA7BC,WAA6B,SAA7BA,WAA6B;AAAA,QAAhBC,OAAgB,SAAhBA,OAAgB;;AAAA;AAC3EC,8BAAMN,IAAN;AAEAM,UAAKL,IAAL,GAAYA,IAAZ;AACAK,UAAKJ,IAAL,GAAYA,IAAZ;AACAI,UAAKH,cAAL,GAAsBA,cAAtB;AACAG,UAAKF,WAAL,GAAmBA,WAAnB;AACAE,UAAKD,OAAL,GAAeA,OAAf;AAP2E;AAQ5E;;;EATkCE,S;;AAYrC,SAASC,kBAAT,CAA4BC,WAA5B,EAAyC;AACvC,MAAMC,cAAc,GAAGD,WAAW,CAACE,MAAnC;AACA,MAAMC,mBAAmB,GAAGH,WAAW,CAACE,MAAZF,CAAmBI,IAAnBJ,CAAwBA,WAAxBA,CAA5B;AACA,MAAIK,UAAJ;AACA,MAAIC,KAAJ,CAJuC,CAMvC;AACA;;AACAN,aAAW,CAACE,MAAZF,wFAAqB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAAO;AAAA,mBACEJ,mBAAmB,EADrB;;AAAA;AACbK,kBADa,iBACbA;AADa,8EAIdA,MAJc;AAKjBC,kBAAI;AAAA,oGAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAAC;AAAA,iCACgBF,MAAM,CAACC,IAAPD,EADhB;;AAAA;AACEG,+BADF,gBACEA,CADF,CAGJ;AACA;AACA;AACA;AACA;;AAEA,8BAAI,CAACN,UAAD,IAAehC,gBAAgB,CAACsC,KAAK,CAACC,MAAP,CAAhBvC,GAAiC,GAApD,EAAyD;AACvD2B,uCAAW,CAACa,MAAZb,CAAmBc,OAAnBd,CAA2B;AAAEe,kCAAI,EAAE;AAAR,6BAA3Bf;AACAK,sCAAU,GAAG,IAAbA;AACD;;AAZG,+BAcAC,KAdA;AAAAI;AAAA;AAAA;;AAAA,2DAeK;AAAEE,kCAAM,EAAE,IAAII,WAAJ,CAAgB,CAAhB,CAAV;AAA8BC,iCAAK,EAAE,IAArC;AAA2CC,wCAAY,EAAEC,IAAI,CAACC,GAALD;AAAzD,2BAfL;;AAAA;AAAA,2DAkBGR,KAlBH;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAF;;AAAA;AAAA;AAAA;;AAAA;AAAA;AALa;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAArB;AA4BA,SAAO;AACLX,eAAW,EAAXA,WADK;AAELqB,SAAK,EAAE,iBAAM;AACXf,WAAK,GAAG,IAARA;AAHG;AAKLgB,aAAS,EAAE,qBAAM;AACftB,iBAAW,CAACE,MAAZF,GAAqBC,cAArBD;AACD;AAPI,GAAP;AASD;;AAEM,SAASuB,6CAAT,QAMJ;AAAA,MALDC,gBAKC,SALDA,gBAKC;AAAA,MAJDC,eAIC,SAJDA,eAIC;AAAA,MAHDC,WAGC,SAHDA,WAGC;AAAA,MAFDC,iBAEC,SAFDA,iBAEC;AAAA,MADDC,iBACC,SADDA,iBACC,EACD;;AACAnE,kBAAgB,CAACgE,eAAjBhE,CAAiCgE,eAAe,KAAK,KAArDhE;;AAFC,MAIKoE,iBAJL;AAAA;;AAAA;;AAKC,iCAAc;AAAA;;AAAA;AACZC;AAEAA,aAAKC,WAAL,GAAmB,KAAnB;AACAD,aAAKE,eAAL,GAAuB,KAAvB;AACAF,aAAKG,KAAL,GACE,OAAOC,MAAP,KAAkB,WAAlB,GACIA,MAAM,CAACC,QAAPD,CAAgBE,eAAhBF,CAAgCG,YAAhCH,CAA6C,MAA7CA,KAAwDA,MAAM,CAACI,SAAPJ,CAAiBK,QAD7E,GAEI,OAHN;AAIAT,aAAKU,SAAL,GAAiB,IAAIC,0BAAJ,EAAjB;AACAX,aAAKY,gBAAL,GAAwB,CAAxB;AAVY;AAWb;;AAhBF;AAAAC;AAAAC,aAkBC,+BAAsBrD,IAAtB,EAA4BsD,KAA5B,EAAmC;AACjC,aAAKC,aAAL,CACE,IAAIxD,sBAAJ,CAA2B,mBAA3B,EAAgD;AAC9CE,cAAI,kCACCqD,KADD;AAEFtD,gBAAI,EAAJA;AAFE;AAD0C,SAAhD,CADF;AAQD;AA3BF;AAAAoD;AAAAI,WA6BC,eAAiB;AACf,eAAO,KAAKhB,WAAZ;AA9BH;AAAAiB,WAiCC,aAAeJ,KAAf,EAAsB;AACpB,aAAKb,WAAL,GAAmBa,KAAnB;AACD;AAnCF;AAAAD;AAAAI,WAqCC,eAAe;AACb,eAAO,KAAKP,SAAZ;AAtCH;AAAAQ,WAyCC,aAAaJ,KAAb,EAAoB;AAClB,YAAIA,KAAK,YAAYH,0BAArB,EAAwC;AACtC,eAAKD,SAAL,GAAiBI,KAAjB;AADF,eAEO;AACL,gBAAM,IAAIK,KAAJ,yDAAN;AACD;AACF;AA/CF;AAAAN;AAAAI,WAiDC,eAAqB;AACnB,eAAO,KAAKf,eAAZ;AAlDH;AAAAgB,WAqDC,aAAmBJ,KAAnB,EAA0B;AACxB,aAAKZ,eAAL,GAAuBY,KAAvB;AACD;AAvDF;AAAAD;AAAAI,WAyDC,eAAsB;AACpB,eAAO,KAAKL,gBAAZ;AA1DH;AAAAM,WA6DC,aAAoBJ,KAApB,EAA2B;AACzB,aAAKF,gBAAL,GAAwBE,KAAxB;AACD;AA/DF;AAAAD;AAAAI,WAiEC,eAAW;AACT,eAAO,KAAKd,KAAZ;AAlEH;AAAAe,WAqEC,aAASJ,KAAT,EAAgB;AACd,aAAKX,KAAL,GAAaW,KAAb;AACD;AAvEF;AAAAD;AAAAI,WAyEC,eAAiB;AACf,eAAO,gCAAuB,IAAvB,EAA6B,UAA7B,CAAP;AA1EH;AAAAC,WA6EC,aAAeJ,KAAf,EAAsB;AACpB,wCAAuB,IAAvB,EAA6B,UAA7B,EAAyCA,KAAzC;AACD;AA/EF;AAAAD;AAAAI,WAiFC,eAAmB;AACjB,eAAO,gCAAuB,IAAvB,EAA6B,YAA7B,CAAP;AAlFH;AAAAC,WAqFC,aAAiBJ,KAAjB,EAAwB;AACtB,wCAAuB,IAAvB,EAA6B,YAA7B,EAA2CA,KAA3C;AACD;AAvFF;AAAAD;AAAAI,WAyFC,eAA0B;AACxB,eAAO,gCAAuB,IAAvB,EAA6B,mBAA7B,CAAP;AA1FH;AAAAC,WA6FC,aAAwBJ,KAAxB,EAA+B;AAC7B,wCAAuB,IAAvB,EAA6B,mBAA7B,EAAkDA,KAAlD;AACD;AA/FF;AAAAD;AAAAI,WAiGC,eAAY;AACV,eAAO,gCAAuB,IAAvB,EAA6B,KAA7B,CAAP;AAlGH;AAAAC,WAqGC,aAAUJ,KAAV,EAAiB;AACf,wCAAuB,IAAvB,EAA6B,KAA7B,EAAoCA,KAApC;AACD;AAvGF;AAAAD;AAAAI,WAyGC,eAAc;AACZ,eAAO,gCAAuB,IAAvB,EAA6B,OAA7B,CAAP;AA1GH;AAAAC,WA6GC,aAAYJ,KAAZ,EAAmB;AACjB,wCAAuB,IAAvB,EAA6B,OAA7B,EAAsCA,KAAtC;AACD;AA/GF;AAAAD;AAAAI,WAiHC,eAAe;AACb,eAAO,gCAAuB,IAAvB,EAA6B,QAA7B,CAAP;AAlHH;AAAAC,WAqHC,aAAaJ,KAAb,EAAoB;AAClB,wCAAuB,IAAvB,EAA6B,QAA7B,EAAuCA,KAAvC;AACD;AAvHF;AAAAD;AAAAI,WAyHC,eAAiB;AACf,eAAO,gCAAuB,IAAvB,EAA6B,UAA7B,CAAP;AA1HH;AAAAC,WA6HC,aAAeJ,KAAf,EAAsB;AACpB,wCAAuB,IAAvB,EAA6B,UAA7B,EAAyCA,KAAzC;AACD;AA/HF;AAAAD;AAAAI,WAiIC,eAAmB;AACjB,eAAO,gCAAuB,IAAvB,EAA6B,YAA7B,CAAP;AAlIH;AAAAC,WAqIC,aAAiBJ,KAAjB,EAAwB;AACtB,wCAAuB,IAAvB,EAA6B,YAA7B,EAA2CA,KAA3C;AACD;AAvIF;AAAAD;AAAAI,WAyIC,eAAkB;AAChB,eAAO,gCAAuB,IAAvB,EAA6B,WAA7B,CAAP;AA1IH;AAAAC,WA6IC,aAAgBJ,KAAhB,EAAuB;AACrB,wCAAuB,IAAvB,EAA6B,WAA7B,EAA0CA,KAA1C;AACD;AA/IF;AAAAD;AAAAI,WAiJC,eAAoB;AAClB,eAAO,gCAAuB,IAAvB,EAA6B,aAA7B,CAAP;AAlJH;AAAAC,WAqJC,aAAkBJ,KAAlB,EAAyB;AACvB,wCAAuB,IAAvB,EAA6B,aAA7B,EAA4CA,KAA5C;AACD;AAvJF;AAAAD;AAAAI,WAyJC,eAAc;AACZ,eAAO,gCAAuB,IAAvB,EAA6B,OAA7B,CAAP;AA1JH;AAAAC,WA6JC,aAAYJ,KAAZ,EAAmB;AACjB,wCAAuB,IAAvB,EAA6B,OAA7B,EAAsCA,KAAtC;AACD;AA/JF;AAAAD;AAAAC,aAiKC,iBAAQ;AAAA;;AACN,aAAKM,UAAL,GAAkBC,KAAlB,CAAwB,eAAO;AAC7BC,gBAAI,CAACN,aAAL,CAAmB,IAAIO,UAAJ,CAAe,OAAf,EAAwB;AAAEC,iBAAK,EAAEC,GAAT;AAAcC,mBAAO,EAAED,GAAG,KAAKA,GAAG,CAACE,KAAJF,IAAaA,GAAG,CAACC,OAAtB;AAA1B,WAAxB,CAAnB;AADF;AAGD;AArKF;AAAAb;AAAAC;AAAA,kGAuKC;AAAA;;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAAc;AAAA,yBAE2BlC,gBAAgB,CAAC,KAAKmC,IAAN,CAF3C;;AAAA;AAEQC,4BAFR,iBAEQA;AAFRC,wCAI+B9D,kBAAkB,CAAC6D,UAAU,CAAC5D,WAAZ,CAJjD,EAIUqB,KAJV,uBAIUA,KAJV,EAIiBC,SAJjB,uBAIiBA,SAJjB;AAAAoC;AAOUI,uBAPV,GAOkB,kCAARA;AAPVC,0CAY+CH,UAAU,CAAC5D,WAAX4D,CAAuB/C,MAAvB+C,CAA8B1D,MAA9B0D,CAAqC,iBAAS;AACvF,wBAAQ7C,IAAR,GAAiB8B,KAAjB,CAAQ9B,IAAR;;AAEA,wBAAIA,IAAI,KAAK,uBAAb,EAAsC;AACpC+C,2BAAK,CAACE,IAANF,CAAW;AAAEG,wCAAgB,EAAE;AAApB,uBAAXH;AADF,2BAEO,IAAI/C,IAAI,KAAK,qBAAb,EAAoC;AACzC+C,2BAAK,CAACE,IAANF,CAAW;AAAEI,sCAAc,EAAE;AAAlB,uBAAXJ;AADK,2BAEA,IAAI/C,IAAI,KAAK,mBAAb,EAAkC;AACvC+C,2BAAK,CAACE,IAANF,CAAW;AAAEK,yCAAiB,EAAE;AAArB,uBAAXL;AACD;AATwC,oBAZ/C,EAYoBM,sBAZpB,yBAYYC,MAZZ;;AAwBIT,4BAAU,CAACU,QAAXV,GAAsB,UAACW,CAAD,SAAoD;AAAA,wBAA9C3G,YAA8C,SAA9CA,YAA8C;AAAA,wBAAhCE,MAAgC,SAAhCA,MAAgC;AAAA,wBAAxBE,MAAwB,SAAxBA,MAAwB;AAAA,wBAAhBwG,SAAgB,SAAhBA,SAAgB;AACxEV,yBAAK,CAACE,IAANF,CAAW;AACTQ,8BAAQ,EAAE;AACR1G,oCAAY,EAAZA,YADQ;AAERE,8BAAM,EAANA,MAFQ;AAGRE,8BAAM,EAANA,MAHQ;AAIRwG,iCAAS,EAATA;AAJQ;AADD,qBAAXV;AADF;;AAWAF,4BAAU,CAACa,UAAXb,GAAwB,UAACW,CAAD,SAAsC;AAAA,wBAAhCzG,MAAgC,SAAhCA,MAAgC;AAAA,wBAAxB4G,MAAwB,SAAxBA,MAAwB;AAAA,wBAAhBF,SAAgB,SAAhBA,SAAgB;AAC5DV,yBAAK,CAACE,IAANF,CAAW;AACTW,gCAAU,EAAE;AACV3G,8BAAM,EAANA,MADU;AAEV4G,8BAAM,EAAEhH,0BAA0B,CAACgH,MAAD,CAFxB;AAGVF,iCAAS,EAATA;AAHU;AADH,qBAAXV;AADF;;AAUAF,4BAAU,CAACe,WAAXf,GAAyB,UAACW,CAAD,SAAsC;AAAA,wBAAhCzG,MAAgC,SAAhCA,MAAgC;AAAA,wBAAxB4G,MAAwB,SAAxBA,MAAwB;AAAA,wBAAhBF,SAAgB,SAAhBA,SAAgB;AAC7DV,yBAAK,CAACE,IAANF,CAAW;AACTa,iCAAW,EAAE;AACX7G,8BAAM,EAANA,MADW;AAEX4G,8BAAM,EAAEhH,0BAA0B,CAACgH,MAAD,CAFvB;AAGXF,iCAAS,EAATA;AAHW;AADJ,qBAAXV;AADF;;AAUAF,4BAAU,CAACgB,cAAXhB,GAA4B,UAACW,CAAD,SAAsB;AAAA,wBAAhBC,SAAgB,SAAhBA,SAAgB;AAChDV,yBAAK,CAACE,IAANF,CAAW;AAAEc,oCAAc,EAAE;AAAEJ,iCAAS,EAATA;AAAF;AAAlB,qBAAXV;AADF;;AAIAF,4BAAU,CAACiB,cAAXjB,GAA4B,UAACW,CAAD,SAAsB;AAAA,wBAAhBC,SAAgB,SAAhBA,SAAgB,EAChD;;AACAV,yBAAK,CAACE,IAANF,CAAW;AAAEe,oCAAc,EAAE;AAAEL,iCAAS,EAATA;AAAF;AAAlB,qBAAXV;AAFF;;AAKAF,4BAAU,CAACkB,mBAAXlB,GAAiC,UAACW,CAAD,UAA8B;AAAA,wBAAxBzG,MAAwB,UAAxBA,MAAwB;AAAA,wBAAhB0G,SAAgB,UAAhBA,SAAgB;AAC7DV,yBAAK,CAACE,IAANF,CAAW;AAAEgB,yCAAmB,EAAE;AAAEhH,8BAAM,EAANA,MAAF;AAAU0G,iCAAS,EAATA;AAAV;AAAvB,qBAAXV;AADF;;AAIAF,4BAAU,CAACmB,iBAAXnB,GAA+B,UAACW,CAAD,UAAsB;AAAA,wBAAhBC,SAAgB,UAAhBA,SAAgB,EACnD;AACA;;AACAV,yBAAK,CAACE,IAANF,CAAW;AAAEiB,uCAAiB,EAAE;AAAEP,iCAAS,EAATA;AAAF;AAArB,qBAAXV;AAHF;;AAMQkB,yBA1EZ,GA0EwB,KAAKC,QAAL,CAAZD,QA1EZ,CA4EI;;AACQE,gCA7EZ,GA6E+BtB,UAAU,CAACuB,QAAXvB,CAAnBsB;AAERvD,mCAAiB,IAAIA,iBAAiB,CAAC7C,MAAvC6C,IAAiDuD,cAAc,CAACE,mBAAfF,CAAmCvD,iBAAnCuD,CAAjDvD;AACAqD,yBAAO,IAAIA,OAAO,CAAClG,MAAnBkG,IAA6BE,cAAc,CAACG,SAAfH,CAAyBF,OAAzBE,CAA7BF;AAhFJtB;AAAA,yBAkFU3E,+BAA+B,CAAC6E,UAAU,CAAC0B,+BAAX1B,CAA2CxD,IAA3CwD,CAAgDA,UAAhDA,CAAD,CAA/B7E,EAlFV;;AAAA;AAoFI,sBAAI6E,UAAU,CAAC2B,8BAAf,EAA+C;AAC7C,yBAAKC,KAAL,GAAa;AAAA,6BAAM1B,KAAK,CAACE,IAANF,CAAW;AAAE0B,6BAAK,EAAE;AAAT,uBAAX1B,CAAN;AAAb;;AACA,yBAAK2B,IAAL,GAAY;AAAA,6BAAM3B,KAAK,CAACE,IAANF,CAAW;AAAE2B,4BAAI,EAAE;AAAR,uBAAX3B,CAAN;AAAZ;AAFF,yBAGO;AACL,yBAAK0B,KAAL,GAAa,KAAKC,IAAL,GAAYC,SAAzB;AACD;;AAIGC,kCA7FR,GA6F2B,EAAnBA;AA7FRC,gFA+FaC,IA/Fb;AAAA;AAAA;AAAA;AAAA;AAAA;AAAAC;AAAA,mCAgG0BhC,KAAK,CAACiC,KAANjC,EAhG1B;;AAAA;AAgGYjB,iCAhGZ,iBAgGYA;AAEJ2C,iCAlGR,GA0GU3C,KA1GV,CAkGQ2C,OACAtB,cAnGR,GA0GUrB,KA1GV,CAmGQqB,cADAsB,EAEAvB,gBApGR,GA0GUpB,KA1GV,CAoGQoB,gBAFAuB,EAGAlB,QArGR,GA0GUzB,KA1GV,CAqGQyB,QAHAkB,EAIArB,iBAtGR,GA0GUtB,KA1GV,CAsGQsB,iBAJAqB,EAKAf,UAvGR,GA0GU5B,KA1GV,CAuGQ4B,UALAe,EAMAb,WAxGR,GA0GU9B,KA1GV,CAwGQ8B,WANAa,EAOAC,IAzGR,GA0GU5C,KA1GV,CAyGQ4C,IAPAD,CAlGR,CA4GM;;AACAQ,kCAAM,CAACC,IAAPD,CAAYnD,KAAZmD,EAAmBE,OAAnBF,CAA2B,gBAAI;AAAA,qCAAIG,MAAI,CAACC,qBAAL,CAA2BrF,IAA3B,EAAiC8B,KAAK,CAAC9B,IAAD,CAAtC,CAAJ;AAA/B;AAEMsF,wCA/GZ,GA+G2B/B,QAAQ,IAAIA,QAAQ,CAAC1G,YAApCyI;;AA/GZ,iCAiHU,sFAAsBC,IAAtB,CAA2BD,YAAY,IAAI,EAA3C,CAjHV;AAAAP;AAAA;AAAA,8BAkHQ;;;AAEAS,sCAAU,GAAG;AACXjD,mCAAK,EAAE,aADI;AAEX/D,kCAAI,EAAE;AAFK,6BAAbgH;AApHR;;AAAA;AA4HM,gCAAI,CAACV,IAAL,EAAW;AACTM,oCAAI,CAACrD,aAAL,CAAmB,IAAIxD,sBAAJ,CAA2B,OAA3B,CAAnB;AACD;;AA9HP,iCAgIU+G,YAhIV;AAAAP;AAAA;AAAA;;AAiIQ,gCAAI,OAAQQ,IAAR,CAAaD,YAAb,CAAJ,EAAgC;AAC9B,kCAAI,CAACG,YAAL,EAAmB;AACjBL,sCAAI,CAACrD,aAAL,CAAmB,IAAIxD,sBAAJ,CAA2B,YAA3B,CAAnB;;AACA6G,sCAAI,CAACrD,aAAL,CAAmB,IAAIxD,sBAAJ,CAA2B,UAA3B,CAAnB;AACD;;AAEDiH,wCAAU,GAAG;AACXjD,qCAAK,EAAE,SADI;AAEX/D,oCAAI,EAAE;AAFK,+BAAbgH;AANF,mCAUO;AACLA,wCAAU,GAAG;AACXjD,qCAAK,EAAE,SADI;AAEX/D,oCAAI,EAAE;AAFK,+BAAbgH;AAID;;AAhJT;;AAAA;AAAA,kCAmJiBf,KAAK,IAAIC,IAnJ1B;AAAAK;AAAA;AAAA;;AAoJQ,gCAAIN,KAAJ,EAAW;AACTe,wCAAU,GAAG;AACXjD,qCAAK,EAAE,SADI;AAEX/D,oCAAI,EAAE;AAFK,+BAAbgH,CADS,CAMT;;AACAE,sCAAQ,GAAG,OAAXA;AAPF,mCAQO;AACL;AACApF,mCAAK;AACLoF,sCAAQ,GAAG,MAAXA;AA/JV,8BAkKQ;AACA;;;AAnKR,kCAoKYjB,KAAK,IAAI5B,UAAU,CAAC2B,8BApKhC;AAAAO;AAAA;AAAA;;AAAAA;AAAA,mCAqKgB/G,+BAA+B,CAAC6E,UAAU,CAAC2B,8BAAX3B,CAA0CxD,IAA1CwD,CAA+CA,UAA/CA,CAAD,CAA/B7E,EArKhB;;AAAA;AAAA+G;AAAA;;AAAA;AAAA,iCAuKiB7B,gBAvKjB;AAAA6B;AAAA;AAAA;;AAwKQK,kCAAI,CAACrD,aAAL,CAAmB,IAAIxD,sBAAJ,CAA2B,YAA3B,CAAnB;;AAEAkH,wCAAY,GAAG,IAAfA;AA1KRV;AAAA;;AAAA;AAAA,iCA2KiB3B,iBA3KjB;AAAA2B;AAAA;AAAA;;AA4KQK,kCAAI,CAACrD,aAAL,CAAmB,IAAIxD,sBAAJ,CAA2B,YAA3B,CAAnB;;AAEAoH,wCAAY,GAAG,IAAfA;AA9KRZ;AAAA;;AAAA;AAAA,iCA+KiB5B,cA/KjB;AAAA4B;AAAA;AAAA,8BAgLQ;AACA;AACA;;;AAEAa,yCAAa,IAAIR,MAAI,CAACrD,aAAL,CAAmB,IAAIxD,sBAAJ,CAA2B,WAA3B,CAAnB,CAAjBqH;AACAD,wCAAY,IAAIP,MAAI,CAACrD,aAAL,CAAmB,IAAIxD,sBAAJ,CAA2B,UAA3B,CAAnB,CAAhBoH;AACAF,wCAAY,IAAIL,MAAI,CAACrD,aAAL,CAAmB,IAAIxD,sBAAJ,CAA2B,UAA3B,CAAnB,CAAhBkH;AAEAA,wCAAY,GAAGE,YAAY,GAAGC,aAAa,GAAG,KAA9CH;AAxLR;;AAAA;AAAA,kCA2LiBC,QAAQ,KAAK,OA3L9B;AAAAX;AAAA;AAAA;;AAAA,kCA4LYrB,UAAU,IAAIA,UAAU,CAACC,MAAzBD,IAAmCA,UAAU,CAACC,MAAXD,CAAkBzG,MAAlByG,KAA6BlH,YAAY,CAACqJ,OA5LzF;AAAAd;AAAA;AAAA;;AA6LUS,sCAAU,GAAG;AACXjD,mCAAK,EAAE,WADI;AAEX/D,kCAAI,EAAE;AAFK,6BAAbgH;AA7LVT;AAAA;;AAAA;AAAA,kCAiMmBrB,UAAU,IAAIE,WAjMjC;AAAAmB;AAAA;AAAA;;AAkMU,gCAAI,CAACU,YAAL,EAAmB;AACjB;AACAL,oCAAI,CAACrD,aAAL,CAAmB,IAAIxD,sBAAJ,CAA2B,YAA3B,CAAnB;;AAEAkH,0CAAY,GAAG,IAAfA;AACD;;AAED,gCAAI,CAACE,YAAL,EAAmB;AACjBP,oCAAI,CAACrD,aAAL,CAAmB,IAAIxD,sBAAJ,CAA2B,YAA3B,CAAnB;;AAEAoH,0CAAY,GAAG,IAAfA;AACD;;AAED,gCAAI,CAACC,aAAL,EAAoB;AAClBR,oCAAI,CAACrD,aAAL,CAAmB,IAAIxD,sBAAJ,CAA2B,aAA3B,CAAnB;;AAEAqH,2CAAa,GAAG,IAAhBA;AACD;;AAnNX,iCAqNclC,UArNd;AAAAqB;AAAA;AAAA;;AAsNkBpB,kCAtNlB,GAsN2B,0EAA4DD,UAAU,CAACC,MAAvE,EAA+E;AAC5FmC,6CAAe,EAAEV,MAAI,CAACU,eADsE;AAE5FjF,+CAAiB,EAAjBA;AAF4F,6BAA/E,CAAT8C;AAKAoC,wCA3NlB,GA2NiC,CAAC,CAACpC,MAAM,CAAC,CAAD,CAANA,CAAUqC,UAA3BD;;AAEN,gCAAIA,YAAJ,EAAkB;AAChBnB,8CAAgB,8CAAOA,gBAAP,IAAyBjB,MAAzB,EAAhBiB;AAEAQ,oCAAI,CAACa,UAAL,IACEb,MAAI,CAACrD,aAAL,CACE,IAAIxD,sBAAJ,CAA2B,QAA3B,EAAqC;AACnCM,uCAAO,EAAE+F;AAD0B,+BAArC,CADF,CADF;AAhOd,8BAwOY;;;AACA,gCAAIQ,MAAI,CAACa,UAAL,IAAmBF,YAAvB,EAAqC;AACnCP,wCAAU,GAAG,IAAbA;AADF,mCAEO;AACLA,wCAAU,GAAG;AACX3G,uCAAO,EAAE+F,gBADE;AAEXpG,oCAAI,EAAE;AAFK,+BAAbgH;AAID;;AAhPb,kCAkPgB,CAACJ,MAAI,CAACa,UAAN,IAAoBpD,UAAU,CAAC2B,8BAlP/C;AAAAO;AAAA;AAAA;;AAAAA;AAAA,mCAmPoB/G,+BAA+B,CAAC6E,UAAU,CAAC2B,8BAAX3B,CAA0CxD,IAA1CwD,CAA+CA,UAA/CA,CAAD,CAA/B7E,EAnPpB;;AAAA;AAsPY;AACA;AACA,gCAAI2C,WAAW,IAAI6E,UAAf7E,IAA6BoF,YAAjC,EAA+C;AAC7CX,oCAAI,CAACrD,aAAL,CAAmB,IAAIxD,sBAAJ,CAA2BiH,UAAU,CAAChH,IAAtC,EAA4CgH,UAA5C,CAAnB;;AACAA,wCAAU,GAAG,IAAbA;AACD;;AA3PbT;AAAA;;AAAA;AA4PiB,gCAAInB,WAAJ,EAAiB;AACtBwB,oCAAI,CAACc,cAAL,IACEd,MAAI,CAACrD,aAAL,CACE,IAAIxD,sBAAJ,CAA2B,QAA3B,EAAqC;AACnCM,uCAAO,6CACF+F,gBADE,IAEL,0EAA4DhB,WAAW,CAACD,MAAxE,EAAgF;AAC9EmC,iDAAe,EAAEV,MAAI,CAACU,eADwD;AAE9EjF,mDAAiB,EAAjBA;AAF8E,iCAAhF,CAFK;AAD4B,+BAArC,CADF,CADF;AAYD;;AAzQX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AA+FaiE,sBA/Fb,GA+FoB,CAAPA;;AA/Fb;AAAA,wBA+FuB,CAACY,QAAD,IAAaD,YA/FpC;AAAA9C;AAAA;AAAA;;AAAA,uDA+FamC,IA/Fb;;AAAA;AAAAqB;;AAAA;AAAAxD;AAAA;AAAA;;AAAA;;AAAA;AA+FkDmC,sBAAI;AA/FtDnC;AAAA;;AAAA;AA8QI,sBAAIiD,aAAJ,EAAmB;AACjB,yBAAK7D,aAAL,CAAmB,IAAIxD,sBAAJ,CAA2B,WAA3B,CAAnB;AACD;;AAED,sBAAIoH,YAAJ,EAAkB;AAChB,yBAAK5D,aAAL,CAAmB,IAAIxD,sBAAJ,CAA2B,UAA3B,CAAnB;AACD;;AAED,sBAAIkH,YAAJ,EAAkB;AAChB,yBAAK1D,aAAL,CAAmB,IAAIxD,sBAAJ,CAA2B,UAA3B,CAAnB;AACD;;AAED,sBAAIiH,UAAJ,EAAgB;AACd,wBAAIA,UAAU,CAAChH,IAAXgH,KAAoB,QAApBA,IAAgC,CAACA,UAAU,CAAC3G,OAAX2G,CAAmBzH,MAAxD,EAAgE;AAC9DyH,gCAAU,GAAG;AACXjD,6BAAK,EAAE,WADI;AAEX/D,4BAAI,EAAE;AAFK,uBAAbgH;AAID;;AAED,wBAAIA,UAAU,CAAChH,IAAXgH,KAAoB,OAAxB,EAAiC;AAC/B,2BAAKzD,aAAL,CAAmB,IAAIO,UAAJ,CAAe,OAAf,EAAwBkD,UAAxB,CAAnB;AADF,2BAEO;AACL,2BAAKzD,aAAL,CAAmB,IAAIxD,sBAAJ,CAA2BiH,UAAU,CAAChH,IAAtC,EAA4CgH,UAA5C,CAAnB;AACD;AAtSP,oBAySI;AACA;;;AACA,uBAAKzD,aAAL,CAAmB,IAAIxD,sBAAJ,CAA2B,KAA3B,CAAnB;AAEA8E,wCAAsB;AA7S1BV;AAAA;;AAAA;AAAAA;AAAAA,wDA+SI;;AACAyD,yBAAO,CAAC7D,KAAR6D;AAhTJ;;AAAA;AAAAzD;AAoTIpC,2BAAS;AACTsC,4BAAU,CAACwD,OAAXxD;AArTJ;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAvKD;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA,IAI+ByD,eAJ/B;;AAieD,SAAO;AACL5E,qBAAiB,EAAjBA,0BADK;AAELZ,qBAAiB,EAAjBA,iBAFK;AAGLvC,0BAAsB,EAAtBA;AAHK,GAAP;AAKD;;eAEc,2BAAW;AACxB,sBAYI,4BAAagI,OAAb,CAZJ;AAAA,4CACEtH,WADF;AAAA,MACEA,WADF,sCACgB5C,WAAW,CAACmK,0BAAZnK,EADhB;AAAA,4CAKEqE,eALF;AAAA,MAKEA,eALF,sCAKoB,IALpB;AAAA,MAOE+F,gBAPF,iBAOEA,gBAPF;AAAA,MAQE9F,WARF,iBAQEA,WARF;AAAA,MASEC,iBATF,iBASEA,iBATF;AAAA,MAUE8F,2BAVF,iBAUEA,2BAVF;AAAA,4CAWE7F,iBAXF;AAAA,MAWEA,iBAXF,sCAWsB,SAXtB;;AAcA,MAAI,CAAC5B,WAAD,KAAiB,CAACkC,MAAM,CAACI,SAAPJ,CAAiBwF,YAAlB,IAAkC,CAACxF,MAAM,CAACI,SAAPJ,CAAiBwF,YAAjBxF,CAA8ByF,YAAlF,CAAJ,EAAqG;AACnGR,WAAO,CAACS,IAART,CACE,mIADFA;AAIA,WAAO,EAAP;AACD;;AAED,MAAM3F,gBAAgB;AAAA,yFAAG,kBAAMmC,IAAN;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAAkE;AAAA,qBACkEL,gBAAgB,EADlF;;AAAA;AAAAM;AACfC,gCADe,yBACfA;AAAoBC,oBADL,yBACKA;AAAQC,uCADb,yBACaA;AAA2BC,6BADxC,yBACwCA;;AAG/D,kBAAID,yBAAJ,EAA+B;AACvBE,oBADuB,GAChB;AAAEC,0BAAQ,EAAEH,yBAAZ;AAAuCI,sBAAI,EAAE,GAA7C;AAAkDC,0BAAQ,EAAE;AAA5D,iBAAPH;;AAEN,oBAAIJ,kBAAJ,EAAwB;AACtBQ,8BAAY,GAAG/K,YAAY,CAACgL,QAAbhL,CAAsB2K,IAAtB3K,CAAf+K;AACAA,8BAAY,CAACR,kBAAbQ,GAAkCR,kBAAlCQ;AAFF,uBAGO;AACLA,8BAAY,GAAG/K,YAAY,CAACgL,QAAbhL,CAAsB2K,IAAtB3K,EAA4B0K,eAA5B1K,CAAf+K;AACD;AARH,qBASO;AACLA,4BAAY,GAAGR,kBAAkB,GAC7BvK,YAAY,CAACiL,sBAAbjL,CAAoCuK,kBAApCvK,EAAwDwK,MAAxDxK,CAD6B,GAE7BA,YAAY,CAACkL,gBAAblL,CAA8B0K,eAA9B1K,EAA+CwK,MAA/CxK,CAFJ+K;AAGD;;AAED,kBAAId,2BAAJ,EAAiC;AAC/Bc,4BAAY,CAACI,UAAbJ,GAA0Bd,2BAA1Bc;AACD;;AAEDA,0BAAY,CAACK,YAAbL,GAA4BjL,YAAY,CAACuL,QAAzCN;AACAA,0BAAY,CAACO,yBAAbP,GAAyC5E,IAAI,IAAI,OAAjD4E;AAxBuB,gDA0BhB,IAAI9K,gBAAJ,CAAqB8K,YAArB,EAAmCvI,WAAnC,CA1BgB;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAH;;AAAA,oBAAhBwB,gBAAgB;AAAA;AAAA;AAAA,KAAtB;;AA6BA,SAAOD,6CAA6C,CAAC;AACnDvB,eAAW,EAAXA,WADmD;AAEnDwB,oBAAgB,EAAhBA,gBAFmD;AAGnDC,mBAAe,EAAfA,eAHmD;AAInDC,eAAW,EAAXA,WAJmD;AAKnDC,qBAAiB,EAAjBA,iBALmD;AAMnDC,qBAAiB,EAAjBA;AANmD,GAAD,CAApD","names":["AudioConfig","SpeechSDK","OutputFormat","ResultReason","SpeechConfig","SpeechRecognizer","serializeRecognitionResult","duration","errorDetails","json","offset","properties","reason","resultId","text","JSON","parse","averageAmplitude","arrayBuffer","array","Int16Array","reduce","call","amplitude","Math","abs","length","cognitiveServicesAsyncToPromise","fn","args","arguments","Promise","resolve","reject","SpeechRecognitionEvent","type","data","emma","interpretation","resultIndex","results","_this","Event","prepareAudioConfig","audioConfig","originalAttach","attach","boundOriginalAttach","bind","firstChunk","muted","_context2","reader","read","_context","chunk","buffer","events","onEvent","name","ArrayBuffer","isEnd","timeReceived","Date","now","pause","unprepare","createSpeechRecognitionPonyfillFromRecognizer","createRecognizer","enableTelemetry","looseEvents","referenceGrammars","textNormalization","SpeechRecognition","_this2","_continuous","_interimResults","_lang","window","document","documentElement","getAttribute","navigator","language","_grammars","SpeechGrammarList","_maxAlternatives","key","value","event","dispatchEvent","get","set","Error","_startOnce","catch","_this3","ErrorEvent","error","err","message","stack","_context4","lang","recognizer","_prepareAudioConfig","queue","_recognizer$audioConf","push","audioSourceReady","audioSourceOff","firstAudibleChunk","detachAudioConfigEvent","detach","canceled","_","sessionId","recognized","result","recognizing","sessionStarted","sessionStopped","speechStartDetected","speechEndDetected","phrases","grammars","dynamicGrammar","privReco","addReferenceGrammar","addPhrase","startContinuousRecognitionAsync","stopContinuousRecognitionAsync","abort","stop","undefined","finalizedResults","_loop","loop","_context3","shift","Object","keys","forEach","_this4","emitCognitiveServices","errorMessage","test","finalEvent","audioStarted","stopping","soundStarted","speechStarted","NoMatch","maxAlternatives","recognizable","transcript","continuous","interimResults","_ret","console","dispose","EventTarget","options","fromDefaultMicrophoneInput","fetchCredentials","speechRecognitionEndpointId","mediaDevices","getUserMedia","warn","_context5","_yield$fetchCredentia","authorizationToken","region","speechRecognitionHostname","subscriptionKey","host","hostname","port","protocol","speechConfig","fromHost","fromAuthorizationToken","fromSubscription","endpointId","outputFormat","Detailed","speechRecognitionLanguage"],"sources":["/Users/dylanmurray/Sweng-2022/front/node_modules/web-speech-cognitive-services/src/SpeechServices/SpeechToText/createSpeechRecognitionPonyfill.js"],"sourcesContent":["/* eslint class-methods-use-this: \"off\" */\n/* eslint complexity: [\"error\", 70] */\n/* eslint no-await-in-loop: \"off\" */\n/* eslint no-empty-function: \"off\" */\n/* eslint no-magic-numbers: [\"error\", { \"ignore\": [0, 100, 150] }] */\n\nimport { Event, EventTarget, getEventAttributeValue, setEventAttributeValue } from 'event-target-shim/es5';\n\nimport cognitiveServiceEventResultToWebSpeechRecognitionResultList from './cognitiveServiceEventResultToWebSpeechRecognitionResultList';\nimport createPromiseQueue from '../../Util/createPromiseQueue';\nimport patchOptions from '../patchOptions';\nimport SpeechGrammarList from './SpeechGrammarList';\nimport SpeechSDK from '../SpeechSDK';\n\n// https://docs.microsoft.com/en-us/javascript/api/microsoft-cognitiveservices-speech-sdk/speechconfig?view=azure-node-latest#outputformat\n// {\n//   \"RecognitionStatus\": \"Success\",\n//   \"Offset\": 900000,\n//   \"Duration\": 49000000,\n//   \"NBest\": [\n//     {\n//       \"Confidence\": 0.738919,\n//       \"Lexical\": \"second\",\n//       \"ITN\": \"second\",\n//       \"MaskedITN\": \"second\",\n//       \"Display\": \"Second.\"\n//     }\n//   ]\n// }\n\n// {\n//   \"RecognitionStatus\": \"InitialSilenceTimeout\",\n//   \"Offset\": 50000000,\n//   \"Duration\": 0\n// }\n\nconst { AudioConfig, OutputFormat, ResultReason, SpeechConfig, SpeechRecognizer } = SpeechSDK;\n\nfunction serializeRecognitionResult({ duration, errorDetails, json, offset, properties, reason, resultId, text }) {\n  return {\n    duration,\n    errorDetails,\n    json: JSON.parse(json),\n    offset,\n    properties,\n    reason,\n    resultId,\n    text\n  };\n}\n\nfunction averageAmplitude(arrayBuffer) {\n  const array = new Int16Array(arrayBuffer);\n\n  return (\n    [].reduce.call(array, (averageAmplitude, amplitude) => averageAmplitude + Math.abs(amplitude), 0) / array.length\n  );\n}\n\nfunction cognitiveServicesAsyncToPromise(fn) {\n  return (...args) => new Promise((resolve, reject) => fn(...args, resolve, reject));\n}\n\nclass SpeechRecognitionEvent extends Event {\n  constructor(type, { data, emma, interpretation, resultIndex, results } = {}) {\n    super(type);\n\n    this.data = data;\n    this.emma = emma;\n    this.interpretation = interpretation;\n    this.resultIndex = resultIndex;\n    this.results = results;\n  }\n}\n\nfunction prepareAudioConfig(audioConfig) {\n  const originalAttach = audioConfig.attach;\n  const boundOriginalAttach = audioConfig.attach.bind(audioConfig);\n  let firstChunk;\n  let muted;\n\n  // We modify \"attach\" function and detect when audible chunk is read.\n  // We will only modify \"attach\" function once.\n  audioConfig.attach = async () => {\n    const reader = await boundOriginalAttach();\n\n    return {\n      ...reader,\n      read: async () => {\n        const chunk = await reader.read();\n\n        // The magic number 150 is measured by:\n        // 1. Set microphone volume to 0\n        // 2. Observe the amplitude (100-110) for the first few chunks\n        //    (There is a short static caught when turning on the microphone)\n        // 3. Set the number a bit higher than the observation\n\n        if (!firstChunk && averageAmplitude(chunk.buffer) > 150) {\n          audioConfig.events.onEvent({ name: 'FirstAudibleChunk' });\n          firstChunk = true;\n        }\n\n        if (muted) {\n          return { buffer: new ArrayBuffer(0), isEnd: true, timeReceived: Date.now() };\n        }\n\n        return chunk;\n      }\n    };\n  };\n\n  return {\n    audioConfig,\n    pause: () => {\n      muted = true;\n    },\n    unprepare: () => {\n      audioConfig.attach = originalAttach;\n    }\n  };\n}\n\nexport function createSpeechRecognitionPonyfillFromRecognizer({\n  createRecognizer,\n  enableTelemetry,\n  looseEvents,\n  referenceGrammars,\n  textNormalization\n}) {\n  // If enableTelemetry is set to null or non-boolean, we will default to true.\n  SpeechRecognizer.enableTelemetry(enableTelemetry !== false);\n\n  class SpeechRecognition extends EventTarget {\n    constructor() {\n      super();\n\n      this._continuous = false;\n      this._interimResults = false;\n      this._lang =\n        typeof window !== 'undefined'\n          ? window.document.documentElement.getAttribute('lang') || window.navigator.language\n          : 'en-US';\n      this._grammars = new SpeechGrammarList();\n      this._maxAlternatives = 1;\n    }\n\n    emitCognitiveServices(type, event) {\n      this.dispatchEvent(\n        new SpeechRecognitionEvent('cognitiveservices', {\n          data: {\n            ...event,\n            type\n          }\n        })\n      );\n    }\n\n    get continuous() {\n      return this._continuous;\n    }\n\n    set continuous(value) {\n      this._continuous = value;\n    }\n\n    get grammars() {\n      return this._grammars;\n    }\n\n    set grammars(value) {\n      if (value instanceof SpeechGrammarList) {\n        this._grammars = value;\n      } else {\n        throw new Error(`The provided value is not of type 'SpeechGrammarList'`);\n      }\n    }\n\n    get interimResults() {\n      return this._interimResults;\n    }\n\n    set interimResults(value) {\n      this._interimResults = value;\n    }\n\n    get maxAlternatives() {\n      return this._maxAlternatives;\n    }\n\n    set maxAlternatives(value) {\n      this._maxAlternatives = value;\n    }\n\n    get lang() {\n      return this._lang;\n    }\n\n    set lang(value) {\n      this._lang = value;\n    }\n\n    get onaudioend() {\n      return getEventAttributeValue(this, 'audioend');\n    }\n\n    set onaudioend(value) {\n      setEventAttributeValue(this, 'audioend', value);\n    }\n\n    get onaudiostart() {\n      return getEventAttributeValue(this, 'audiostart');\n    }\n\n    set onaudiostart(value) {\n      setEventAttributeValue(this, 'audiostart', value);\n    }\n\n    get oncognitiveservices() {\n      return getEventAttributeValue(this, 'cognitiveservices');\n    }\n\n    set oncognitiveservices(value) {\n      setEventAttributeValue(this, 'cognitiveservices', value);\n    }\n\n    get onend() {\n      return getEventAttributeValue(this, 'end');\n    }\n\n    set onend(value) {\n      setEventAttributeValue(this, 'end', value);\n    }\n\n    get onerror() {\n      return getEventAttributeValue(this, 'error');\n    }\n\n    set onerror(value) {\n      setEventAttributeValue(this, 'error', value);\n    }\n\n    get onresult() {\n      return getEventAttributeValue(this, 'result');\n    }\n\n    set onresult(value) {\n      setEventAttributeValue(this, 'result', value);\n    }\n\n    get onsoundend() {\n      return getEventAttributeValue(this, 'soundend');\n    }\n\n    set onsoundend(value) {\n      setEventAttributeValue(this, 'soundend', value);\n    }\n\n    get onsoundstart() {\n      return getEventAttributeValue(this, 'soundstart');\n    }\n\n    set onsoundstart(value) {\n      setEventAttributeValue(this, 'soundstart', value);\n    }\n\n    get onspeechend() {\n      return getEventAttributeValue(this, 'speechend');\n    }\n\n    set onspeechend(value) {\n      setEventAttributeValue(this, 'speechend', value);\n    }\n\n    get onspeechstart() {\n      return getEventAttributeValue(this, 'speechstart');\n    }\n\n    set onspeechstart(value) {\n      setEventAttributeValue(this, 'speechstart', value);\n    }\n\n    get onstart() {\n      return getEventAttributeValue(this, 'start');\n    }\n\n    set onstart(value) {\n      setEventAttributeValue(this, 'start', value);\n    }\n\n    start() {\n      this._startOnce().catch(err => {\n        this.dispatchEvent(new ErrorEvent('error', { error: err, message: err && (err.stack || err.message) }));\n      });\n    }\n\n    async _startOnce() {\n      // TODO: [P2] Should check if recognition is active, we should not start recognition twice\n      const recognizer = await createRecognizer(this.lang);\n\n      const { pause, unprepare } = prepareAudioConfig(recognizer.audioConfig);\n\n      try {\n        const queue = createPromiseQueue();\n        let soundStarted;\n        let speechStarted;\n        let stopping;\n\n        const { detach: detachAudioConfigEvent } = recognizer.audioConfig.events.attach(event => {\n          const { name } = event;\n\n          if (name === 'AudioSourceReadyEvent') {\n            queue.push({ audioSourceReady: {} });\n          } else if (name === 'AudioSourceOffEvent') {\n            queue.push({ audioSourceOff: {} });\n          } else if (name === 'FirstAudibleChunk') {\n            queue.push({ firstAudibleChunk: {} });\n          }\n        });\n\n        recognizer.canceled = (_, { errorDetails, offset, reason, sessionId }) => {\n          queue.push({\n            canceled: {\n              errorDetails,\n              offset,\n              reason,\n              sessionId\n            }\n          });\n        };\n\n        recognizer.recognized = (_, { offset, result, sessionId }) => {\n          queue.push({\n            recognized: {\n              offset,\n              result: serializeRecognitionResult(result),\n              sessionId\n            }\n          });\n        };\n\n        recognizer.recognizing = (_, { offset, result, sessionId }) => {\n          queue.push({\n            recognizing: {\n              offset,\n              result: serializeRecognitionResult(result),\n              sessionId\n            }\n          });\n        };\n\n        recognizer.sessionStarted = (_, { sessionId }) => {\n          queue.push({ sessionStarted: { sessionId } });\n        };\n\n        recognizer.sessionStopped = (_, { sessionId }) => {\n          // \"sessionStopped\" is never fired, probably because we are using startContinuousRecognitionAsync instead of recognizeOnceAsync.\n          queue.push({ sessionStopped: { sessionId } });\n        };\n\n        recognizer.speechStartDetected = (_, { offset, sessionId }) => {\n          queue.push({ speechStartDetected: { offset, sessionId } });\n        };\n\n        recognizer.speechEndDetected = (_, { sessionId }) => {\n          // \"speechEndDetected\" is never fired, probably because we are using startContinuousRecognitionAsync instead of recognizeOnceAsync.\n          // Update: \"speechEndDetected\" is fired for DLSpeech.listenOnceAsync()\n          queue.push({ speechEndDetected: { sessionId } });\n        };\n\n        const { phrases } = this.grammars;\n\n        // HACK: We are using the internal of SpeechRecognizer because they did not expose it\n        const { dynamicGrammar } = recognizer.privReco;\n\n        referenceGrammars && referenceGrammars.length && dynamicGrammar.addReferenceGrammar(referenceGrammars);\n        phrases && phrases.length && dynamicGrammar.addPhrase(phrases);\n\n        await cognitiveServicesAsyncToPromise(recognizer.startContinuousRecognitionAsync.bind(recognizer))();\n\n        if (recognizer.stopContinuousRecognitionAsync) {\n          this.abort = () => queue.push({ abort: {} });\n          this.stop = () => queue.push({ stop: {} });\n        } else {\n          this.abort = this.stop = undefined;\n        }\n\n        let audioStarted;\n        let finalEvent;\n        let finalizedResults = [];\n\n        for (let loop = 0; !stopping || audioStarted; loop++) {\n          const event = await queue.shift();\n          const {\n            abort,\n            audioSourceOff,\n            audioSourceReady,\n            canceled,\n            firstAudibleChunk,\n            recognized,\n            recognizing,\n            stop\n          } = event;\n\n          // We are emitting event \"cognitiveservices\" for debugging purpose.\n          Object.keys(event).forEach(name => this.emitCognitiveServices(name, event[name]));\n\n          const errorMessage = canceled && canceled.errorDetails;\n\n          if (/Permission\\sdenied/u.test(errorMessage || '')) {\n            // If microphone is not allowed, we should not emit \"start\" event.\n\n            finalEvent = {\n              error: 'not-allowed',\n              type: 'error'\n            };\n\n            break;\n          }\n\n          if (!loop) {\n            this.dispatchEvent(new SpeechRecognitionEvent('start'));\n          }\n\n          if (errorMessage) {\n            if (/1006/u.test(errorMessage)) {\n              if (!audioStarted) {\n                this.dispatchEvent(new SpeechRecognitionEvent('audiostart'));\n                this.dispatchEvent(new SpeechRecognitionEvent('audioend'));\n              }\n\n              finalEvent = {\n                error: 'network',\n                type: 'error'\n              };\n            } else {\n              finalEvent = {\n                error: 'unknown',\n                type: 'error'\n              };\n            }\n\n            break;\n          } else if (abort || stop) {\n            if (abort) {\n              finalEvent = {\n                error: 'aborted',\n                type: 'error'\n              };\n\n              // If we are aborting, we will ignore lingering recognizing/recognized events. But if we are stopping, we need them.\n              stopping = 'abort';\n            } else {\n              // When we pause, we will send { isEnd: true }, Speech Services will send us \"recognized\" event.\n              pause();\n              stopping = 'stop';\n            }\n\n            // Abort should not be dispatched without support of \"stopContinuousRecognitionAsync\".\n            // But for defensive purpose, we make sure \"stopContinuousRecognitionAsync\" is available before we can call.\n            if (abort && recognizer.stopContinuousRecognitionAsync) {\n              await cognitiveServicesAsyncToPromise(recognizer.stopContinuousRecognitionAsync.bind(recognizer))();\n            }\n          } else if (audioSourceReady) {\n            this.dispatchEvent(new SpeechRecognitionEvent('audiostart'));\n\n            audioStarted = true;\n          } else if (firstAudibleChunk) {\n            this.dispatchEvent(new SpeechRecognitionEvent('soundstart'));\n\n            soundStarted = true;\n          } else if (audioSourceOff) {\n            // Looks like we don't need this line and all the tests are still working.\n            // Guessing probably stopping is already truthy.\n            // stopping = true;\n\n            speechStarted && this.dispatchEvent(new SpeechRecognitionEvent('speechend'));\n            soundStarted && this.dispatchEvent(new SpeechRecognitionEvent('soundend'));\n            audioStarted && this.dispatchEvent(new SpeechRecognitionEvent('audioend'));\n\n            audioStarted = soundStarted = speechStarted = false;\n\n            break;\n          } else if (stopping !== 'abort') {\n            if (recognized && recognized.result && recognized.result.reason === ResultReason.NoMatch) {\n              finalEvent = {\n                error: 'no-speech',\n                type: 'error'\n              };\n            } else if (recognized || recognizing) {\n              if (!audioStarted) {\n                // Unconfirmed prevention of quirks\n                this.dispatchEvent(new SpeechRecognitionEvent('audiostart'));\n\n                audioStarted = true;\n              }\n\n              if (!soundStarted) {\n                this.dispatchEvent(new SpeechRecognitionEvent('soundstart'));\n\n                soundStarted = true;\n              }\n\n              if (!speechStarted) {\n                this.dispatchEvent(new SpeechRecognitionEvent('speechstart'));\n\n                speechStarted = true;\n              }\n\n              if (recognized) {\n                const result = cognitiveServiceEventResultToWebSpeechRecognitionResultList(recognized.result, {\n                  maxAlternatives: this.maxAlternatives,\n                  textNormalization\n                });\n\n                const recognizable = !!result[0].transcript;\n\n                if (recognizable) {\n                  finalizedResults = [...finalizedResults, result];\n\n                  this.continuous &&\n                    this.dispatchEvent(\n                      new SpeechRecognitionEvent('result', {\n                        results: finalizedResults\n                      })\n                    );\n                }\n\n                // If it is continuous, we just sent the finalized results. So we don't need to send it again after \"audioend\" event.\n                if (this.continuous && recognizable) {\n                  finalEvent = null;\n                } else {\n                  finalEvent = {\n                    results: finalizedResults,\n                    type: 'result'\n                  };\n                }\n\n                if (!this.continuous && recognizer.stopContinuousRecognitionAsync) {\n                  await cognitiveServicesAsyncToPromise(recognizer.stopContinuousRecognitionAsync.bind(recognizer))();\n                }\n\n                // If event order can be loosened, we can send the recognized event as soon as we receive it.\n                // 1. If it is not recognizable (no-speech), we should send an \"error\" event just before \"end\" event. We will not loosen \"error\" events.\n                if (looseEvents && finalEvent && recognizable) {\n                  this.dispatchEvent(new SpeechRecognitionEvent(finalEvent.type, finalEvent));\n                  finalEvent = null;\n                }\n              } else if (recognizing) {\n                this.interimResults &&\n                  this.dispatchEvent(\n                    new SpeechRecognitionEvent('result', {\n                      results: [\n                        ...finalizedResults,\n                        cognitiveServiceEventResultToWebSpeechRecognitionResultList(recognizing.result, {\n                          maxAlternatives: this.maxAlternatives,\n                          textNormalization\n                        })\n                      ]\n                    })\n                  );\n              }\n            }\n          }\n        }\n\n        if (speechStarted) {\n          this.dispatchEvent(new SpeechRecognitionEvent('speechend'));\n        }\n\n        if (soundStarted) {\n          this.dispatchEvent(new SpeechRecognitionEvent('soundend'));\n        }\n\n        if (audioStarted) {\n          this.dispatchEvent(new SpeechRecognitionEvent('audioend'));\n        }\n\n        if (finalEvent) {\n          if (finalEvent.type === 'result' && !finalEvent.results.length) {\n            finalEvent = {\n              error: 'no-speech',\n              type: 'error'\n            };\n          }\n\n          if (finalEvent.type === 'error') {\n            this.dispatchEvent(new ErrorEvent('error', finalEvent));\n          } else {\n            this.dispatchEvent(new SpeechRecognitionEvent(finalEvent.type, finalEvent));\n          }\n        }\n\n        // Even though there is no \"start\" event emitted, we will still emit \"end\" event\n        // This is mainly for \"microphone blocked\" story.\n        this.dispatchEvent(new SpeechRecognitionEvent('end'));\n\n        detachAudioConfigEvent();\n      } catch (err) {\n        // Logging out the erorr because Speech SDK would fail silently.\n        console.error(err);\n\n        throw err;\n      } finally {\n        unprepare();\n        recognizer.dispose();\n      }\n    }\n  }\n\n  return {\n    SpeechGrammarList,\n    SpeechRecognition,\n    SpeechRecognitionEvent\n  };\n}\n\nexport default options => {\n  const {\n    audioConfig = AudioConfig.fromDefaultMicrophoneInput(),\n\n    // We set telemetry to true to honor the default telemetry settings of Speech SDK\n    // https://github.com/Microsoft/cognitive-services-speech-sdk-js#data--telemetry\n    enableTelemetry = true,\n\n    fetchCredentials,\n    looseEvents,\n    referenceGrammars,\n    speechRecognitionEndpointId,\n    textNormalization = 'display'\n  } = patchOptions(options);\n\n  if (!audioConfig && (!window.navigator.mediaDevices || !window.navigator.mediaDevices.getUserMedia)) {\n    console.warn(\n      'web-speech-cognitive-services: This browser does not support WebRTC and it will not work with Cognitive Services Speech Services.'\n    );\n\n    return {};\n  }\n\n  const createRecognizer = async lang => {\n    const { authorizationToken, region, speechRecognitionHostname, subscriptionKey } = await fetchCredentials();\n    let speechConfig;\n\n    if (speechRecognitionHostname) {\n      const host = { hostname: speechRecognitionHostname, port: 443, protocol: 'wss:' };\n\n      if (authorizationToken) {\n        speechConfig = SpeechConfig.fromHost(host);\n        speechConfig.authorizationToken = authorizationToken;\n      } else {\n        speechConfig = SpeechConfig.fromHost(host, subscriptionKey);\n      }\n    } else {\n      speechConfig = authorizationToken\n        ? SpeechConfig.fromAuthorizationToken(authorizationToken, region)\n        : SpeechConfig.fromSubscription(subscriptionKey, region);\n    }\n\n    if (speechRecognitionEndpointId) {\n      speechConfig.endpointId = speechRecognitionEndpointId;\n    }\n\n    speechConfig.outputFormat = OutputFormat.Detailed;\n    speechConfig.speechRecognitionLanguage = lang || 'en-US';\n\n    return new SpeechRecognizer(speechConfig, audioConfig);\n  };\n\n  return createSpeechRecognitionPonyfillFromRecognizer({\n    audioConfig,\n    createRecognizer,\n    enableTelemetry,\n    looseEvents,\n    referenceGrammars,\n    textNormalization\n  });\n};\n"]},"metadata":{},"sourceType":"script"}